
PMID- 26481401
OWN - NLM
STAT- In-Process
DA  - 20151020
LR  - 20151026
IS  - 1916-0216 (Electronic)
IS  - 1916-0208 (Linking)
VI  - 44
DP  - 2015
TI  - Face and content validity of a virtual-reality simulator for myringotomy with
      tube placement.
PG  - 40
LID - 10.1186/s40463-015-0094-2 [doi]
AB  - BACKGROUND: Myringotomy with tube insertion can be challenging for junior
      Otolaryngology residents as it is one of the first microscopic procedures they
      encounter. The Western myringotomy simulator was developed to allow trainees to
      practice microscope positioning, myringotomy, and tube placement. This
      virtual-reality simulator is viewed in stereoscopic 3D, and a haptic device is
      used to manipulate the digital ear model and surgical tools. OBJECTIVE: To assess
      the face and content validity of the Western myringotomy simulator. METHODS: The 
      myringotomy simulator was integrated with new modules to allow speculum
      placement, manipulation of an operative microscope, and insertion of the
      ventilation tube through a deformable tympanic membrane. A questionnaire was
      developed in consultation with instructing surgeons. Fourteen face validity
      questions focused on the anatomy of the ear, simulation of the operative
      microscope, appearance and movement of the surgical instruments, deformation and 
      cutting of the eardrum, and myringotomy tube insertion. Six content validity
      questions focused on training potential on surgical tasks such as speculum
      placement, microscope positioning, tool navigation, ear anatomy, myringotomy
      creation and tube insertion. A total of 12 participants from the Department of
      Otolaryngology-Head and Neck Surgery were recruited for the study. Prior to
      completing the questionnaire, participants were oriented to the simulator and
      given unlimited time to practice until they were comfortable with all of its
      aspects. RESULTS: Responses to 12 of the 14 questions on face validity were
      predominantly positive. One issue of concern was with contact modeling related to
      tube insertion into the eardrum, and the second was with the movement of the
      blade and forceps. The former could be resolved by using a higher resolution
      digital model for the eardrum to improve contact localization. The latter could
      be resolved by using a higher fidelity haptic device. With regard to content
      validity, 64% of the responses were positive, 21% were neutral, and 15% were
      negative. CONCLUSIONS: The Western myringotomy simulator appears to have
      sufficient face and content validity. Further development with automated metrics 
      and skills transference testing is planned.
FAU - Huang, Caiwen
AU  - Huang C
AD  - Department of Electrical and Computer Engineering, Western University, London,
      ON, Canada. chuang97@uwo.ca.
FAU - Cheng, Horace
AU  - Cheng H
AD  - Department of Otolaryngology - Head and Neck Surgery, Schulich School of Medicine
      and Dentistry, Western University, London, ON, Canada. Horace.Cheng@lhsc.on.ca.
FAU - Bureau, Yves
AU  - Bureau Y
AD  - Lawson Health Research Institute, London, ON, Canada. ybureau@lawsonimaging.ca.
AD  - Department of Medical Biophysics, Western University, London, ON, Canada.
      ybureau@lawsonimaging.ca.
FAU - Agrawal, Sumit K
AU  - Agrawal SK
AD  - Department of Electrical and Computer Engineering, Western University, London,
      ON, Canada. Sumit.Agrawal@lhsc.on.ca.
AD  - Department of Otolaryngology - Head and Neck Surgery, Schulich School of Medicine
      and Dentistry, Western University, London, ON, Canada. Sumit.Agrawal@lhsc.on.ca.
AD  - London Health Sciences Centre, Room B1-333, University Hospital, 339 Windermere
      Rd., London, N6A 5A5, ON, Canada. Sumit.Agrawal@lhsc.on.ca.
FAU - Ladak, Hanif M
AU  - Ladak HM
AD  - Department of Electrical and Computer Engineering, Western University, London,
      ON, Canada. hladak@uwo.ca.
AD  - Department of Otolaryngology - Head and Neck Surgery, Schulich School of Medicine
      and Dentistry, Western University, London, ON, Canada. hladak@uwo.ca.
AD  - Biomedical Engineering Graduate Program, Western University, London, ON, Canada. 
      hladak@uwo.ca.
AD  - Department of Medical Biophysics, Western University, London, ON, Canada.
      hladak@uwo.ca.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20151020
PL  - England
TA  - J Otolaryngol Head Neck Surg
JT  - Journal of otolaryngology - head & neck surgery = Le Journal
      d'oto-rhino-laryngologie et de chirurgie cervico-faciale
JID - 101479544
SB  - IM
PMC - PMC4615336
OID - NLM: PMC4615336
EDAT- 2015/10/21 06:00
MHDA- 2015/10/21 06:00
CRDT- 2015/10/21 06:00
PHST- 2015/05/18 [received]
PHST- 2015/10/12 [accepted]
PHST- 2015/10/20 [aheadofprint]
AID - 10.1186/s40463-015-0094-2 [doi]
AID - 10.1186/s40463-015-0094-2 [pii]
PST - epublish
SO  - J Otolaryngol Head Neck Surg. 2015 Oct 20;44:40. doi: 10.1186/s40463-015-0094-2.

PMID- 26436451
OWN - NLM
STAT- In-Process
DA  - 20151029
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
VI  - 526
IP  - 7575
DP  - 2015 Oct 29
TI  - Projections from neocortex mediate top-down control of memory retrieval.
PG  - 653-9
LID - 10.1038/nature15389 [doi]
AB  - Top-down prefrontal cortex inputs to the hippocampus have been hypothesized to be
      important in memory consolidation, retrieval, and the pathophysiology of major
      psychiatric diseases; however, no such direct projections have been identified
      and functionally described. Here we report the discovery of a monosynaptic
      prefrontal cortex (predominantly anterior cingulate) to hippocampus (CA3 to CA1
      region) projection in mice, and find that optogenetic manipulation of this
      projection (here termed AC-CA) is capable of eliciting contextual memory
      retrieval. To explore the network mechanisms of this process, we developed and
      applied tools to observe cellular-resolution neural activity in the hippocampus
      while stimulating AC-CA projections during memory retrieval in mice behaving in
      virtual-reality environments. Using this approach, we found that learning drives 
      the emergence of a sparse class of neurons in CA2/CA3 that are highly correlated 
      with the local network and that lead synchronous population activity events;
      these neurons are then preferentially recruited by the AC-CA projection during
      memory retrieval. These findings reveal a sparsely implemented memory retrieval
      mechanism in the hippocampus that operates via direct top-down prefrontal input, 
      with implications for the patterning and storage of salient memory
      representations.
FAU - Rajasethupathy, Priyamvada
AU  - Rajasethupathy P
AD  - Department of Bioengineering, Stanford University, Stanford, California 94305,
      USA.
AD  - CNC Program, Stanford University, Stanford, California 94305, USA.
FAU - Sankaran, Sethuraman
AU  - Sankaran S
AD  - CNC Program, Stanford University, Stanford, California 94305, USA.
FAU - Marshel, James H
AU  - Marshel JH
AD  - Department of Bioengineering, Stanford University, Stanford, California 94305,
      USA.
FAU - Kim, Christina K
AU  - Kim CK
AD  - Department of Bioengineering, Stanford University, Stanford, California 94305,
      USA.
AD  - Neuroscience Program, Stanford University, Stanford, California 94305, USA.
FAU - Ferenczi, Emily
AU  - Ferenczi E
AD  - Department of Bioengineering, Stanford University, Stanford, California 94305,
      USA.
AD  - Neuroscience Program, Stanford University, Stanford, California 94305, USA.
FAU - Lee, Soo Yeun
AU  - Lee SY
AD  - Department of Bioengineering, Stanford University, Stanford, California 94305,
      USA.
AD  - Neuroscience Program, Stanford University, Stanford, California 94305, USA.
FAU - Berndt, Andre
AU  - Berndt A
AD  - Department of Bioengineering, Stanford University, Stanford, California 94305,
      USA.
AD  - Neuroscience Program, Stanford University, Stanford, California 94305, USA.
FAU - Ramakrishnan, Charu
AU  - Ramakrishnan C
AD  - Department of Bioengineering, Stanford University, Stanford, California 94305,
      USA.
FAU - Jaffe, Anna
AU  - Jaffe A
AD  - Department of Bioengineering, Stanford University, Stanford, California 94305,
      USA.
FAU - Lo, Maisie
AU  - Lo M
AD  - Department of Bioengineering, Stanford University, Stanford, California 94305,
      USA.
FAU - Liston, Conor
AU  - Liston C
AD  - Department of Bioengineering, Stanford University, Stanford, California 94305,
      USA.
AD  - Department of Psychiatry and Behavioral Sciences, Stanford University, Stanford, 
      California 94305, USA.
FAU - Deisseroth, Karl
AU  - Deisseroth K
AD  - Department of Bioengineering, Stanford University, Stanford, California 94305,
      USA.
AD  - CNC Program, Stanford University, Stanford, California 94305, USA.
AD  - Department of Psychiatry and Behavioral Sciences, Stanford University, Stanford, 
      California 94305, USA.
AD  - Howard Hughes Medical Institute, Stanford University, Stanford, California 94305,
      USA.
LA  - eng
GR  - Howard Hughes Medical Institute/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, Non-U.S. Gov't
PT  - Research Support, U.S. Gov't, Non-P.H.S.
DEP - 20151005
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
EDAT- 2015/10/06 06:00
MHDA- 2015/10/06 06:00
CRDT- 2015/10/06 06:00
PHST- 2015/05/27 [received]
PHST- 2015/08/10 [accepted]
PHST- 2015/10/05 [aheadofprint]
AID - nature15389 [pii]
AID - 10.1038/nature15389 [doi]
PST - ppublish
SO  - Nature. 2015 Oct 29;526(7575):653-9. doi: 10.1038/nature15389. Epub 2015 Oct 5.

PMID- 26342783
OWN - NLM
STAT- Publisher
DA  - 20150906
LR  - 20150908
IS  - 1878-8750 (Electronic)
DP  - 2015 Sep 2
TI  - Virtual Interactive Presence in Global Surgical Education: International
      Collaboration through Augmented Reality.
LID - S1878-8750(15)01069-4 [pii]
LID - 10.1016/j.wneu.2015.08.053 [doi]
AB  - BACKGROUND: Technology allowing a remote, experienced surgeon to provide
      real-time guidance to local surgeons has great potential for training and
      capacity building in medical centers worldwide. Virtual interactive presence and 
      augmented reality (VIPAR), an iPad(R)-based tool, allows surgeons to provide
      long-distance virtual assistance wherever a wireless internet connection is
      available. Local and remote surgeons view a composite image of video feeds at
      each station, allowing for intraoperative telecollaboration in real time.
      METHODS: Local and remote stations were established in Ho Chi Minh City, Vietnam,
      and Birmingham, Alabama, as part of ongoing neurosurgical collaboration.
      Endoscopic third ventriculostomy with choroid plexus coagulation (ETV/CPC)
      utilizing VIPAR was used for subjective and objective evaluation of system
      performance. RESULTS: VIPAR allowed both surgeons to engage in complex visual and
      verbal communication during the procedure. Analysis of five video clips revealed 
      video delay of 237msec (range: 93-391msec) relative to the audio signal.
      Excellent image resolution allowed the remote neurosurgeon to visualize all
      critical anatomy. The remote neurosurgeon could gesture to structures with no
      detectable difference in accuracy between stations, allowing for sub-millimeter
      precision. Fifteen ETV/CPC procedures have been performed utilizing VIPAR between
      Vietnam and the United States, with no significant complications. 80% of these
      patients remain shunt-free. CONCLUSION: Evolving technologies allowing
      long-distance, intra-operative guidance and knowledge transfer hold great
      potential for highly efficient international neurosurgical education. VIPAR is
      one example of an inexpensive, scalable platform for increasing global
      neurosurgical capacity. Efforts to create a network of Vietnamese neurosurgeons
      using VIPAR for collaboration are underway.
CI  - Copyright (c) 2015 Elsevier Inc. All rights reserved.
FAU - Davis, Matthew Christopher
AU  - Davis MC
FAU - Can, Dang D
AU  - Can DD
FAU - Pindrik, Jonathan
AU  - Pindrik J
FAU - Rocque, Brandon G
AU  - Rocque BG
FAU - Johnston, James M
AU  - Johnston JM
LA  - ENG
PT  - JOURNAL ARTICLE
DEP - 20150902
TA  - World Neurosurg
JT  - World neurosurgery
JID - 101528275
OTO - NOTNLM
OT  - Global Health
OT  - Neurosurgery
OT  - Pediatrics
OT  - Telecommunications
EDAT- 2015/09/08 06:00
MHDA- 2015/09/08 06:00
CRDT- 2015/09/07 06:00
PHST- 2015/07/21 [received]
PHST- 2015/08/06 [revised]
PHST- 2015/08/07 [accepted]
AID - S1878-8750(15)01069-4 [pii]
AID - 10.1016/j.wneu.2015.08.053 [doi]
PST - aheadofprint
SO  - World Neurosurg. 2015 Sep 2. pii: S1878-8750(15)01069-4. doi:
      10.1016/j.wneu.2015.08.053.

PMID- 26284023
OWN - NLM
STAT- PubMed-not-MEDLINE
DA  - 20150818
DCOM- 20150818
LR  - 20150820
IS  - 1664-2295 (Electronic)
IS  - 1664-2295 (Linking)
VI  - 6
DP  - 2015
TI  - Maintaining Balance when Looking at a Virtual Reality Three-Dimensional Display
      of a Field of Moving Dots or at a Virtual Reality Scene.
PG  - 164
LID - 10.3389/fneur.2015.00164 [doi]
AB  - EXPERIMENTAL OBJECTIVE: To provide a safe, simple, relatively inexpensive, fast, 
      accurate way of quantifying balance performance either in isolation, or in the
      face of challenges provided by 3D high definition moving visual stimuli as well
      as by the proprioceptive challenge from standing on a foam pad. This method uses 
      the new technology of the Wii balance board to measure postural stability during 
      powerful, realistic visual challenges from immersive virtual reality. LIMITATIONS
      OF CURRENT TECHNIQUES: Present computerized methods for measuring postural
      stability are large, complex, slow, and expensive, and do not allow for testing
      the response to realistic visual challenges. PROTOCOL: Subjects stand on a 6 cm
      thick, firm, foam pad on a Wii balance board. They wear a fast, high resolution, 
      low persistence, virtual reality head set (Oculus Rift DK2). This allows displays
      of varying speed, direction, depth, and complexity to be delivered. The subject
      experiences a visual illusion of real objects fixed relative to the world, and
      any of these displays can be perturbed in an unpredictable fashion. A special app
      (BalanceRite) used the same procedures for analyzing postural analysis as used by
      the Equitest. POWER OF THE TECHNIQUE: Four simple "proof of concept" experiments 
      demonstrate that this technique matches the gold standard Equitest in terms of
      the measurement of postural stability but goes beyond the Equitest by measuring
      stability in the face of visual challenges, which are so powerful that even
      healthy subjects fall. The response to these challenges presents an opportunity
      for predicting falls and for rehabilitation of seniors and patients with poor
      postural stability. SIGNIFICANCE FOR THE FIELD: This new method provides a
      simpler, quicker, cheaper method of measurement than the Equitest. It may provide
      a new mode of training to prevent falls, by maintaining postural stability in the
      face of visual and proprioceptive challenges similar to those encountered in
      life.
FAU - Chiarovano, Elodie
AU  - Chiarovano E
AD  - CNRS UMR 8257, Cognition and Action Group, Centre Universitaire des Saints-Peres,
      Universite Paris Descartes , Paris , France.
FAU - de Waele, Catherine
AU  - de Waele C
AD  - CNRS UMR 8257, Cognition and Action Group, Centre Universitaire des Saints-Peres,
      Universite Paris Descartes , Paris , France.
FAU - MacDougall, Hamish G
AU  - MacDougall HG
AD  - Vestibular Research Laboratory, School of Psychology, University of Sydney ,
      Sydney, NSW , Australia.
FAU - Rogers, Stephen J
AU  - Rogers SJ
AD  - Vestibular Research Laboratory, School of Psychology, University of Sydney ,
      Sydney, NSW , Australia.
FAU - Burgess, Ann M
AU  - Burgess AM
AD  - Vestibular Research Laboratory, School of Psychology, University of Sydney ,
      Sydney, NSW , Australia.
FAU - Curthoys, Ian S
AU  - Curthoys IS
AD  - Vestibular Research Laboratory, School of Psychology, University of Sydney ,
      Sydney, NSW , Australia.
LA  - eng
PT  - Journal Article
DEP - 20150727
PL  - Switzerland
TA  - Front Neurol
JT  - Frontiers in neurology
JID - 101546899
PMC - PMC4515556
OID - NLM: PMC4515556
OTO - NOTNLM
OT  - balance
OT  - optokinetic
OT  - posture
OT  - proprioception
OT  - vestibular
OT  - virtual reality
EDAT- 2015/08/19 06:00
MHDA- 2015/08/19 06:01
CRDT- 2015/08/19 06:00
PHST- 2015 [ecollection]
PHST- 2015/05/08 [received]
PHST- 2015/07/06 [accepted]
PHST- 2015/07/27 [epublish]
AID - 10.3389/fneur.2015.00164 [doi]
PST - epublish
SO  - Front Neurol. 2015 Jul 27;6:164. doi: 10.3389/fneur.2015.00164. eCollection 2015.

PMID- 26191026
OWN - NLM
STAT- PubMed-not-MEDLINE
DA  - 20150720
DCOM- 20150720
LR  - 20150729
IS  - 1664-1078 (Electronic)
IS  - 1664-1078 (Linking)
VI  - 6
DP  - 2015
TI  - Modeling strategic use of human computer interfaces with novel hidden Markov
      models.
PG  - 919
LID - 10.3389/fpsyg.2015.00919 [doi]
AB  - Immersive software tools are virtual environments designed to give their users an
      augmented view of real-world data and ways of manipulating that data. As virtual 
      environments, every action users make while interacting with these tools can be
      carefully logged, as can the state of the software and the information it
      presents to the user, giving these actions context. This data provides a
      high-resolution lens through which dynamic cognitive and behavioral processes can
      be viewed. In this report, we describe new methods for the analysis and
      interpretation of such data, utilizing a novel implementation of the Beta Process
      Hidden Markov Model (BP-HMM) for analysis of software activity logs. We further
      report the results of a preliminary study designed to establish the validity of
      our modeling approach. A group of 20 participants were asked to play a simple
      computer game, instrumented to log every interaction with the interface.
      Participants had no previous experience with the game's functionality or rules,
      so the activity logs collected during their naive interactions capture patterns
      of exploratory behavior and skill acquisition as they attempted to learn the
      rules of the game. Pre- and post-task questionnaires probed for self-reported
      styles of problem solving, as well as task engagement, difficulty, and workload. 
      We jointly modeled the activity log sequences collected from all participants
      using the BP-HMM approach, identifying a global library of activity patterns
      representative of the collective behavior of all the participants. Analyses show 
      systematic relationships between both pre- and post-task questionnaires,
      self-reported approaches to analytic problem solving, and metrics extracted from 
      the BP-HMM decomposition. Overall, we find that this novel approach to
      decomposing unstructured behavioral data within software environments provides a 
      sensible means for understanding how users learn to integrate software
      functionality for strategic task pursuit.
FAU - Mariano, Laura J
AU  - Mariano LJ
AD  - The Charles Stark Draper Laboratory, Inc. Cambridge, MA, USA.
FAU - Poore, Joshua C
AU  - Poore JC
AD  - The Charles Stark Draper Laboratory, Inc. Cambridge, MA, USA.
FAU - Krum, David M
AU  - Krum DM
AD  - Mixed Reality Lab, Institute for Creative Technologies, University of Southern
      California Los Angeles, CA, USA.
FAU - Schwartz, Jana L
AU  - Schwartz JL
AD  - The Charles Stark Draper Laboratory, Inc. Cambridge, MA, USA.
FAU - Coskren, William D
AU  - Coskren WD
AD  - The Charles Stark Draper Laboratory, Inc. Cambridge, MA, USA.
FAU - Jones, Eric M
AU  - Jones EM
AD  - The Charles Stark Draper Laboratory, Inc. Cambridge, MA, USA.
LA  - eng
PT  - Journal Article
DEP - 20150703
PL  - Switzerland
TA  - Front Psychol
JT  - Frontiers in psychology
JID - 101550902
PMC - PMC4490801
OID - NLM: PMC4490801
OTO - NOTNLM
OT  - Markov processes
OT  - UX
OT  - behavioral modeling
OT  - contextual computing
OT  - hidden Markov models
OT  - human computer interaction
OT  - virtual environments
EDAT- 2015/07/21 06:00
MHDA- 2015/07/21 06:01
CRDT- 2015/07/21 06:00
PHST- 2015 [ecollection]
PHST- 2015/02/15 [received]
PHST- 2015/06/19 [accepted]
PHST- 2015/07/03 [epublish]
AID - 10.3389/fpsyg.2015.00919 [doi]
PST - epublish
SO  - Front Psychol. 2015 Jul 3;6:919. doi: 10.3389/fpsyg.2015.00919. eCollection 2015.

PMID- 26181538
OWN - NLM
STAT- MEDLINE
DA  - 20150718
DCOM- 20151005
LR  - 20151028
IS  - 1536-5964 (Electronic)
IS  - 0025-7974 (Linking)
VI  - 94
IP  - 28
DP  - 2015 Jul
TI  - Correcting Congenital Talipes Equinovarus in Children Using Three Different
      Corrective Methods: A Consort Study.
PG  - e1004
LID - 10.1097/MD.0000000000001004 [doi]
AB  - Equinus, varus, cavus, and adduction are typical signs of congenital talipes
      equinovarus (CTEV). Forefoot adduction remains a difficulty from using previous
      corrective methods. This study aims to develop a corrective method to reduce the 
      severity of forefoot adduction of CTEV children with moderate deformities during 
      their walking age. The devised method was compared with 2 other common corrective
      methods to evaluate its effectiveness. A Dennis Brown (DB) splint, DB splint with
      orthopedic shoes (OS), and forefoot abduct shoes (FAS) with OS were,
      respectively, applied to 15, 20, and 18 CTEV children with moderate deformities
      who were scored at their first visit according to the Dimeglio classification.
      The mean follow-up was 44 months and the orthoses were changed as the children
      grew. A 3D scanner and a high-resolution pedobarograph were used to record
      morphological characteristics and plantar pressure distribution. One-way MAVONA
      analysis was used to compare the bimalleolar angle, bean-shape ratio, and
      pressure ratios in each study group. There were significant differences in the
      FAS+OS group compared to the DB and DB+OS groups (P < 0.05) for most
      measurements. The most salient differences were as follows: the FAS+OS group had 
      a significantly greater bimalleolar angle (P < 0.05) and lower bean-shape ratio
      (P < 0.01) than the other groups; the DB+OS and FAS+OS groups had higher
      heel/forefoot and heel/LMF ratios (P < 0.01 and P < 0.001) than the DB group. FAS
      are critical for correcting improper forefoot adduction and OS are important for 
      the correction of equinus and varus in moderately afflicted CTEV children. This
      study suggests that the use of FAS+OS may improve treatment outcomes for moderate
      CTEV children who do not show signs of serious torsional deformity.
FAU - Chen, Wei
AU  - Chen W
AD  - From the Key Laboratory of Rehabilitation Technical Aids, Ministry of Civil
      Affair, School of Biological Science and Medical Engineering, Beihang University 
      (WC, FP, YY, JY, LW, YF); State Key Laboratory of Virtual Reality Technology and 
      Systems, Beihang University (FP, YF); National Research Center for Rehabilitation
      Technical Aids (YF); and Rokab Pedorthic Center, Beijing, P. R. China (HL).
FAU - Pu, Fang
AU  - Pu F
FAU - Yang, Yang
AU  - Yang Y
FAU - Yao, Jie
AU  - Yao J
FAU - Wang, Lizhen
AU  - Wang L
FAU - Liu, Hong
AU  - Liu H
FAU - Fan, Yubo
AU  - Fan Y
LA  - eng
PT  - Comparative Study
PT  - Journal Article
PT  - Randomized Controlled Trial
PT  - Research Support, Non-U.S. Gov't
PL  - United States
TA  - Medicine (Baltimore)
JT  - Medicine
JID - 2985248R
SB  - AIM
SB  - IM
MH  - Child
MH  - Child, Preschool
MH  - Clubfoot/*therapy
MH  - Female
MH  - *Foot Orthoses
MH  - Humans
MH  - Male
MH  - Prospective Studies
PMC - PMC4617080
OID - NLM: PMC4617080
EDAT- 2015/07/17 06:00
MHDA- 2015/10/06 06:00
CRDT- 2015/07/17 06:00
AID - 10.1097/MD.0000000000001004 [doi]
AID - 00005792-201507030-00007 [pii]
PST - ppublish
SO  - Medicine (Baltimore). 2015 Jul;94(28):e1004. doi: 10.1097/MD.0000000000001004.

PMID- 26085713
OWN - NLM
STAT- Publisher
DA  - 20150618
LR  - 20150621
IS  - 0957-4174 (Print)
IS  - 0957-4174 (Linking)
VI  - 42
IP  - 12
DP  - 2015 Jul 15
TI  - Optimization Model for Web Based Multimodal Interactive Simulations.
PG  - 5245-5255
AB  - This paper presents a technique for optimizing the performance of web based
      multimodal interactive simulations. For such applications where visual quality
      and the performance of simulations directly influence user experience,
      overloading of hardware resources may result in unsatisfactory reduction in the
      quality of the simulation and user satisfaction. However, optimization of
      simulation performance on individual hardware platforms is not practical. Hence, 
      we present a mixed integer programming model to optimize the performance of
      graphical rendering and simulation performance while satisfying application
      specific constraints. Our approach includes three distinct phases:
      identification, optimization and update. In the identification phase, the
      computing and rendering capabilities of the client device are evaluated using an 
      exploratory proxy code. This data is utilized in conjunction with user specified 
      design requirements in the optimization phase to ensure best possible
      computational resource allocation. The optimum solution is used for rendering
      (e.g. texture size, canvas resolution) and simulation parameters (e.g. simulation
      domain) in the update phase. Test results are presented on multiple hardware
      platforms with diverse computing and graphics capabilities to demonstrate the
      effectiveness of our approach.
FAU - Halic, Tansel
AU  - Halic T
AD  - Computer Science Department, University of Central Arkansas, 201 Donaghey Ave.,
      Conway, Arkansas, 72035.
FAU - Ahn, Woojin
AU  - Ahn W
AD  - Department of Mechanical, Aerospace and Nuclear Engineering, Rensselaer
      Polytechnic Institute, Troy, New York, 12180.
FAU - De, Suvranu
AU  - De S
AD  - Department of Mechanical, Aerospace and Nuclear Engineering, Rensselaer
      Polytechnic Institute, Troy, New York, 12180.
LA  - ENG
GR  - R01 EB005807/EB/NIBIB NIH HHS/United States
GR  - R01 EB009362/EB/NIBIB NIH HHS/United States
GR  - R01 EB010037/EB/NIBIB NIH HHS/United States
GR  - R01 EB014305/EB/NIBIB NIH HHS/United States
GR  - R01 HL119248/HL/NHLBI NIH HHS/United States
PT  - JOURNAL ARTICLE
TA  - Expert Syst Appl
JT  - Expert systems with applications
JID - 9884333
PMC - PMC4465190
MID - NIHMS669530
OTO - NOTNLM
OT  - Interactive Web environments for Medicine
OT  - Optimization
OT  - Simulation
OT  - Virtual reality
OT  - Web-based interaction
EDAT- 2015/06/19 06:00
MHDA- 2015/06/19 06:00
CRDT- 2015/06/19 06:00
PMCR- 2016/07/15 00:00
AID - 10.1016/j.eswa.2015.02.026 [doi]
PST - ppublish
SO  - Expert Syst Appl. 2015 Jul 15;42(12):5245-5255.

PMID- 26069857
OWN - NLM
STAT- PubMed-not-MEDLINE
DA  - 20150613
DCOM- 20150613
LR  - 20150614
IS  - 2160-8407 (Electronic)
VI  - 5
IP  - 3
DP  - 2015
TI  - The next evolution in radioguided surgery: breast cancer related sentinel node
      localization using a freehandSPECT-mobile gamma camera combination.
PG  - 233-45
AB  - Accurate pre- and intraoperative identification of the sentinel node (SN) forms
      the basis of the SN biopsy procedure. Gamma tracing technologies such as a gamma 
      probe (GP), a 2D mobile gamma camera (MGC) or 3D freehandSPECT (FHS) can be used 
      to provide the surgeon with radioguidance to the SN(s). We reasoned that
      integrated use of these technologies results in the generation of a "hybrid"
      modality that combines the best that the individual radioguidance technologies
      have to offer. The sensitivity and resolvability of both 2D-MGC and 3D-FHS-MGC
      were studied in a phantom setup (at various source-detector depths and using
      varying injection site-to-SN distances), and in ten breast cancer patients
      scheduled for SN biopsy. Acquired 3D-FHS-MGC images were overlaid with the
      position of the phantom/patient. This augmented-reality overview image was then
      used for navigation to the hotspot/SN in virtual-reality using the GP. Obtained
      results were compared to conventional gamma camera lymphoscintigrams. Resolution 
      of 3D-FHS-MGC allowed identification of the SNs at a minimum injection site (100 
      MBq)-to-node (1 MBq; 1%) distance of 20 mm, up to a source-detector depth of 36
      mm in 2D-MGC and up to 24 mm in 3D-FHS-MGC. A clinically relevant dose of
      approximately 1 MBq was clearly detectable up to a depth of 60 mm in 2D-MGC and
      48 mm in 3D-FHS-MGC. In all ten patients at least one SN was visualized on the
      lymphoscintigrams with a total of 12 SNs visualized. 3D-FHS-MGC identified 11 of 
      12 SNs and allowed navigation to all these visualized SNs; in one patient with
      two axillary SNs located closely to each other (11 mm), 3D-FHS-MGC was not able
      to distinguish the two SNs. In conclusion, high sensitivity detection of SNs at
      an injection site-to-node distance of 20 mm-and-up was possible using 3D-FHS-MGC.
      In patients, 3D-FHS-MGC showed highly reproducible images as compared to the
      conventional lymphoscintigrams.
FAU - Engelen, Thijs
AU  - Engelen T
AD  - Interventional Molecular Imaging Laboratory and Nuclear Medicine section,
      Department of Radiology, Leiden University Medical Center Albinusdreef 2, PO Box 
      9600, 2300 RC, Leiden, The Netherlands ; Department of Head and Neck Surgery and 
      Oncology, The Netherlands Cancer Institute - Antoni van Leeuwenhoek Hospital
      Plesmanlaan 121, 1066CX, Amsterdam, The Netherlands.
FAU - Winkel, Beatrice Mf
AU  - Winkel BM
AD  - Interventional Molecular Imaging Laboratory and Nuclear Medicine section,
      Department of Radiology, Leiden University Medical Center Albinusdreef 2, PO Box 
      9600, 2300 RC, Leiden, The Netherlands.
FAU - Rietbergen, Daphne Dd
AU  - Rietbergen DD
AD  - Interventional Molecular Imaging Laboratory and Nuclear Medicine section,
      Department of Radiology, Leiden University Medical Center Albinusdreef 2, PO Box 
      9600, 2300 RC, Leiden, The Netherlands.
FAU - KleinJan, Gijs H
AU  - KleinJan GH
AD  - Interventional Molecular Imaging Laboratory and Nuclear Medicine section,
      Department of Radiology, Leiden University Medical Center Albinusdreef 2, PO Box 
      9600, 2300 RC, Leiden, The Netherlands ; Department of Nuclear Medicine, The
      Netherlands Cancer Institute - Antoni van Leeuwenhoek Hospital Plesmanlaan 121,
      1066CX, Amsterdam, The Netherlands.
FAU - Vidal-Sicart, Sergi
AU  - Vidal-Sicart S
AD  - Department of Nuclear Medicine, Hospital Clinic-Barcelona Villarroel 170. 08036
      Barcelona, Spain.
FAU - Olmos, Renato A Valdes
AU  - Olmos RA
AD  - Interventional Molecular Imaging Laboratory and Nuclear Medicine section,
      Department of Radiology, Leiden University Medical Center Albinusdreef 2, PO Box 
      9600, 2300 RC, Leiden, The Netherlands ; Department of Nuclear Medicine, The
      Netherlands Cancer Institute - Antoni van Leeuwenhoek Hospital Plesmanlaan 121,
      1066CX, Amsterdam, The Netherlands.
FAU - van den Berg, Nynke S
AU  - van den Berg NS
AD  - Interventional Molecular Imaging Laboratory and Nuclear Medicine section,
      Department of Radiology, Leiden University Medical Center Albinusdreef 2, PO Box 
      9600, 2300 RC, Leiden, The Netherlands ; Department of Urology, The Netherlands
      Cancer Institute - Antoni van Leeuwenhoek Hospital Plesmanlaan 121, 1066CX,
      Amsterdam, The Netherlands.
FAU - van Leeuwen, Fijs Wb
AU  - van Leeuwen FW
AD  - Interventional Molecular Imaging Laboratory and Nuclear Medicine section,
      Department of Radiology, Leiden University Medical Center Albinusdreef 2, PO Box 
      9600, 2300 RC, Leiden, The Netherlands ; Department of Head and Neck Surgery and 
      Oncology, The Netherlands Cancer Institute - Antoni van Leeuwenhoek Hospital
      Plesmanlaan 121, 1066CX, Amsterdam, The Netherlands ; Department of Urology, The 
      Netherlands Cancer Institute - Antoni van Leeuwenhoek Hospital Plesmanlaan 121,
      1066CX, Amsterdam, The Netherlands.
LA  - eng
PT  - Journal Article
DEP - 20150215
PL  - United States
TA  - Am J Nucl Med Mol Imaging
JT  - American journal of nuclear medicine and molecular imaging
JID - 101564121
PMC - PMC4446392
OID - NLM: PMC4446392
OTO - NOTNLM
OT  - Sentinel node
OT  - breast cancer
OT  - freehandSPECT
OT  - mobile gamma camera
OT  - navigation
OT  - nuclear medicine
OT  - radioguided surgery
EDAT- 2015/06/13 06:00
MHDA- 2015/06/13 06:01
CRDT- 2015/06/13 06:00
PHST- 2015 [ecollection]
PHST- 2014/12/09 [received]
PHST- 2015/01/09 [accepted]
PHST- 2015/02/15 [epublish]
PST - epublish
SO  - Am J Nucl Med Mol Imaging. 2015 Feb 15;5(3):233-45. eCollection 2015.

PMID- 25967333
OWN - NLM
STAT- PubMed-not-MEDLINE
DA  - 20150513
DCOM- 20150715
IS  - 1539-4522 (Electronic)
IS  - 0003-6935 (Linking)
VI  - 54
IP  - 11
DP  - 2015 Apr 10
TI  - Slim near-eye display using pinhole aperture arrays.
PG  - 3422-7
LID - 10.1364/AO.54.003422 [doi]
AB  - We report a new technique for building a wide-angle, lightweight,
      thin-form-factor, cost-effective, easy-to-manufacture near-eye head-mounted
      display (HMD) for virtual reality applications. Our approach adopts an aperture
      mask containing an array of pinholes and a screen as a source of imagery. We
      demonstrate proof-of-concept HMD prototypes with a binocular field of view (FOV) 
      of 70 degrees x45 degrees , or total diagonal FOV of 83 degrees . This FOV should
      increase with increasing display panel size. The optical angular resolution
      supported in our prototype can go down to 1.4-2.1 arcmin by adopting a display
      with 20-30 mum pixel pitch.
FAU - Aksit, Kaan
AU  - Aksit K
FAU - Kautz, Jan
AU  - Kautz J
FAU - Luebke, David
AU  - Luebke D
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Appl Opt
JT  - Applied optics
JID - 0247660
EDAT- 2015/05/15 06:00
MHDA- 2015/05/15 06:01
CRDT- 2015/05/14 06:00
AID - 315125 [pii]
PST - ppublish
SO  - Appl Opt. 2015 Apr 10;54(11):3422-7. doi: 10.1364/AO.54.003422.

PMID- 25929248
OWN - NLM
STAT- Publisher
DA  - 20150501
LR  - 20150502
IS  - 1935-9780 (Electronic)
IS  - 1935-9772 (Linking)
DP  - 2015 Apr 30
TI  - Stereoscopic vascular models of the head and neck: A computed tomography
      angiography visualization.
LID - 10.1002/ase.1537 [doi]
AB  - Computer-assisted 3D models are used in some medical and allied health science
      schools; however, they are often limited to online use and 2D flat screen-based
      imaging. Few schools take advantage of 3D stereoscopic learning tools in anatomy 
      education and clinically relevant anatomical variations when teaching anatomy. A 
      new approach to teaching anatomy includes use of computed tomography angiography 
      (CTA) images of the head and neck to create clinically relevant 3D stereoscopic
      virtual models. These high resolution images of the arteries can be used in
      unique and innovative ways to create 3D virtual models of the vasculature as a
      tool for teaching anatomy. Blood vessel 3D models are presented stereoscopically 
      in a virtual reality environment, can be rotated 360 degrees in all axes, and
      magnified according to need. In addition, flexible views of internal structures
      are possible. Images are displayed in a stereoscopic mode, and students view
      images in a small theater-like classroom while wearing polarized 3D glasses.
      Reconstructed 3D models enable students to visualize vascular structures with
      clinically relevant anatomical variations in the head and neck and appreciate
      spatial relationships among the blood vessels, the skull and the skin. Anat Sci
      Educ. (c) 2015 American Association of Anatomists.
CI  - (c) 2015 American Association of Anatomists.
FAU - Cui, Dongmei
AU  - Cui D
AD  - Department of Neurobiology and Anatomical Sciences, University of Mississippi
      Medical Center, Jackson, Mississippi.
FAU - Lynch, James C
AU  - Lynch JC
FAU - Smith, Andrew D
AU  - Smith AD
FAU - Wilson, Timothy D
AU  - Wilson TD
FAU - Lehman, Michael N
AU  - Lehman MN
LA  - ENG
PT  - JOURNAL ARTICLE
DEP - 20150430
TA  - Anat Sci Educ
JT  - Anatomical sciences education
JID - 101392205
OTO - NOTNLM
OT  - 3D stereoscopic models
OT  - 3D virtual models
OT  - CT angiography
OT  - CTA
OT  - anatomy imaging
OT  - gross anatomy education
OT  - medical education
OT  - radiology education
OT  - vasculature of the head and neck
EDAT- 2015/05/02 06:00
MHDA- 2015/05/02 06:00
CRDT- 2015/05/02 06:00
PHST- 2015/02/05 [received]
PHST- 2015/04/10 [revised]
PHST- 2015/04/12 [accepted]
AID - 10.1002/ase.1537 [doi]
PST - aheadofprint
SO  - Anat Sci Educ. 2015 Apr 30. doi: 10.1002/ase.1537.

PMID- 25915061
OWN - NLM
STAT- In-Process
DA  - 20150428
LR  - 20150508
IS  - 1932-6203 (Electronic)
IS  - 1932-6203 (Linking)
VI  - 10
IP  - 4
DP  - 2015
TI  - MEVA--An Interactive Visualization Application for Validation of Multifaceted
      Meteorological Data with Multiple 3D Devices.
PG  - e0123811
LID - 10.1371/journal.pone.0123811 [doi]
AB  - BACKGROUND: To achieve more realistic simulations, meteorologists develop and use
      models with increasing spatial and temporal resolution. The analyzing, comparing,
      and visualizing of resulting simulations becomes more and more challenging due to
      the growing amounts and multifaceted character of the data. Various data sources,
      numerous variables and multiple simulations lead to a complex database. Although 
      a variety of software exists suited for the visualization of meteorological data,
      none of them fulfills all of the typical domain-specific requirements: support
      for quasi-standard data formats and different grid types, standard visualization 
      techniques for scalar and vector data, visualization of the context (e.g.,
      topography) and other static data, support for multiple presentation devices used
      in modern sciences (e.g., virtual reality), a user-friendly interface, and
      suitability for cooperative work. METHODS AND RESULTS: Instead of attempting to
      develop yet another new visualization system to fulfill all possible needs in
      this application domain, our approach is to provide a flexible workflow that
      combines different existing state-of-the-art visualization software components in
      order to hide the complexity of 3D data visualization tools from the end user. To
      complete the workflow and to enable the domain scientists to interactively
      visualize their data without advanced skills in 3D visualization systems, we
      developed a lightweight custom visualization application (MEVA - multifaceted
      environmental data visualization application) that supports the most relevant
      visualization and interaction techniques and can be easily deployed.
      Specifically, our workflow combines a variety of different data abstraction
      methods provided by a state-of-the-art 3D visualization application with the
      interaction and presentation features of a computer-games engine. Our customized 
      application includes solutions for the analysis of multirun data, specifically
      with respect to data uncertainty and differences between simulation runs. In an
      iterative development process, our easy-to-use application was developed in close
      cooperation with meteorologists and visualization experts. The usability of the
      application has been validated with user tests. We report on how this application
      supports the users to prove and disprove existing hypotheses and discover new
      insights. In addition, the application has been used at public events to
      communicate research results.
FAU - Helbig, Carolin
AU  - Helbig C
AD  - Department of Environmental Informatics, Helmholtz Centre for Environmental
      Research (UFZ), Leipzig, Germany; Faculty of Environmental Sciences, Technical
      University Dresden, Dresden, Germany.
FAU - Bilke, Lars
AU  - Bilke L
AD  - Department of Environmental Informatics, Helmholtz Centre for Environmental
      Research (UFZ), Leipzig, Germany.
FAU - Bauer, Hans-Stefan
AU  - Bauer HS
AD  - Institute of Physics and Meteorology, University of Hohenheim, Stuttgart,
      Germany.
FAU - Bottinger, Michael
AU  - Bottinger M
AD  - German Climate Computing Center (DKRZ), Hamburg, Germany.
FAU - Kolditz, Olaf
AU  - Kolditz O
AD  - Department of Environmental Informatics, Helmholtz Centre for Environmental
      Research (UFZ), Leipzig, Germany; Faculty of Environmental Sciences, Technical
      University Dresden, Dresden, Germany.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20150427
PL  - United States
TA  - PLoS One
JT  - PloS one
JID - 101285081
SB  - IM
PMC - PMC4411171
OID - NLM: PMC4411171
EDAT- 2015/04/29 06:00
MHDA- 2015/04/29 06:00
CRDT- 2015/04/28 06:00
PHST- 2015 [ecollection]
PHST- 2014/07/31 [received]
PHST- 2015/03/07 [accepted]
PHST- 2015/04/27 [epublish]
AID - 10.1371/journal.pone.0123811 [doi]
AID - PONE-D-14-34348 [pii]
PST - epublish
SO  - PLoS One. 2015 Apr 27;10(4):e0123811. doi: 10.1371/journal.pone.0123811.
      eCollection 2015.

PMID- 25910194
OWN - NLM
STAT- Publisher
DA  - 20150424
LR  - 20150425
IS  - 1558-0210 (Electronic)
IS  - 1534-4320 (Linking)
DP  - 2015 Apr 22
TI  - Monitoring Neuro-motor Recovery from Stroke with High-resolution EEG, Robotics
      and Virtual Reality: a Proof of Concept.
AB  - A novel system for the neuro-motor rehabilitation of upper limbs was validated in
      three sub-acute post-stroke pa-tients. The system permits synchronized cortical
      and kinematic measures by integrating high-resolution EEG, passive robotic device
      and Virtual Reality. The brain functional re-organization was monitored in
      association with motor patterns replicating ac-tivities of daily living (ADL).
      Patients underwent 13 rehabilita-tion sessions. At sessions 1, 7 and 13, clinical
      tests were adminis-tered to assess the level of motor impairment, and EEG was
      rec-orded during rehabilitation task execution. For each session and
      rehabilitation task, four kinematic indices of motor performance were calculated 
      and compared with the outcome of clinical tests. Functional source maps were
      obtained from EEG data and pro-jected on the real patients' anatomy (MRI data).
      Laterality indic-es were calculated for hemispheric dominance assessment. All
      patients showed increased participation in the rehabilitation process. Cortical
      activation changes during recovery were de-tected in relation to different motor 
      patterns, hence verifying the system's suitability to add quantitative measures
      of motor per-formance and neural recovery to classical tests. We conclude that
      this system seems a promising tool for novel robot-based rehabili-tation
      paradigms tailored to individual needs and neuro-motor responses of the patients.
FAU - Comani, Silvia
AU  - Comani S
FAU - Velluto, Lucia
AU  - Velluto L
FAU - Schinaia, Lorenzo
AU  - Schinaia L
FAU - Cerroni, Gianluigi
AU  - Cerroni G
FAU - Serio, Antonio
AU  - Serio A
FAU - Buzzelli, Sandro
AU  - Buzzelli S
FAU - Sorbi, Sandro
AU  - Sorbi S
FAU - Guarnieri, Biancamaria
AU  - Guarnieri B
LA  - ENG
PT  - JOURNAL ARTICLE
DEP - 20150422
TA  - IEEE Trans Neural Syst Rehabil Eng
JT  - IEEE transactions on neural systems and rehabilitation engineering : a
      publication of the IEEE Engineering in Medicine and Biology Society
JID - 101097023
EDAT- 2015/04/25 06:00
MHDA- 2015/04/25 06:00
CRDT- 2015/04/25 06:00
AID - 10.1109/TNSRE.2015.2425474 [doi]
PST - aheadofprint
SO  - IEEE Trans Neural Syst Rehabil Eng. 2015 Apr 22.

PMID- 25898342
OWN - NLM
STAT- In-Process
DA  - 20150508
IS  - 1873-622X (Electronic)
IS  - 0005-7967 (Linking)
VI  - 69
DP  - 2015 Jun
TI  - Veteran satisfaction and treatment preferences in response to a posttraumatic
      stress disorder specialty clinic orientation group.
PG  - 75-82
LID - 10.1016/j.brat.2015.04.006 [doi]
LID - S0005-7967(15)00064-9 [pii]
AB  - To maximize accessibility to evidence-based treatments for posttraumatic stress
      disorder (PTSD), the United States Department of Veterans Affairs (VA) has widely
      disseminated cognitive processing therapy (CPT) and prolonged exposure (PE)
      therapy to VA clinicians. However, there is a lack of research on veteran
      preferences when presented with a range of psychotherapy and medication options. 
      This study uses a mixed-method approach to explore veteran satisfaction with a VA
      PTSD specialty clinic pre-treatment orientation group, which provides education
      about available PTSD treatment options. This study also tested differences in
      treatment preference in response to the group. Participants were 183 US veterans.
      Most were White, male, and referred to the clinic by a VA provider. Results
      indicated high satisfaction with the group in providing an overview of services
      and helping to inform treatment choice. Most preferred psychotherapy plus
      medications (63.4%) or psychotherapy only (30.1%). Participants endorsed a
      significantly stronger preference for CPT versus other psychotherapies. PE was
      significantly preferred over nightmare resolution therapy and present-centered
      therapy, and both PE and cognitive-behavioral conjoint therapy were preferred
      over virtual reality exposure therapy. Results suggest that by informing
      consumers about evidence-based treatments for PTSD, pre-treatment educational
      approaches may increase consumer demand for these treatment options.
CI  - Published by Elsevier Ltd.
FAU - Schumm, Jeremiah A
AU  - Schumm JA
AD  - Cincinnati VA Medical Center, Trauma Recovery Center, 3200 Vine Street,
      Cincinnati, OH 45220, USA; University of Cincinnati, Department of Psychiatry and
      Behavioral Neuroscience, 260 Stetson Street, Suite 3200, Cincinnati, OH 45219,
      USA. Electronic address: Jeremiah.Schumm@va.gov.
FAU - Walter, Kristen H
AU  - Walter KH
AD  - Veterans Medical Research Foundation, VA San Diego Healthcare System, USA.
FAU - Bartone, Anne S
AU  - Bartone AS
AD  - Cincinnati VA Medical Center, Trauma Recovery Center, 3200 Vine Street,
      Cincinnati, OH 45220, USA.
FAU - Chard, Kathleen M
AU  - Chard KM
AD  - Cincinnati VA Medical Center, Trauma Recovery Center, 3200 Vine Street,
      Cincinnati, OH 45220, USA; University of Cincinnati, Department of Psychiatry and
      Behavioral Neuroscience, 260 Stetson Street, Suite 3200, Cincinnati, OH 45219,
      USA.
LA  - eng
PT  - Journal Article
PT  - Research Support, U.S. Gov't, Non-P.H.S.
DEP - 20150416
PL  - England
TA  - Behav Res Ther
JT  - Behaviour research and therapy
JID - 0372477
SB  - IM
OTO - NOTNLM
OT  - Choice
OT  - Medication
OT  - Posttraumatic stress disorder
OT  - Psychotherapy
OT  - Veterans
EDAT- 2015/04/22 06:00
MHDA- 2015/04/22 06:00
CRDT- 2015/04/22 06:00
PHST- 2014/09/29 [received]
PHST- 2015/03/26 [revised]
PHST- 2015/04/11 [accepted]
PHST- 2015/04/16 [aheadofprint]
AID - S0005-7967(15)00064-9 [pii]
AID - 10.1016/j.brat.2015.04.006 [doi]
PST - ppublish
SO  - Behav Res Ther. 2015 Jun;69:75-82. doi: 10.1016/j.brat.2015.04.006. Epub 2015 Apr
      16.

PMID- 25811316
OWN - NLM
STAT- In-Process
DA  - 20150703
IS  - 1940-1027 (Electronic)
IS  - 0022-2895 (Linking)
VI  - 47
IP  - 6
DP  - 2015
TI  - Visual and Proprioceptive Adaptation of Arm Position in a Virtual Environment.
PG  - 483-9
LID - 10.1080/00222895.2015.1015674 [doi]
AB  - The authors examined the resolution of a discrepancy between visual and
      proprioceptive estimates of arm position in 10 participants. The participants
      fixed their right shoulder at 0 degrees , 30 degrees , or 60 degrees of
      transverse adduction while they viewed a video on a head-mounted display that
      showed their right arm extended in front of the trunk for 30 min. The perceived
      arm position more closely approached the seen arm position on the display as the 
      difference between the actual and visually displayed arm positions increased. In 
      the extreme case of a 90 degrees discrepancy, the seen arm position on the
      display was very gradually perceived as approaching the actual arm position. The 
      magnitude of changes in sensory estimates was larger for proprioception (20%)
      than for vision (< 10%).
FAU - Masumoto, Junya
AU  - Masumoto J
AD  - a The Joint Graduate School in Science of School Education, Hyogo University of
      Teacher Education , Kato , Japan.
FAU - Inui, Nobuyuki
AU  - Inui N
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20150326
PL  - United States
TA  - J Mot Behav
JT  - Journal of motor behavior
JID - 0236512
SB  - IM
OTO - NOTNLM
OT  - adaptation
OT  - position sense
OT  - proprioception
OT  - virtual reality
OT  - vision
EDAT- 2015/03/27 06:00
MHDA- 2015/03/27 06:00
CRDT- 2015/03/27 06:00
PHST- 2015/03/26 [aheadofprint]
AID - 10.1080/00222895.2015.1015674 [doi]
PST - ppublish
SO  - J Mot Behav. 2015;47(6):483-9. doi: 10.1080/00222895.2015.1015674. Epub 2015 Mar 
      26.

PMID- 25720239
OWN - NLM
STAT- MEDLINE
DA  - 20150227
DCOM- 20150401
IS  - 0019-1442 (Print)
IS  - 0019-1442 (Linking)
VI  - 67
IP  - 11-12
DP  - 2014 Nov 30
TI  - [The interactive neuroanatomical simulation and practical application of
      frontotemporal transsylvian exposure in neurosurgery].
PG  - 376-83
AB  - BACKGROUND AND PURPOSE: There is an increased need for new digital education
      tools in neurosurgical training. Illustrated textbooks offer anatomic and
      technical reference but do not substitute hands-on experience provided by surgery
      or cadaver dissection. Due to limited availability of cadaver dissections the
      need for development of simulation tools has been augmented. We explored
      simulation technology for producing virtual reality-like reconstructions of
      simulated surgical approaches on cadaver. Practical application of the simulation
      tool has been presented through frontotemporal transsylvian exposure. METHODS:
      The dissections were performed on two cadaveric heads. Arteries and veins were
      prepared and injected with colorful silicon rubber. The heads were rigidly fixed 
      in Mayfield headholder. A robotic microscope with two digital cameras in inverted
      cone method of image acquisition was used to capture images around a pivot point 
      in several phases of dissections. Multilayered, high-resolution images have been 
      built into interactive 4D environment by custom developed software. RESULTS: We
      have developed the simulation module of the frontotemporal transsylvian approach.
      The virtual specimens can be rotated or tilted to any selected angles and
      examined from different surgical perspectives at any stage of dissections.
      Important surgical issues such as appropriate head positioning or surgical
      maneuvers to expose deep situated neuroanatomic structures can be simulated and
      studied by using the module. CONCLUSION: The simulation module of the
      frontotemporal transsylvian exposure helps to examine effect of head positioning 
      on the visibility of deep situated neuroanatomic structures and study surgical
      maneuvers required to achieve optimal exposure of deep situated anatomic
      structures. The simulation program is a powerful tool to study issues of
      preoperative planning and well suited for neurosurgical training.
FAU - Balogh, Attila
AU  - Balogh A
FAU - Czigleczki, Gabor
AU  - Czigleczki G
FAU - Papal, Zsolt
AU  - Papal Z
FAU - Preul, Mark C
AU  - Preul MC
FAU - Banczerowski, Peter
AU  - Banczerowski P
LA  - hun
PT  - English Abstract
PT  - Journal Article
TT  - A frontotemporalis transsylvian feltaras szimulacioja es alkalmazasanak
      ismertetese.
PL  - Hungary
TA  - Ideggyogy Sz
JT  - Ideggyogyaszati szemle
JID - 17510500R
SB  - IM
MH  - Cadaver
MH  - *Cerebral Aqueduct
MH  - *Computer Simulation
MH  - Frontal Lobe/anatomy & histology/*surgery
MH  - Humans
MH  - Imaging, Three-Dimensional
MH  - Neurosurgical Procedures/*methods
MH  - Temporal Lobe/anatomy & histology/*surgery
MH  - User-Computer Interface
EDAT- 2015/02/28 06:00
MHDA- 2015/04/02 06:00
CRDT- 2015/02/28 06:00
PST - ppublish
SO  - Ideggyogy Sz. 2014 Nov 30;67(11-12):376-83.

PMID- 25503366
OWN - NLM
STAT- MEDLINE
DA  - 20141231
DCOM- 20150422
LR  - 20150523
IS  - 1091-6490 (Electronic)
IS  - 0027-8424 (Linking)
VI  - 111
IP  - 52
DP  - 2014 Dec 30
TI  - Cellular resolution optical access to brain regions in fissures: imaging medial
      prefrontal cortex and grid cells in entorhinal cortex.
PG  - 18739-44
LID - 10.1073/pnas.1421753111 [doi]
AB  - In vivo two-photon microscopy provides the foundation for an array of powerful
      techniques for optically measuring and perturbing neural circuits. However,
      challenging tissue properties and geometry have prevented high-resolution optical
      access to regions situated within deep fissures. These regions include the medial
      prefrontal and medial entorhinal cortex (mPFC and MEC), which are of broad
      scientific and clinical interest. Here, we present a method for in vivo,
      subcellular resolution optical access to the mPFC and MEC using microprisms
      inserted into the fissures. We chronically imaged the mPFC and MEC in mice
      running on a spherical treadmill, using two-photon laser-scanning microscopy and 
      genetically encoded calcium indicators to measure network activity. In the MEC,
      we imaged grid cells, a widely studied cell type essential to memory and spatial 
      information processing. These cells exhibited spatially modulated activity during
      navigation in a virtual reality environment. This method should be extendable to 
      other brain regions situated within deep fissures, and opens up these regions for
      study at cellular resolution in behaving animals using a rapidly expanding
      palette of optical tools for perturbing and measuring network structure and
      function.
FAU - Low, Ryan J
AU  - Low RJ
AD  - Princeton Neuroscience Institute, Bezos Center for Neural Circuit Dynamics, and.
FAU - Gu, Yi
AU  - Gu Y
AD  - Princeton Neuroscience Institute, Bezos Center for Neural Circuit Dynamics, and.
FAU - Tank, David W
AU  - Tank DW
AD  - Princeton Neuroscience Institute, Bezos Center for Neural Circuit Dynamics, and
      Department of Molecular Biology, Princeton University, Princeton, NJ 08544
      dwtank@princeton.edu.
LA  - eng
GR  - 5R01MH083686-05/MH/NIMH NIH HHS/United States
GR  - 5R37NS081242-02/NS/NINDS NIH HHS/United States
GR  - R01 MH083686/MH/NIMH NIH HHS/United States
GR  - R37 NS081242/NS/NINDS NIH HHS/United States
GR  - U01 NS090541/NS/NINDS NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
DEP - 20141212
PL  - United States
TA  - Proc Natl Acad Sci U S A
JT  - Proceedings of the National Academy of Sciences of the United States of America
JID - 7505876
SB  - IM
MH  - Animals
MH  - Entorhinal Cortex/*cytology/physiology
MH  - Male
MH  - Mice
MH  - Microscopy, Confocal/methods
MH  - Prefrontal Cortex/*cytology/physiology
PMC - PMC4284609
OID - NLM: PMC4284609
OTO - NOTNLM
OT  - grid cell
OT  - medial entorhinal cortex
OT  - medial prefrontal cortex
OT  - two-photon imaging
EDAT- 2014/12/17 06:00
MHDA- 2015/04/23 06:00
CRDT- 2014/12/16 06:00
PHST- 2014/12/12 [aheadofprint]
AID - 1421753111 [pii]
AID - 10.1073/pnas.1421753111 [doi]
PST - ppublish
SO  - Proc Natl Acad Sci U S A. 2014 Dec 30;111(52):18739-44. doi:
      10.1073/pnas.1421753111. Epub 2014 Dec 12.

PMID- 25419358
OWN - NLM
STAT- PubMed-not-MEDLINE
DA  - 20141124
DCOM- 20141124
LR  - 20141215
IS  - 1940-5901 (Electronic)
IS  - 1940-5901 (Linking)
VI  - 7
IP  - 10
DP  - 2014
TI  - A virtual reality model of the clivus and surgical simulation via transoral or
      transnasal route.
PG  - 3270-9
AB  - BACKGROUND: Neurosurgery in areas with restricted space and complicated anatomy
      can be greatly aided by the virtual reality (VR) technique. The clivus represents
      one of such challenging surgical areas, but its VR has not been established. The 
      present study aimed to document a VR model of clival anatomy that may be useful
      in clival surgery. METHODS: High resolution CT angiography and MRI were used. The
      study included a total of 20 patients who did not have any obvious abnormalities 
      detected in the oral, nasal, and clival areas. The images were fused with a
      Dextroscope. RESULTS: In the VR model, the key structures such as the clival
      bone, basilar artery, brainstem, pituitary gland, and paranasal sinuses were
      clearly observed. The morphology of the clivus and its spatial relationships with
      the neighboring structures were also illustrated. Visualization of the clival
      model can be made flexible from various planes, angles, or orientations. In
      addition, surgical access to the clivus via the transoral route or transnasal
      route was simulated in detail. CONCLUSION: The simulation of the VR model offers 
      a straightforward, three-dimensional, interactive understanding of the size and
      shape of the clivus, and its relationships with the surrounding blood vessels and
      bones. It also demonstrates simulated operational procedures such as opening the 
      surgical window, measuring the exposure distance and angles, and determining the 
      critical boundaries in relation to key structures such as the brainstem and
      arteries. Digitalized VR modeling appears to be helpful for understanding the
      anatomy of the clivus and its surgical approaches.
FAU - Wang, Shou-Sen
AU  - Wang SS
AD  - Department of Neurosurgery, Fuzhou General Hospital, Fujian Medical University
      156 Xihuanbei Road, Fuzhou 350025, China.
FAU - Li, Jun-Feng
AU  - Li JF
AD  - Department of Neurosurgery, Fuzhou General Hospital, Fujian Medical University
      156 Xihuanbei Road, Fuzhou 350025, China.
FAU - Zhang, Shang-Ming
AU  - Zhang SM
AD  - Department of Neurosurgery, Fuzhou General Hospital, Fujian Medical University
      156 Xihuanbei Road, Fuzhou 350025, China.
FAU - Jing, Jun-Jie
AU  - Jing JJ
AD  - Department of Neurosurgery, Fuzhou General Hospital, Fujian Medical University
      156 Xihuanbei Road, Fuzhou 350025, China.
FAU - Xue, Liang
AU  - Xue L
AD  - Department of Neurosurgery, Fuzhou General Hospital, Fujian Medical University
      156 Xihuanbei Road, Fuzhou 350025, China.
LA  - eng
PT  - Journal Article
DEP - 20141015
PL  - United States
TA  - Int J Clin Exp Med
JT  - International journal of clinical and experimental medicine
JID - 101471010
PMC - PMC4238541
OID - NLM: PMC4238541
OTO - NOTNLM
OT  - Clivus
OT  - digitalized anatomical model
OT  - surgical simulation
OT  - transnasal
OT  - transoral
EDAT- 2014/11/25 06:00
MHDA- 2014/11/25 06:01
CRDT- 2014/11/25 06:00
PHST- 2014 [ecollection]
PHST- 2014/08/19 [received]
PHST- 2014/09/20 [accepted]
PHST- 2014/10/15 [epublish]
PST - epublish
SO  - Int J Clin Exp Med. 2014 Oct 15;7(10):3270-9. eCollection 2014.

PMID- 25402854
OWN - NLM
STAT- MEDLINE
DA  - 20141121
DCOM- 20150206
LR  - 20151008
IS  - 1546-1726 (Electronic)
IS  - 1097-6256 (Linking)
VI  - 17
IP  - 12
DP  - 2014 Dec
TI  - Simultaneous cellular-resolution optical perturbation and imaging of place cell
      firing fields.
PG  - 1816-24
LID - 10.1038/nn.3866 [doi]
AB  - Linking neural microcircuit function to emergent properties of the mammalian
      brain requires fine-scale manipulation and measurement of neural activity during 
      behavior, where each neuron's coding and dynamics can be characterized. We
      developed an optical method for simultaneous cellular-resolution stimulation and 
      large-scale recording of neuronal activity in behaving mice. Dual-wavelength
      two-photon excitation allowed largely independent functional imaging with a green
      fluorescent calcium sensor (GCaMP3, lambda = 920 +/- 6 nm) and single-neuron
      photostimulation with a red-shifted optogenetic probe (C1V1, lambda = 1,064 +/- 6
      nm) in neurons coexpressing the two proteins. We manipulated task-modulated
      activity in individual hippocampal CA1 place cells during spatial navigation in a
      virtual reality environment, mimicking natural place-field activity, or
      'biasing', to reveal subthreshold dynamics. Notably, manipulating single
      place-cell activity also affected activity in small groups of other place cells
      that were active around the same time in the task, suggesting a functional role
      for local place cell interactions in shaping firing fields.
FAU - Rickgauer, John Peter
AU  - Rickgauer JP
AD  - 1] Princeton Neuroscience Institute, Princeton University, Princeton, New Jersey,
      USA. [2] Bezos Center for Neural Circuit Dynamics, Princeton University,
      Princeton, New Jersey, USA. [3] Lewis-Sigler Institute for Integrative Genomics, 
      Princeton University, Princeton, New Jersey, USA. [4] Department of Molecular
      Biology, Princeton University, Princeton, New Jersey, USA.
FAU - Deisseroth, Karl
AU  - Deisseroth K
AD  - 1] Department of Bioengineering, Stanford University, Stanford, California, USA. 
      [2] CNC Program, Stanford University, Stanford, California, USA. [3] Department
      of Psychiatry and Behavioral Sciences, Stanford University, Stanford, California,
      USA. [4] Howard Hughes Medical Institute, Stanford University, Stanford,
      California, USA.
FAU - Tank, David W
AU  - Tank DW
AD  - 1] Princeton Neuroscience Institute, Princeton University, Princeton, New Jersey,
      USA. [2] Bezos Center for Neural Circuit Dynamics, Princeton University,
      Princeton, New Jersey, USA. [3] Lewis-Sigler Institute for Integrative Genomics, 
      Princeton University, Princeton, New Jersey, USA. [4] Department of Molecular
      Biology, Princeton University, Princeton, New Jersey, USA.
LA  - eng
GR  - P50-GM071508/GM/NIGMS NIH HHS/United States
GR  - R01 MH075957/MH/NIMH NIH HHS/United States
GR  - R01 MH083686/MH/NIMH NIH HHS/United States
GR  - R01 MH099647/MH/NIMH NIH HHS/United States
GR  - R01-MH083686/MH/NIMH NIH HHS/United States
GR  - U01 NS090541/NS/NINDS NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, U.S. Gov't, Non-P.H.S.
DEP - 20141117
PL  - United States
TA  - Nat Neurosci
JT  - Nature neuroscience
JID - 9809671
SB  - IM
MH  - Animals
MH  - Hippocampus/*cytology/*physiology
MH  - Male
MH  - Mice
MH  - Mice, Inbred C57BL
MH  - Mice, Transgenic
MH  - Neurons/*physiology
MH  - Optogenetics/*methods
MH  - Photic Stimulation/*methods
MH  - Space Perception/*physiology
PMC - PMC4459599
MID - NIHMS695817
OID - NLM: NIHMS695817
OID - NLM: PMC4459599
EDAT- 2014/11/18 06:00
MHDA- 2015/02/07 06:00
CRDT- 2014/11/18 06:00
PHST- 2014/07/16 [received]
PHST- 2014/10/15 [accepted]
PHST- 2014/11/17 [aheadofprint]
AID - nn.3866 [pii]
AID - 10.1038/nn.3866 [doi]
PST - ppublish
SO  - Nat Neurosci. 2014 Dec;17(12):1816-24. doi: 10.1038/nn.3866. Epub 2014 Nov 17.

PMID- 25138097
OWN - NLM
STAT- MEDLINE
DA  - 20140820
DCOM- 20150512
IS  - 1096-9101 (Electronic)
IS  - 0196-8092 (Linking)
VI  - 46
IP  - 7
DP  - 2014 Sep
TI  - An automatic robotic system for three-dimensional tooth crown preparation using a
      picosecond laser.
PG  - 573-81
LID - 10.1002/lsm.22274 [doi]
AB  - BACKGROUND: Laser techniques have been introduced into dentistry to overcome the 
      drawbacks of traditional treatment methods. The existing methods in dental
      clinical operations for tooth crown preparation have several drawbacks which
      affect the long-term success of the dental treatment. OBJECTIVE: To develop an
      improved robotic system to manipulate the laser beam to achieve safe and accurate
      three-dimensional (3D) tooth ablation, and thus to realize automatic tooth crown 
      preparation in clinical operations. METHOD: We present an automatic laser
      ablation system for tooth crown preparation in dental restorative operations. The
      system, combining robotics and laser technology, is developed to control the
      laser focus in three-dimensional motion aiming for high speed and accuracy crown 
      preparation. The system consists of an end-effector, a real-time monitor and a
      tooth fixture. A layer-by-layer ablation method is developed to control the laser
      focus during the crown preparation. Experiments are carried out with picosecond
      laser on wax resin and teeth. RESULTS: The accuracy of the system is satisfying, 
      achieving the average linear errors of 0.06 mm for wax resin and 0.05 mm for
      dentin. The angle errors are 4.33 degrees for wax resin and 0.5 degrees for
      dentin. The depth errors for wax resin and dentin are both within 0.1 mm. The
      ablation time is 1.5 hours for wax resin and 3.5 hours for dentin. CONCLUSIONS:
      The ablation experimental results show that the movement range and the resolution
      of the robotic system can meet the requirements of typical dental operations for 
      tooth crown preparation. Also, the errors of tooth shape and preparation angle
      are able to satisfy the requirements of clinical crown preparation. Although the 
      experimental results illustrate the potential of using picosecond lasers for 3D
      tooth crown preparation, many research issues still need to be studied before the
      system can be applied to clinical operations.
CI  - (c) 2014 Wiley Periodicals, Inc.
FAU - Wang, Lei
AU  - Wang L
AD  - State Key Lab of Virtual Reality Technology and Systems, Beihang University,
      Beijing, China.
FAU - Wang, Dangxiao
AU  - Wang D
FAU - Zhang, Yuru
AU  - Zhang Y
FAU - Ma, Lei
AU  - Ma L
FAU - Sun, Yuchun
AU  - Sun Y
FAU - Lv, Peijun
AU  - Lv P
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - United States
TA  - Lasers Surg Med
JT  - Lasers in surgery and medicine
JID - 8007168
SB  - IM
MH  - Crowns
MH  - Equipment Design
MH  - Humans
MH  - *Lasers
MH  - Robotics/*instrumentation
MH  - Tooth Preparation/*instrumentation/*methods
OTO - NOTNLM
OT  - layer-by-layer ablation
OT  - picosecond laser
OT  - robotic system
OT  - tooth crown preparation
EDAT- 2014/08/21 06:00
MHDA- 2015/05/13 06:00
CRDT- 2014/08/21 06:00
PHST- 2014/06/11 [accepted]
AID - 10.1002/lsm.22274 [doi]
PST - ppublish
SO  - Lasers Surg Med. 2014 Sep;46(7):573-81. doi: 10.1002/lsm.22274.

PMID- 24873098
OWN - NLM
STAT- MEDLINE
DA  - 20140530
DCOM- 20140617
LR  - 20140731
IS  - 0001-6462 (Print)
IS  - 0001-6462 (Linking)
VI  - 80
IP  - 1
DP  - 2014 Mar
TI  - Three-dimensional virtual reality simulation of periarticular tumors using
      Dextroscope reconstruction and simulated surgery: a preliminary 10 case study.
PG  - 132-8
AB  - Dextroscope three-dimensional (3D) imaging has been extensively applied for
      generation of virtual reality (VR) workspaces for in neurosurgery and
      laparoscopy, though few applications in orthopedic surgery have been reported.
      Patients undergoing surgery for periarticular tumors (n = 10) from Oct. 2008 to
      Jun. 2010 were enrolled and presurgically subjected to computed tomography (CT), 
      magnetic resonance imaging (MRI), and MRI angiography (MRI-A). Imaging data was
      transferred and integrated in Dextroscope, producing a VR simulation. Resultant
      presurgical 3D anatomical reconstructions and intraoperative anatomical
      characteristics (virtual vs. actual data) and surgical approach (virtual vs.
      actual situation) measurement and subjective appearance were compared. Anatomical
      characteristics in the area of interest and tumor diameters were consistent
      between virtual and actual data. However, the virtual surgical situations
      remained inconsistent with the actual intraoperative situation in many cases,
      leading to complications. The resolution of original CT, MRI, and MRI-A images
      directly correlated with the quality of 3D simulations, with soft tissues most
      poorly represented. Tumor tissue imaging quality in 3D varied extensively by
      tumor type. CONCLUSIONS: Anatomical structures of periarticular tumors can be
      reconstructed using the Dextroscope system with good accuracy in the case of
      simple fenestration, increasing individualization of treatment, surgical
      competence level, and potentially reducing intraoperative complications. However,
      further specialization of VR tools for use in orthopedic applications that
      involve specialized tools and procedures, such as drilling and implant placement,
      are urgently required.
FAU - Shi, JingSheng
AU  - Shi J
FAU - Xia, Jun
AU  - Xia J
FAU - Wei, YiBing
AU  - Wei Y
FAU - Wang, SiQun
AU  - Wang S
FAU - Wu, JianGuo
AU  - Wu J
FAU - Chen, FeiYan
AU  - Chen F
FAU - Huang, GangYong
AU  - Huang G
FAU - Chen, Jie
AU  - Chen J
LA  - eng
PT  - Journal Article
PL  - Belgium
TA  - Acta Orthop Belg
JT  - Acta orthopaedica Belgica
JID - 2985165R
SB  - IM
MH  - Adult
MH  - Bone Cysts, Aneurysmal/*surgery
MH  - Bone Neoplasms/*surgery
MH  - Female
MH  - Humans
MH  - Imaging, Three-Dimensional
MH  - Magnetic Resonance Angiography
MH  - Magnetic Resonance Imaging
MH  - Male
MH  - Middle Aged
MH  - Tomography, X-Ray Computed
MH  - *User-Computer Interface
MH  - Virtual Reality Exposure Therapy/*methods
EDAT- 2014/05/31 06:00
MHDA- 2014/06/18 06:00
CRDT- 2014/05/31 06:00
PST - ppublish
SO  - Acta Orthop Belg. 2014 Mar;80(1):132-8.

PMID- 24835294
OWN - NLM
STAT- MEDLINE
DA  - 20140519
DCOM- 20140911
IS  - 1824-4785 (Print)
IS  - 1824-4785 (Linking)
VI  - 58
IP  - 2
DP  - 2014 Jun
TI  - The GOSTT concept and hybrid mixed/virtual/augmented reality environment
      radioguided surgery.
PG  - 207-15
AB  - The popularity gained by the sentinel lymph node (SLN) procedure in the last two 
      decades did increase the interest of the surgical disciplines for other
      applications of radioguided surgery. An example is the gamma-probe guided
      localization of occult or difficult to locate neoplastic lesions. Such guidance
      can be achieved by intralesional delivery (ultrasound, stereotaxis or CT) of a
      radiolabelled agent that remains accumulated at the site of the injection.
      Another possibility rested on the use of systemic administration of a
      tumour-seeking radiopharmaceutical with favourable tumour accumulation and
      retention. On the other hand, new intraoperative imaging devices for radioguided 
      surgery in complex anatomical areas became available. All this a few years ago
      led to the delineation of the concept Guided intraOperative Scintigraphic Tumour 
      Targeting (GOSTT) to include the whole spectrum of basic and advanced nuclear
      medicine procedures required for providing a roadmap that would optimise surgery.
      The introduction of allied signatures using, e.g. hybrid tracers for simultaneous
      detection of the radioactive and fluorescent signals did amply the GOSTT concept.
      It was now possible to combine perioperative nuclear medicine imaging with the
      superior resolution of additional optical guidance in the operating room. This
      hybrid approach is currently in progress and probably will become an important
      model to follow in the coming years. A cornerstone in the GOSTT concept is
      constituted by diagnostic imaging technologies like SPECT/CT. SPECT/CT was
      introduced halfway the past decade and was immediately incorporated into the SLN 
      procedure. Important reasons attributing to the success of SPECT/CT were its
      combination with lymphoscintigraphy, and the ability to display SLNs in an
      anatomical environment. This latter aspect has significantly been improved in the
      new generation of SPECT/CT cameras and provides the base for the novel mixed
      reality protocols of image-guided surgery. In these protocols the generated
      virtual SPECT/CT elements are visually superimposed in the body of the patient in
      the operating room to directly facilitate, by means of visualization on screen or
      using head-mounted devices, the localization of radioactive and/or fluorescent
      targets by minimal invasive approaches in areas of complex anatomy. All these
      technological advances will play an increasing role in the future extension and
      the clinical impact of the GOSTT concept.
FAU - Valdes Olmos, R A
AU  - Valdes Olmos RA
AD  - Diagnostic Oncology, Department of Nuclear Medicine, Netherlands Cancer Institute
      - Antoni van Leuwenhoek Hospital Amsterdam, The Netherlands - r.valdes@nki.nl.
FAU - Vidal-Sicart, S
AU  - Vidal-Sicart S
FAU - Giammarile, F
AU  - Giammarile F
FAU - Zaknun, J J
AU  - Zaknun JJ
FAU - Van Leeuwen, F W
AU  - Van Leeuwen FW
FAU - Mariani, G
AU  - Mariani G
LA  - eng
PT  - Journal Article
PT  - Review
PL  - Italy
TA  - Q J Nucl Med Mol Imaging
JT  - The quarterly journal of nuclear medicine and molecular imaging : official
      publication of the Italian Association of Nuclear Medicine (AIMN) [and] the
      International Association of Radiopharmacology (IAR), [and] Section of the
      Society of Radiopharmaceutical Chemistry and Biology
JID - 101213861
SB  - IM
MH  - Evidence-Based Medicine
MH  - Female
MH  - Humans
MH  - Image-Guided Biopsy/*methods
MH  - Lymph Nodes/pathology/surgery
MH  - Lymphatic Metastasis
MH  - Male
MH  - Multimodal Imaging/methods
MH  - Neoplasms/*diagnosis/*surgery
MH  - Reproducibility of Results
MH  - Sensitivity and Specificity
MH  - Sentinel Lymph Node Biopsy/*methods
MH  - Surgery, Computer-Assisted/*methods
MH  - Tomography, Emission-Computed, Single-Photon/*methods
MH  - *User-Computer Interface
EDAT- 2014/05/20 06:00
MHDA- 2014/09/12 06:00
CRDT- 2014/05/20 06:00
AID - R39Y2014N02A0207 [pii]
PST - ppublish
SO  - Q J Nucl Med Mol Imaging. 2014 Jun;58(2):207-15.

PMID- 24834973
OWN - NLM
STAT- MEDLINE
DA  - 20140520
DCOM- 20150115
IS  - 1741-2552 (Electronic)
IS  - 1741-2552 (Linking)
VI  - 11
IP  - 3
DP  - 2014 Jun
TI  - Controlling an avatar by thought using real-time fMRI.
PG  - 035006
LID - 10.1088/1741-2560/11/3/035006 [doi]
AB  - OBJECTIVE: We have developed a brain-computer interface (BCI) system based on
      real-time functional magnetic resonance imaging (fMRI) with virtual reality
      feedback. The advantage of fMRI is the relatively high spatial resolution and the
      coverage of the whole brain; thus we expect that it may be used to explore novel 
      BCI strategies, based on new types of mental activities. However, fMRI suffers
      from a low temporal resolution and an inherent delay, since it is based on a
      hemodynamic response rather than electrical signals. Thus, our objective in this 
      paper was to explore whether subjects could perform a BCI task in a virtual
      environment using our system, and how their performance was affected by the
      delay. APPROACH: The subjects controlled an avatar by left-hand, right-hand and
      leg motion or imagery. The BCI classification is based on locating the regions of
      interest (ROIs) related with each of the motor classes, and selecting the ROI
      with maximum average values online. The subjects performed a cue-based task and a
      free-choice task, and the analysis includes evaluation of the performance as well
      as subjective reports. MAIN RESULTS: Six subjects performed the task with high
      accuracy when allowed to move their fingers and toes, and three subjects achieved
      high accuracy using imagery alone. In the cue-based task the accuracy was highest
      8-12 s after the trigger, whereas in the free-choice task the subjects performed 
      best when the feedback was provided 6 s after the trigger. SIGNIFICANCE: We show 
      that subjects are able to perform a navigation task in a virtual environment
      using an fMRI-based BCI, despite the hemodynamic delay. The same approach can be 
      extended to other mental tasks and other brain areas.
FAU - Cohen, Ori
AU  - Cohen O
AD  - The Interdisciplinary Center Herzliya, 46150, Israel. Bar-Ilan University,
      Ramat-Gan 52900, Israel.
FAU - Koppel, Moshe
AU  - Koppel M
FAU - Malach, Rafael
AU  - Malach R
FAU - Friedman, Doron
AU  - Friedman D
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20140519
PL  - England
TA  - J Neural Eng
JT  - Journal of neural engineering
JID - 101217933
SB  - IM
MH  - Adult
MH  - Algorithms
MH  - Brain Mapping/*methods
MH  - *Brain-Computer Interfaces
MH  - Computer Systems
MH  - Evoked Potentials, Motor/*physiology
MH  - Female
MH  - Humans
MH  - Image Interpretation, Computer-Assisted/methods
MH  - Imagination/*physiology
MH  - Magnetic Resonance Imaging/methods
MH  - Male
MH  - Movement
MH  - Robotics/*methods
MH  - Spatial Navigation/*physiology
MH  - Thinking/physiology
MH  - *User-Computer Interface
EDAT- 2014/05/20 06:00
MHDA- 2015/01/16 06:00
CRDT- 2014/05/20 06:00
PHST- 2014/05/19 [aheadofprint]
AID - 10.1088/1741-2560/11/3/035006 [doi]
PST - ppublish
SO  - J Neural Eng. 2014 Jun;11(3):035006. doi: 10.1088/1741-2560/11/3/035006. Epub
      2014 May 19.

PMID- 24808058
OWN - NLM
STAT- PubMed-not-MEDLINE
DA  - 20140508
DCOM- 20150330
IS  - 1558-1756 (Electronic)
IS  - 0272-1716 (Linking)
VI  - 33
IP  - 4
DP  - 2013 Jul-Aug
TI  - Visualizing large, heterogeneous data in hybrid-reality environments.
PG  - 38-48
LID - 10.1109/MCG.2013.37 [doi]
AB  - Constructing integrative visualizations that simultaneously cater to a variety of
      data types is challenging. Hybrid-reality environments blur the line between
      virtual environments and tiled display walls. They incorporate high-resolution,
      stereoscopic displays, which can be used to juxtapose large, heterogeneous
      datasets while providing a range of naturalistic interaction schemes. They thus
      empower designers to construct integrative visualizations that more effectively
      mash up 2D, 3D, temporal, and multivariate datasets.
FAU - Reda, Khairi
AU  - Reda K
FAU - Febretti, Alessandro
AU  - Febretti A
FAU - Knoll, Aaron
AU  - Knoll A
FAU - Aurisano, Jillian
AU  - Aurisano J
FAU - Leigh, Jason
AU  - Leigh J
FAU - Johnson, Andrew
AU  - Johnson A
FAU - Papka, Michael E
AU  - Papka ME
FAU - Hereld, Mark
AU  - Hereld M
LA  - eng
PT  - Journal Article
PT  - Research Support, U.S. Gov't, Non-P.H.S.
PL  - United States
TA  - IEEE Comput Graph Appl
JT  - IEEE computer graphics and applications
JID - 9881869
EDAT- 2014/05/09 06:00
MHDA- 2014/05/09 06:01
CRDT- 2014/05/09 06:00
AID - 10.1109/MCG.2013.37 [doi]
PST - ppublish
SO  - IEEE Comput Graph Appl. 2013 Jul-Aug;33(4):38-48. doi: 10.1109/MCG.2013.37.

PMID- 24650983
OWN - NLM
STAT- In-Data-Review
DA  - 20140321
IS  - 1941-0506 (Electronic)
IS  - 1077-2626 (Linking)
VI  - 20
IP  - 4
DP  - 2014 Apr
TI  - FlyAR: augmented reality supported micro aerial vehicle navigation.
PG  - 560-8
LID - 10.1109/TVCG.2014.24 [doi]
AB  - Micro aerial vehicles equipped with high-resolution cameras can be used to create
      aerial reconstructions of an area of interest. In that context automatic flight
      path planning and autonomous flying is often applied but so far cannot fully
      replace the human in the loop, supervising the flight on-site to assure that
      there are no collisions with obstacles. Unfortunately, this workflow yields
      several issues, such as the need to mentally transfer the aerial vehicle&#146;s
      position between 2D map positions and the physical environment, and the
      complicated depth perception of objects flying in the distance. Augmented Reality
      can address these issues by bringing the flight planning process on-site and
      visualizing the spatial relationship between the planned or current positions of 
      the vehicle and the physical environment. In this paper, we present Augmented
      Reality supported navigation and flight planning of micro aerial vehicles by
      augmenting the user&#146;s view with relevant information for flight planning and
      live feedback for flight supervision. Furthermore, we introduce additional depth 
      hints supporting the user in understanding the spatial relationship of virtual
      waypoints in the physical world and investigate the effect of these visualization
      techniques on the spatial understanding.
FAU - Zollmann, Stefanie
AU  - Zollmann S
AD  - University of Technology.
FAU - Hoppe, Christof
AU  - Hoppe C
AD  - University of Technology.
FAU - Langlotz, Tobias
AU  - Langlotz T
AD  - University of Technology.
FAU - Reitmayr, Gerhard
AU  - Reitmayr G
AD  - University of Technology.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - United States
TA  - IEEE Trans Vis Comput Graph
JT  - IEEE transactions on visualization and computer graphics
JID - 9891704
SB  - IM
EDAT- 2014/03/22 06:00
MHDA- 2014/03/22 06:00
CRDT- 2014/03/22 06:00
AID - 10.1109/TVCG.2014.24 [doi]
PST - ppublish
SO  - IEEE Trans Vis Comput Graph. 2014 Apr;20(4):560-8. doi: 10.1109/TVCG.2014.24.

PMID- 24390978
OWN - NLM
STAT- MEDLINE
DA  - 20141216
DCOM- 20150921
IS  - 1478-596X (Electronic)
IS  - 1478-5951 (Linking)
VI  - 10
IP  - 4
DP  - 2014 Dec
TI  - Preliminary study on a miniature laser manipulation robotic device for tooth
      crown preparation.
PG  - 482-94
LID - 10.1002/rcs.1560 [doi]
AB  - BACKGROUND: The existing methods in dental clinical operations for hard tissue
      removal have several drawbacks which affect the long-term success of the dental
      treatment. METHODS: In this paper, we introduce a miniature robotic device called
      LaserBot, which can manipulate a femtosecond laser beam to drill/burr a decayed
      tooth to realize clinical tooth crown preparation. In order to control the 3D
      motion of the laser focal point on the surface of a tooth, three miniature
      voice-coil motors with optical grating rulers are utilized to drive the 2D
      pitch/yaw rotation of a vibration mirror and 1D translation of a protruding
      optical lens. This method can provide high-resolution control of the laser beam. 
      In order to maintain the small size of the robot, a parallel five linkage
      mechanism combined with a slider-rocker mechanism is developed to realize 2D
      pitch/yaw rotation of the vibration mirror. RESULTS: Experiment results show that
      the movement range and resolution of the laser beam point can meet the
      requirement of typical dental operations. The size of the working end of the
      device that enters the mouth is 25 x 22 x 57 mm (height x width x length), which 
      is small enough to be mounted on any tooth. The average repeatability error of
      the laser focal point is about 40 microm. Ablation experiments on wax-resin
      material and on tooth validate that a femtosecond laser can be used for tooth
      ablation. CONCLUSIONS: The developed robotic device achieved precise 3D motion
      control of a laser focal point and is small enough to be used in the narrow
      workspace of the oral cavity. Limitations of the prototype have been identified, 
      and quantified specifications are identified for designing the next generation
      prototype.
CI  - Copyright (c) 2014 John Wiley & Sons, Ltd.
FAU - Wang, Dangxiao
AU  - Wang D
AD  - State Key Lab of Virtual Reality Technology and Systems, Beihang University,
      Beijing, 100191, China.
FAU - Wang, Lei
AU  - Wang L
FAU - Zhang, Yuru
AU  - Zhang Y
FAU - Lv, Peijun
AU  - Lv P
FAU - Sun, Yuchun
AU  - Sun Y
FAU - Xiao, Jing
AU  - Xiao J
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20140106
PL  - England
TA  - Int J Med Robot
JT  - The international journal of medical robotics + computer assisted surgery : MRCAS
JID - 101250764
SB  - IM
MH  - Biomechanical Phenomena
MH  - *Crowns
MH  - Humans
MH  - *Lasers
MH  - Robotic Surgical Procedures/*instrumentation
OTO - NOTNLM
OT  - femtosecond laser
OT  - miniature robotic device
OT  - optical transfer model
OT  - tooth crown preparation
EDAT- 2014/01/07 06:00
MHDA- 2015/09/22 06:00
CRDT- 2014/01/07 06:00
PHST- 2013/06/25 [received]
PHST- 2013/10/30 [revised]
PHST- 2013/10/31 [accepted]
PHST- 2014/01/06 [aheadofprint]
AID - 10.1002/rcs.1560 [doi]
PST - ppublish
SO  - Int J Med Robot. 2014 Dec;10(4):482-94. doi: 10.1002/rcs.1560. Epub 2014 Jan 6.

PMID- 24163637
OWN - NLM
STAT- PubMed-not-MEDLINE
DA  - 20131028
DCOM- 20140502
IS  - 1537-744X (Electronic)
IS  - 1537-744X (Linking)
VI  - 2013
DP  - 2013
TI  - Aircraft detection from VHR images based on circle-frequency filter and
      multilevel features.
PG  - 917928
LID - 10.1155/2013/917928 [doi]
AB  - Aircraft automatic detection from very high-resolution (VHR) images plays an
      important role in a wide variety of applications. This paper proposes a novel
      detector for aircraft detection from very high-resolution (VHR) remote sensing
      images. To accurately distinguish aircrafts from background, a circle-frequency
      filter (CF-filter) is used to extract the candidate locations of aircrafts from a
      large size image. A multi-level feature model is then employed to represent both 
      local appearance and spatial layout of aircrafts by means of Robust Hue
      Descriptor and Histogram of Oriented Gradients. The experimental results
      demonstrate the superior performance of the proposed method.
FAU - Gao, Feng
AU  - Gao F
AD  - Beijing Key Laboratory of Digital Media, School of Computer Science and
      Engineering, Beihang University, Beijing 100191, China ; State Key Laboratory of 
      Virtual Reality Technology and Systems, Beihang University, Beijing 100191,
      China.
FAU - Xu, Qizhi
AU  - Xu Q
FAU - Li, Bo
AU  - Li B
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20130915
PL  - England
TA  - ScientificWorldJournal
JT  - TheScientificWorldJournal
JID - 101131163
PMC - PMC3791842
OID - NLM: PMC3791842
EDAT- 2013/10/29 06:00
MHDA- 2013/10/29 06:01
CRDT- 2013/10/29 06:00
PHST- 2013 [ecollection]
PHST- 2013/07/16 [received]
PHST- 2013/08/07 [accepted]
PHST- 2013/09/15 [epublish]
AID - 10.1155/2013/917928 [doi]
PST - epublish
SO  - ScientificWorldJournal. 2013 Sep 15;2013:917928. doi: 10.1155/2013/917928.
      eCollection 2013.

PMID- 23932623
OWN - NLM
STAT- MEDLINE
DA  - 20130812
DCOM- 20140414
IS  - 1531-5037 (Electronic)
IS  - 0022-3468 (Linking)
VI  - 48
IP  - 8
DP  - 2013 Aug
TI  - 3D virtual rendering before laparoscopic partial splenectomy in children.
PG  - 1784-8
LID - 10.1016/j.jpedsurg.2013.06.011 [doi]
LID - S0022-3468(13)00524-1 [pii]
AB  - INTRODUCTION: Partial splenectomy in children is a good surgical option for
      hematological diseases and focal splenic tumors because it allows the
      preservation of the spleen's immunological function. Furthermore, it can be
      performed by laparoscopy in children as it is a safe procedure, offering the
      benefits of a minimally invasive approach. MATERIALS AND METHODS: The software
      VR-render LE version 0.81 is a system that enables the visualization of
      bidimentional 3D images with magnification of anatomical details. We have applied
      this system to five cases of non-parasitic splenic cysts before laparoscopic
      partial splenectomy. RESULTS: The images obtained with VR rendering software
      permitted the preoperative reconstruction of the vascularization of the splenic
      hilum, allowing the surgeon safe vessel control during laparoscopic procedures.
      All five partial splenectomies were carried out with no complications or major
      blood loss. CONCLUSIONS: Laparoscopic partial splenectomy should be a first
      choice procedure because it is feasible, reproducible, and safe for children;
      furthermore, it preserves enough splenic tissue thereby preventing
      post-splenectomy infections. Volume rendering provides high anatomical resolution
      and can be useful in guiding the surgical procedure.
CI  - (c) 2013.
FAU - Lima, Mario
AU  - Lima M
AD  - Department of Pediatric Surgery, University of Bologna, Bologna 40138, Italy.
      mario.lima@unibo.it
FAU - Reinberg, Olivier
AU  - Reinberg O
FAU - Ruggeri, Giovanni
AU  - Ruggeri G
FAU - De Buys Roessingh, Anthony Stephan
AU  - De Buys Roessingh AS
FAU - Gargano, Tommaso
AU  - Gargano T
FAU - Soler, Luc
AU  - Soler L
FAU - Mogiatti, Mirella
AU  - Mogiatti M
FAU - Cantone, Noemi
AU  - Cantone N
LA  - eng
PT  - Evaluation Studies
PT  - Journal Article
PL  - United States
TA  - J Pediatr Surg
JT  - Journal of pediatric surgery
JID - 0052631
SB  - IM
MH  - Adolescent
MH  - Child
MH  - Cysts/pathology/radiography/*surgery
MH  - Female
MH  - Humans
MH  - *Imaging, Three-Dimensional
MH  - Laparoscopy/*methods
MH  - Length of Stay/statistics & numerical data
MH  - Male
MH  - *Multimodal Imaging
MH  - Organ Size
MH  - Preoperative Care/*methods
MH  - Retrospective Studies
MH  - Splenectomy/*methods
MH  - Splenic Diseases/pathology/radiography/*surgery
MH  - *Tomography, X-Ray Computed
MH  - *User-Computer Interface
OTO - NOTNLM
OT  - Augmented reality
OT  - Laparoscopy partial splenectomies
OT  - Virtual rendering
EDAT- 2013/08/13 06:00
MHDA- 2014/04/15 06:00
CRDT- 2013/08/13 06:00
PHST- 2012/11/13 [received]
PHST- 2013/06/08 [revised]
PHST- 2013/06/10 [accepted]
AID - S0022-3468(13)00524-1 [pii]
AID - 10.1016/j.jpedsurg.2013.06.011 [doi]
PST - ppublish
SO  - J Pediatr Surg. 2013 Aug;48(8):1784-8. doi: 10.1016/j.jpedsurg.2013.06.011.

PMID- 23851748
OWN - NLM
STAT- MEDLINE
DA  - 20130715
DCOM- 20150810
IS  - 1536-3732 (Electronic)
IS  - 1049-2275 (Linking)
VI  - 24
IP  - 4
DP  - 2013 Jul
TI  - Computer-aided design and manufacturing in craniosynostosis surgery.
PG  - 1100-5
LID - 10.1097/SCS.0b013e31828b7021 [doi]
AB  - BACKGROUND: Considerable operative time is expended during the planning, shaping,
      and reconfiguring of the cranial vault in the pursuit of symmetry during open
      craniosynostosis surgery. Computer-aided design and manufacturing has recently
      been implemented in orthognathic surgery and complex craniomaxillofacial
      reconstruction as a means of optimizing operative accuracy and efficiency. In
      this report, we highlight our growing experience with this promising modality for
      the preoperative planning and intraoperative execution of cranial vault
      remodeling in patients with both simple and complex forms of craniosynostosis.
      METHODS: Computer-assisted surgical planning begins with acquisition of
      high-resolution computed tomography scans of the craniofacial skeleton. An
      Internet-based teleconference is then held between the craniofacial and
      biomedical engineering teams and provides a forum for virtual manipulation of the
      patient's preoperative three-dimensional computed tomography with real-time
      changes and feedback. Through virtual surgical planning, osteotomies are designed
      and calvarial bones reconfigured to achieve the desired cranial vault appearance.
      Cutting and positioning guides are manufactured to transform the virtual plan
      into a reality. RESULTS: From February to March 2012, 4 children (aged 9 months
      to 6 years) with craniosynostosis underwent computer-assisted simulation and
      surgery. Diagnoses included metopic, unicoronal (n = 2), and multisutural
      synostoses (sagittal and left unicoronal). Open craniofacial repairs were
      performed as virtually planned, including front o-orbital remodeling,
      fronto-orbital advancement, and anterior two-thirds calvarial remodeling,
      respectively. Cutting and final positioning guides demonstrated excellent
      fidelity and ease of use. CONCLUSIONS: Computer-aided design and manufacturing
      may offer a platform for optimizing operative efficiency, precision, and accuracy
      in craniosynostosis surgery, while accelerating the learning curve for future
      trainees.
FAU - Seruya, Mitchel
AU  - Seruya M
AD  - Department of Plastic and Maxillofacial Surgery, Royal Children's Hospital,
      Melbourne, Victoria, Australia. adorafs1@jhmi.edu
FAU - Borsuk, Daniel E
AU  - Borsuk DE
FAU - Khalifian, Saami
AU  - Khalifian S
FAU - Carson, Benjamin S
AU  - Carson BS
FAU - Dalesio, Nicholas M
AU  - Dalesio NM
FAU - Dorafshar, Amir H
AU  - Dorafshar AH
LA  - eng
PT  - Journal Article
PL  - United States
TA  - J Craniofac Surg
JT  - The Journal of craniofacial surgery
JID - 9010410
SB  - D
MH  - Child
MH  - Child, Preschool
MH  - *Computer-Aided Design
MH  - Craniosynostoses/radiography/*surgery
MH  - Female
MH  - Humans
MH  - Image Processing, Computer-Assisted/methods
MH  - Infant
MH  - Male
MH  - Osteotomy/methods
MH  - Patient Care Planning
MH  - Reconstructive Surgical Procedures/*methods
MH  - Tomography, X-Ray Computed/methods
EDAT- 2013/07/16 06:00
MHDA- 2015/08/11 06:00
CRDT- 2013/07/16 06:00
AID - 10.1097/SCS.0b013e31828b7021 [doi]
AID - 00001665-201307000-00012 [pii]
PST - ppublish
SO  - J Craniofac Surg. 2013 Jul;24(4):1100-5. doi: 10.1097/SCS.0b013e31828b7021.

PMID- 23831480
OWN - NLM
STAT- MEDLINE
DA  - 20131111
DCOM- 20140627
IS  - 1873-5126 (Electronic)
IS  - 1353-8020 (Linking)
VI  - 19
IP  - 11
DP  - 2013 Nov
TI  - Using virtual reality to explore the role of conflict resolution and
      environmental salience in freezing of gait in Parkinson's disease.
PG  - 937-42
LID - 10.1016/j.parkreldis.2013.06.002 [doi]
LID - S1353-8020(13)00220-4 [pii]
AB  - BACKGROUND: The freezing phenomenon is among the most disabling symptoms of
      Parkinson's disease (PD) manifesting most commonly as Freezing of Gait with a
      paroxysmal cessation of effective stepping. Recent studies have suggested that
      freezing is related to both impairments in conflict resolution as well as the
      processing of environmentally salient information. METHODS: In this study, we
      utilized a virtual reality gait paradigm to investigate differences in motor
      outflow between PD patients with (n = 36) and without (n = 37) Freezing of Gait, 
      as well as age-matched healthy controls (n = 18). Subjects were required to
      navigate a realistic on-screen environment with the use of foot pedals to
      simulate stepping whilst responding to either cues associated with conflict
      resolution (congruent 'Red', 'Green' or 'Blue') or environmental salience (wide, 
      narrow and sliding doorways). Footstep latency was used as a measure of motor
      output. RESULTS: Significantly increased stepping latencies were observed in
      freezers compared to non-freezers (p = 0.004) and controls (p = 0.016) in
      response to stimuli requiring the inhibition of implicitly cued behavior ('red'
      cue). Patients with Freezing of Gait also demonstrated increased motor latency
      compared to non-freezers and controls specifically in response to environmentally
      salient triggers including narrow doorways (p = 0.03 and 0.01 respectively) and
      the opening of a sliding door (p = 0.036 and 0.048 respectively). Performance on 
      the paradigm in relation to these triggers correlated significantly with
      self-reported freezing severity. CONCLUSION: These results suggest that deficits 
      in conflict resolution and visuospatial processing may reflect some of the neural
      mechanisms associated with freezing behavior and that these can be probed in a
      virtual reality environment.
CI  - Copyright (c) 2013 The Authors. Published by Elsevier Ltd.. All rights reserved.
FAU - Matar, Elie
AU  - Matar E
AD  - Parkinson's Disease Research Clinic, Brain and Mind Research Institute,
      University of Sydney, Level 4, Building F, 94 Mallett St, Camperdown, New South
      Wales 2050, Australia.
FAU - Shine, James M
AU  - Shine JM
FAU - Naismith, Sharon L
AU  - Naismith SL
FAU - Lewis, Simon J G
AU  - Lewis SJ
LA  - eng
PT  - Journal Article
PT  - Randomized Controlled Trial
PT  - Research Support, Non-U.S. Gov't
DEP - 20130704
PL  - England
TA  - Parkinsonism Relat Disord
JT  - Parkinsonism & related disorders
JID - 9513583
SB  - IM
MH  - Aged
MH  - *Environment
MH  - Female
MH  - Gait Disorders, Neurologic/diagnosis/psychology/*therapy
MH  - Humans
MH  - Male
MH  - Middle Aged
MH  - Negotiating/*methods/psychology
MH  - Parkinson Disease/diagnosis/psychology/*therapy
MH  - Photic Stimulation/methods
MH  - Reaction Time/physiology
MH  - *Spatial Behavior/physiology
MH  - Virtual Reality Exposure Therapy/*methods
OTO - NOTNLM
OT  - Conflict resolution
OT  - Environmental salience
OT  - Freezing of Gait
OT  - Parkinson's disease
OT  - Virtual reality
OT  - Visuospatial processing
EDAT- 2013/07/09 06:00
MHDA- 2014/06/28 06:00
CRDT- 2013/07/09 06:00
PHST- 2012/12/13 [received]
PHST- 2013/05/28 [revised]
PHST- 2013/06/10 [accepted]
PHST- 2013/07/04 [aheadofprint]
AID - S1353-8020(13)00220-4 [pii]
AID - 10.1016/j.parkreldis.2013.06.002 [doi]
PST - ppublish
SO  - Parkinsonism Relat Disord. 2013 Nov;19(11):937-42. doi:
      10.1016/j.parkreldis.2013.06.002. Epub 2013 Jul 4.

PMID- 23797283
OWN - NLM
STAT- MEDLINE
DA  - 20130909
DCOM- 20140401
IS  - 1558-0210 (Electronic)
IS  - 1534-4320 (Linking)
VI  - 21
IP  - 5
DP  - 2013 Sep
TI  - A post-stroke rehabilitation system integrating robotics, VR and high-resolution 
      EEG imaging.
PG  - 849-59
LID - 10.1109/TNSRE.2013.2267851 [doi]
AB  - We propose a system for the neuro-motor rehabilitation of upper limbs in stroke
      survivors. The system is composed of a passive robotic device (Trackhold) for
      kinematic tracking and gravity compensation, five dedicated virtual reality (VR) 
      applications for training of distinct movement patterns, and high-resolution EEG 
      for synchronous monitoring of cortical activity. In contrast to active devices,
      the Trackhold omits actuators for increased patient safety and acceptance levels,
      and for reduced complexity and costs. VR applications present all relevant
      information for task execution as easy-to-understand graphics that do not need
      any written or verbal instructions. High-resolution electroencephalography
      (HR-EEG) is synchronized with kinematic data acquisition, allowing for the
      epoching of EEG signals on the basis of movement-related temporal events. Two
      healthy volunteers participated in a feasibility study and performed a protocol
      suggested for the rehabilitation of post-stroke patients. Kinematic data were
      analyzed by means of in-house code. Open source packages (EEGLAB, SPM, and GMAC) 
      and in-house code were used to process the neurological data. Results from
      kinematic and EEG data analysis are in line with knowledge from currently
      available literature and theoretical predictions, and demonstrate the feasibility
      and potential usefulness of the proposed rehabilitation system to monitor
      neuro-motor recovery.
FAU - Steinisch, Martin
AU  - Steinisch M
FAU - Tana, Maria Gabriella
AU  - Tana MG
FAU - Comani, Silvia
AU  - Comani S
LA  - eng
PT  - Journal Article
DEP - 20130618
PL  - United States
TA  - IEEE Trans Neural Syst Rehabil Eng
JT  - IEEE transactions on neural systems and rehabilitation engineering : a
      publication of the IEEE Engineering in Medicine and Biology Society
JID - 101097023
SB  - IM
MH  - Algorithms
MH  - Biomechanical Phenomena
MH  - Brain/physiopathology
MH  - Brain Mapping
MH  - Data Interpretation, Statistical
MH  - Electroencephalography/*instrumentation/*methods
MH  - Female
MH  - Gravitation
MH  - Humans
MH  - Male
MH  - Middle Aged
MH  - Monitoring, Physiologic
MH  - Psychomotor Performance/physiology
MH  - *Robotics
MH  - Stroke/physiopathology/*rehabilitation
MH  - Upper Extremity/physiology
MH  - *User-Computer Interface
MH  - Young Adult
EDAT- 2013/06/26 06:00
MHDA- 2014/04/02 06:00
CRDT- 2013/06/26 06:00
PHST- 2013/06/18 [aheadofprint]
AID - 10.1109/TNSRE.2013.2267851 [doi]
PST - ppublish
SO  - IEEE Trans Neural Syst Rehabil Eng. 2013 Sep;21(5):849-59. doi:
      10.1109/TNSRE.2013.2267851. Epub 2013 Jun 18.

PMID- 23766395
OWN - NLM
STAT- MEDLINE
DA  - 20130902
DCOM- 20131031
LR  - 20131121
IS  - 1538-6724 (Electronic)
IS  - 0031-9023 (Linking)
VI  - 93
IP  - 9
DP  - 2013 Sep
TI  - Returning service members to duty following mild traumatic brain injury:
      exploring the use of dual-task and multitask assessment methods.
PG  - 1254-67
LID - 10.2522/ptj.20120143 [doi]
AB  - Within the last decade, more than 220,000 service members have sustained
      traumatic brain injury (TBI) in support of military operations in Iraq and
      Afghanistan. Mild TBI may result in subtle cognitive and sensorimotor deficits
      that adversely affect warfighter performance, creating significant challenges for
      service members, commanders, and clinicians. In recent conflicts, physical
      therapists and occupational therapists have played an important role in
      evaluating service member readiness to return to duty (RTD), incorporating
      research and best practices from the sports concussion literature. Because
      premorbid (baseline) performance metrics are not typically available for deployed
      service members as for athletes, clinicians commonly determine duty readiness
      based upon the absence of postconcussive symptoms and return to "normal"
      performance on clinical assessments not yet validated in the military population.
      Although practices described in the sports concussion literature guide
      "return-to-play" determinations, resolution of symptoms or improvement of
      isolated impairments may be inadequate to predict readiness in a military
      operational environment. Existing clinical metrics informing RTD decision making 
      are limited because they fail to emphasize functional, warrior task demands and
      they lack versatility to assess the effects of comorbid deficits. Recently, a
      number of complex task-oriented RTD approaches have emerged from Department of
      Defense laboratory and clinical settings to address this gap. Immersive virtual
      reality environments, field-based scenario-driven assessment programs, and
      militarized dual-task and multitask-based approaches have all been proposed for
      the evaluation of sensorimotor and cognitive function following TBI. There
      remains a need for clinically feasible assessment methods that can be used to
      verify functional performance and operational competence in a variety of practice
      settings. Complex and ecologically valid assessment techniques incorporating
      dual-task and multitask methods may prove useful in validating return-to-activity
      requirements in civilian and military populations.
FAU - Scherer, Matthew R
AU  - Scherer MR
AD  - Military Performance Division, US Army Research Institute of Environmental
      Medicine, 15 Kansas St, Natick, MA 01760, USA. matthew.scherer@us.army.mil
FAU - Weightman, Margaret M
AU  - Weightman MM
FAU - Radomski, Mary V
AU  - Radomski MV
FAU - Davidson, Leslie F
AU  - Davidson LF
FAU - McCulloch, Karen L
AU  - McCulloch KL
LA  - eng
PT  - Journal Article
PT  - Research Support, U.S. Gov't, Non-P.H.S.
DEP - 20130613
PL  - United States
TA  - Phys Ther
JT  - Physical therapy
JID - 0022623
SB  - AIM
SB  - IM
MH  - Afghan Campaign 2001-
MH  - Brain Concussion/*rehabilitation
MH  - Disabled Persons/*rehabilitation
MH  - Female
MH  - Humans
MH  - Iraq War, 2003-2011
MH  - Male
MH  - *Military Personnel
MH  - Neuropsychological Tests
MH  - *Physical Therapy Modalities
MH  - *Recovery of Function
MH  - *Return to Work
MH  - United States
EDAT- 2013/06/15 06:00
MHDA- 2013/11/01 06:00
CRDT- 2013/06/15 06:00
PHST- 2013/06/13 [aheadofprint]
PHST- 2013/06/27 [aheadofprint]
AID - ptj.20120143 [pii]
AID - 10.2522/ptj.20120143 [doi]
PST - ppublish
SO  - Phys Ther. 2013 Sep;93(9):1254-67. doi: 10.2522/ptj.20120143. Epub 2013 Jun 13.

PMID- 23465646
OWN - NLM
STAT- MEDLINE
DA  - 20130930
DCOM- 20140505
IS  - 1873-4758 (Electronic)
IS  - 0955-3959 (Linking)
VI  - 24
IP  - 5
DP  - 2013 Sep
TI  - 'Silk Road', the virtual drug marketplace: a single case study of user
      experiences.
PG  - 385-91
LID - 10.1016/j.drugpo.2013.01.005 [doi]
LID - S0955-3959(13)00006-6 [pii]
AB  - BACKGROUND: The online promotion of 'drug shopping' and user information networks
      is of increasing public health and law enforcement concern. An online drug
      marketplace called 'Silk Road' has been operating on the 'Deep Web' since
      February 2011 and was designed to revolutionise contemporary drug consumerism.
      METHODS: A single case study approach explored a 'Silk Road' user's motives for
      online drug purchasing, experiences of accessing and using the website, drug
      information sourcing, decision making and purchasing, outcomes and settings for
      use, and perspectives around security. The participant was recruited following a 
      lengthy relationship building phase on the 'Silk Road' chat forum. RESULTS: The
      male participant described his motives, experiences of purchasing processes and
      drugs used from 'Silk Road'. Consumer experiences on 'Silk Road' were described
      as 'euphoric' due to the wide choice of drugs available, relatively easy once
      navigating the Tor Browser (encryption software) and using 'Bitcoins' for
      transactions, and perceived as safer than negotiating illicit drug markets.
      Online researching of drug outcomes, particularly for new psychoactive substances
      was reported. Relationships between vendors and consumers were described as based
      on cyber levels of trust and professionalism, and supported by 'stealth modes',
      user feedback and resolution modes. The reality of his drug use was described as 
      covert and solitary with psychonautic characteristics, which contrasted with his 
      membership, participation and feelings of safety within the 'Silk Road'
      community. CONCLUSION: 'Silk Road' as online drug marketplace presents an
      interesting displacement away from 'traditional' online and street sources of
      drug supply. Member support and harm reduction ethos within this virtual
      community maximises consumer decision-making and positive drug experiences, and
      minimises potential harms and consumer perceived risks. Future research is
      necessary to explore experiences and backgrounds of other users.
CI  - Copyright (c) 2013 Elsevier B.V. All rights reserved.
FAU - Van Hout, Marie Claire
AU  - Van Hout MC
AD  - School of Health Sciences, Waterford Institute of Technology, Waterford, Ireland.
      Electronic address: mcvanhout@wit.ie.
FAU - Bingham, Tim
AU  - Bingham T
LA  - eng
PT  - Case Reports
PT  - Journal Article
DEP - 20130301
PL  - Netherlands
TA  - Int J Drug Policy
JT  - The International journal on drug policy
JID - 9014759
RN  - 0 (Street Drugs)
SB  - IM
MH  - Adult
MH  - Drug Trafficking/*psychology
MH  - Drug Users/*psychology
MH  - *Health Knowledge, Attitudes, Practice
MH  - Humans
MH  - *Internet
MH  - Male
MH  - Street Drugs/*economics
OTO - NOTNLM
OT  - Ethnopharmacy
OT  - Internet
OT  - New psychoactive substances
OT  - Online drug forums
OT  - Psychonautics
OT  - 'Silk Road'
EDAT- 2013/03/08 06:00
MHDA- 2014/05/06 06:00
CRDT- 2013/03/08 06:00
PHST- 2012/09/30 [received]
PHST- 2013/01/01 [revised]
PHST- 2013/01/14 [accepted]
PHST- 2013/03/01 [aheadofprint]
AID - S0955-3959(13)00006-6 [pii]
AID - 10.1016/j.drugpo.2013.01.005 [doi]
PST - ppublish
SO  - Int J Drug Policy. 2013 Sep;24(5):385-91. doi: 10.1016/j.drugpo.2013.01.005. Epub
      2013 Mar 1.

PMID- 23400189
OWN - NLM
STAT- MEDLINE
DA  - 20130212
DCOM- 20130702
IS  - 0926-9630 (Print)
IS  - 0926-9630 (Linking)
VI  - 184
DP  - 2013
TI  - Visualization of three-dimensional ultra-high resolution OCT in virtual reality.
PG  - 387-91
AB  - Three-dimensional reconstruction of optical coherence tomography (OCT) images is 
      a modern technique that helps interpret the images and understand the underlying 
      disease. However, the 3D reconstruction displayed on commercial devices is of
      limited quality: images are shown on 2D screens and it is difficult or impossible
      to adjust the view point and capture the data set from a meaningful perspective. 
      We did a preliminary study to evaluate the applicability of a novel, 3D TV-based 
      virtual reality system with interactive volume rendering software to clinical
      diagnostics and present a workflow, which can incorporate virtual reality
      technology at various levels of immersion into the daily medical practice, from
      interactive VR systems to printed media.
FAU - Schulze, Jurgen P
AU  - Schulze JP
AD  - Calit2, University of California San Diego, La Jolla, CA, USA. jschulze@ucsd.edu
FAU - Schulze-Dobold, Claudia
AU  - Schulze-Dobold C
FAU - Erginay, Ali
AU  - Erginay A
FAU - Tadayoni, Ramin
AU  - Tadayoni R
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - T
MH  - *Computer Graphics
MH  - Humans
MH  - Image Interpretation, Computer-Assisted/*methods
MH  - Imaging, Three-Dimensional/*methods
MH  - Retinoscopy/*methods
MH  - Tomography, Optical Coherence/*methods
MH  - *User-Computer Interface
EDAT- 2013/02/13 06:00
MHDA- 2013/07/03 06:00
CRDT- 2013/02/13 06:00
PST - ppublish
SO  - Stud Health Technol Inform. 2013;184:387-91.

PMID- 23254799
OWN - NLM
STAT- MEDLINE
DA  - 20121220
DCOM- 20130528
LR  - 20141104
IS  - 1524-4040 (Electronic)
IS  - 0148-396X (Linking)
VI  - 72 Suppl 1
DP  - 2013 Jan
TI  - Role of cranial and spinal virtual and augmented reality simulation using
      immersive touch modules in neurosurgical training.
PG  - 115-23
LID - 10.1227/NEU.0b013e3182753093 [doi]
AB  - Recent studies have shown that mental script-based rehearsal and simulation-based
      training improve the transfer of surgical skills in various medical disciplines. 
      Despite significant advances in technology and intraoperative techniques over the
      last several decades, surgical skills training on neurosurgical operations still 
      carries significant risk of serious morbidity or mortality. Potentially avoidable
      technical errors are well recognized as contributing to poor surgical outcome.
      Surgical education is undergoing overwhelming change, as a result of the
      reduction of work hours and current trends focusing on patient safety and linking
      reimbursement with clinical outcomes. Thus, there is a need for adjunctive means 
      for neurosurgical training, which is a recent advancement in simulation
      technology. ImmersiveTouch is an augmented reality system that integrates a
      haptic device and a high-resolution stereoscopic display. This simulation
      platform uses multiple sensory modalities, re-creating many of the environmental 
      cues experienced during an actual procedure. Modules available include
      ventriculostomy, bone drilling, percutaneous trigeminal rhizotomy, and simulated 
      spinal modules such as pedicle screw placement, vertebroplasty, and lumbar
      puncture. We present our experience with the development of such augmented
      reality neurosurgical modules and the feedback from neurosurgical residents.
FAU - Alaraj, Ali
AU  - Alaraj A
AD  - Department of Neurosurgery, University of Illinois at Chicago College of
      Medicine, Chicago, Illinois, USA. alaraj@uic.edu
FAU - Charbel, Fady T
AU  - Charbel FT
FAU - Birk, Daniel
AU  - Birk D
FAU - Tobin, Matthew
AU  - Tobin M
FAU - Luciano, Cristian
AU  - Luciano C
FAU - Banerjee, Pat P
AU  - Banerjee PP
FAU - Rizzi, Silvio
AU  - Rizzi S
FAU - Sorenson, Jeff
AU  - Sorenson J
FAU - Foley, Kevin
AU  - Foley K
FAU - Slavin, Konstantin
AU  - Slavin K
FAU - Roitberg, Ben
AU  - Roitberg B
LA  - eng
GR  - 1R21EB007650- 01A1/EB/NIBIB NIH HHS/United States
GR  - 1R43NS066557 -01A1/NS/NINDS NIH HHS/United States
GR  - R21 EB007650/EB/NIBIB NIH HHS/United States
GR  - R43 NS066557/NS/NINDS NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PL  - United States
TA  - Neurosurgery
JT  - Neurosurgery
JID - 7802914
SB  - IM
EIN - Neurosurgery. 2013 Nov;73(5):E913. Tobin, Mathew [corrected to Tobin, Matthew]
MH  - Central Nervous System Diseases/*surgery
MH  - Competency-Based Education/methods
MH  - *Computer Simulation
MH  - Craniotomy/education/methods
MH  - Education, Medical, Graduate/*methods
MH  - Feedback
MH  - Humans
MH  - Imaging, Three-Dimensional/methods
MH  - Internship and Residency/*methods
MH  - Medical Errors/prevention & control
MH  - Neurosurgical Procedures/*education
MH  - Rhizotomy/education/methods
MH  - Spinal Fusion/education/methods
MH  - Spinal Puncture/methods
MH  - Touch
MH  - Trigeminal Neuralgia/surgery
MH  - User-Computer Interface
MH  - Ventriculostomy/education/methods
MH  - Vertebroplasty/education/methods
PMC - PMC3676942
MID - NIHMS466496
OID - NLM: NIHMS466496
OID - NLM: PMC3676942
EDAT- 2013/01/04 06:00
MHDA- 2013/05/29 06:00
CRDT- 2012/12/21 06:00
AID - 10.1227/NEU.0b013e3182753093 [doi]
AID - 00006123-201301001-00016 [pii]
PST - ppublish
SO  - Neurosurgery. 2013 Jan;72 Suppl 1:115-23. doi: 10.1227/NEU.0b013e3182753093.

PMID- 23256049
OWN - NLM
STAT- PubMed-not-MEDLINE
DA  - 20121220
DCOM- 20121221
LR  - 20130530
IS  - 2223-4292 (Print)
IS  - 2223-4306 (Linking)
VI  - 1
IP  - 1
DP  - 2011 Dec
TI  - Human brain functional MRI and DTI visualization with virtual reality.
PG  - 11-6
LID - 10.3978/j.issn.2223-4292.2011.11.01 [doi]
AB  - Magnetic resonance diffusion tensor imaging (DTI) and functional MRI (fMRI) are
      two active research areas in neuroimaging. DTI is sensitive to the anisotropic
      diffusion of water exerted by its macromolecular environment and has been shown
      useful in characterizing structures of ordered tissues such as the brain white
      matter, myocardium, and cartilage. The diffusion tensor provides two new types of
      information of water diffusion: the magnitude and the spatial orientation of
      water diffusivity inside the tissue. This information has been used for white
      matter fiber tracking to review physical neuronal pathways inside the brain.
      Functional MRI measures brain activations using the hemodynamic response. The
      statistically derived activation map corresponds to human brain functional
      activities caused by neuronal activities. The combination of these two methods
      provides a new way to understand human brain from the anatomical neuronal fiber
      connectivity to functional activities between different brain regions. In this
      study, virtual reality (VR) based MR DTI and fMRI visualization with high
      resolution anatomical image segmentation and registration, ROI definition and
      neuronal white matter fiber tractography visualization and fMRI activation map
      integration is proposed. Rationale and methods for producing and distributing
      stereoscopic videos are also discussed.
FAU - Chen, Bin
AU  - Chen B
AD  - Department of Engineering, Purdue University Calumet, Hammond, IN 46323, United
      States;
FAU - Moreland, John
AU  - Moreland J
FAU - Zhang, Jingyu
AU  - Zhang J
LA  - eng
PT  - Journal Article
PL  - China
TA  - Quant Imaging Med Surg
JT  - Quantitative imaging in medicine and surgery
JID - 101577942
PMC - PMC3496490
OID - NLM: PMC3496490
OTO - NOTNLM
OT  - Human brain visualization
OT  - stereoscopic 3D visualization
EDAT- 2012/12/21 06:00
MHDA- 2012/12/21 06:01
CRDT- 2012/12/21 06:00
PHST- 2011/10/28 [received]
PHST- 2011/11/03 [accepted]
AID - 10.3978/j.issn.2223-4292.2011.11.01 [doi]
AID - qims-01-01-011 [pii]
PST - ppublish
SO  - Quant Imaging Med Surg. 2011 Dec;1(1):11-6. doi:
      10.3978/j.issn.2223-4292.2011.11.01.

PMID- 23123995
OWN - NLM
STAT- MEDLINE
DA  - 20121105
DCOM- 20130619
IS  - 1559-0879 (Electronic)
IS  - 1556-9845 (Linking)
VI  - 7
IP  - 4
DP  - 2012 Jul-Aug
TI  - Augmented reality image guidance improves navigation for beating heart mitral
      valve repair.
PG  - 274-81
LID - 10.1097/IMI.0b013e31827439ea [doi]
AB  - OBJECTIVE: Emerging off-pump beating heart valve repair techniques offer patients
      less invasive alternatives for mitral valve (MV) repair. However, most of these
      techniques rely on the limited spatial and temporal resolution of transesophageal
      echocardiography (TEE) alone, which can make tool visualization and guidance
      challenging. METHODS: Using a magnetic tracking system and integrated sensors, we
      created an augmented reality (AR) environment displaying virtual representations 
      of important intracardiac landmarks registered to biplane TEE imaging. In a
      porcine model, we evaluated the AR guidance system versus TEE alone using the
      transapically delivered NeoChord DS1000 system to perform MV repair with chordal 
      reconstruction. RESULTS: Successful tool navigation from left ventricular apex to
      MV leaflet was achieved in 12 of 12 and 9 of 12 (P = 0.2) attempts with AR
      imaging and TEE alone, respectively. The distance errors of the tracked tool tip 
      from the intended midline trajectory (5.2 +/- 2.4 mm vs 16.8 +/- 10.9 mm, P =
      0.003), navigation times (16.7 +/- 8.0 seconds vs 92.0 +/- 84.5 seconds, P =
      0.004), and total path lengths (225.2 +/- 120.3 mm vs 1128.9 +/- 931.1 mm, P =
      0.003) were significantly shorter in the AR-guided trials compared with
      navigation with TEE alone. Furthermore, the potential for injury to other
      intracardiac structures was nearly 40-fold lower when using the AR imaging for
      tool navigation. The AR guidance also seemed to shorten the learning curve for
      novice surgeons. CONCLUSIONS: Augmented reality-enhanced TEE facilitates more
      direct and safe intracardiac navigation of the NeoChord DS tool from left
      ventricular apex to MV leaflet. Tracked tool path results demonstrate fourfold
      improved accuracy, fivefold shorter navigation times, and overall improved safety
      with AR imaging guidance.
FAU - Chu, Michael W A
AU  - Chu MW
AD  - Division of Cardiac Surgery, Department of Surgery, Western University, London,
      ON Canada. michael.chu@lhsc.on.ca
FAU - Moore, John
AU  - Moore J
FAU - Peters, Terry
AU  - Peters T
FAU - Bainbridge, Daniel
AU  - Bainbridge D
FAU - McCarty, David
AU  - McCarty D
FAU - Guiraudon, Gerard M
AU  - Guiraudon GM
FAU - Wedlake, Chris
AU  - Wedlake C
FAU - Lang, Pencilla
AU  - Lang P
FAU - Rajchl, Martin
AU  - Rajchl M
FAU - Currie, Maria E
AU  - Currie ME
FAU - Daly, Richard C
AU  - Daly RC
FAU - Kiaii, Bob
AU  - Kiaii B
LA  - eng
GR  - 179298/Canadian Institutes of Health Research/Canada
PT  - Comparative Study
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - United States
TA  - Innovations (Phila)
JT  - Innovations (Philadelphia, Pa.)
JID - 101257528
SB  - IM
MH  - Animals
MH  - Cardiac Surgical Procedures/methods
MH  - *Coronary Artery Bypass, Off-Pump
MH  - Disease Models, Animal
MH  - Echocardiography, Transesophageal/*instrumentation/methods
MH  - Equipment Design
MH  - Heart Valve Prosthesis Implantation/*methods
MH  - Image Processing, Computer-Assisted
MH  - Mitral Valve/*surgery/*ultrasonography
MH  - Sus scrofa
MH  - Treatment Outcome
MH  - Ultrasonography, Interventional/instrumentation/methods
EDAT- 2012/11/06 06:00
MHDA- 2013/06/20 06:00
CRDT- 2012/11/06 06:00
AID - 10.1097/IMI.0b013e31827439ea [doi]
AID - 01243895-201207000-00008 [pii]
PST - ppublish
SO  - Innovations (Phila). 2012 Jul-Aug;7(4):274-81. doi: 10.1097/IMI.0b013e31827439ea.

PMID- 22995776
OWN - NLM
STAT- MEDLINE
DA  - 20121126
DCOM- 20130604
IS  - 1095-9572 (Electronic)
IS  - 1053-8119 (Linking)
VI  - 64
DP  - 2013 Jan 1
TI  - Shared electrophysiology mechanisms of body ownership and motor imagery.
PG  - 216-28
LID - 10.1016/j.neuroimage.2012.09.027 [doi]
LID - S1053-8119(12)00937-8 [pii]
AB  - Although we feel, see, and experience our hands as our own (body or hand
      ownership), recent research has shown that illusory hand ownership can be induced
      for fake or virtual hands and may be useful for neuroprosthetics and
      brain-computer interfaces. Despite the vast amount of behavioral data on illusory
      hand ownership, neuroimaging studies are rare, in particular electrophysiological
      studies. Thus, while the neural systems underlying hand ownership are relatively 
      well described, the spectral signatures of body ownership as measured by
      electroencephalography (EEG) remain elusive. Here we induced illusory hand
      ownership in an automated, computer-controlled manner using virtual reality while
      recording 64-channel EEG and found that illusory hand ownership is reflected by a
      body-specific modulation in the mu-band over fronto-parietal cortex. In a second 
      experiment in the same subjects, we then show that mu as well as beta-band
      activity in highly similar fronto-parietal regions was also modulated during a
      motor imagery task often used in paradigms employing non-invasive brain-computer 
      interface technology. These data provide insights into the electrophysiological
      brain mechanisms of illusory hand ownership and their strongly overlapping
      mechanisms with motor imagery in fronto-parietal cortex. They also highlight the 
      potential of combining high-resolution EEG with virtual reality setups and
      automatized stimulation protocols for systematic, reproducible stimulus
      presentation in cognitive neuroscience, and may inform the design of non-invasive
      brain-computer interfaces.
CI  - Copyright (c) 2012 Elsevier Inc. All rights reserved.
FAU - Evans, Nathan
AU  - Evans N
AD  - Center for Neuroprosthetics, School of Life Sciences, Ecole Polytechnique
      Federale de Lausanne, Switzerland.
FAU - Blanke, Olaf
AU  - Blanke O
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20120918
PL  - United States
TA  - Neuroimage
JT  - NeuroImage
JID - 9215515
SB  - IM
MH  - Adult
MH  - *Body Image
MH  - Cerebral Cortex/*physiology
MH  - Female
MH  - Hand/*physiology
MH  - Humans
MH  - Illusions/*physiology
MH  - Imagination/*physiology
MH  - Male
MH  - Movement/*physiology
MH  - Nerve Net/*physiology
EDAT- 2012/09/22 06:00
MHDA- 2013/06/05 06:00
CRDT- 2012/09/22 06:00
PHST- 2012/02/07 [received]
PHST- 2012/08/30 [revised]
PHST- 2012/09/04 [accepted]
PHST- 2012/09/18 [aheadofprint]
AID - S1053-8119(12)00937-8 [pii]
AID - 10.1016/j.neuroimage.2012.09.027 [doi]
PST - ppublish
SO  - Neuroimage. 2013 Jan 1;64:216-28. doi: 10.1016/j.neuroimage.2012.09.027. Epub
      2012 Sep 18.

PMID- 22882289
OWN - NLM
STAT- MEDLINE
DA  - 20121217
DCOM- 20130613
IS  - 1365-2559 (Electronic)
IS  - 0309-0167 (Linking)
VI  - 62
IP  - 2
DP  - 2013 Jan
TI  - Virtual reality microscope versus conventional microscope regarding time to
      diagnosis: an experimental study.
PG  - 351-8
LID - 10.1111/j.1365-2559.2012.04323.x [doi]
AB  - AIMS: To create and evaluate a virtual reality (VR) microscope that is as
      efficient as the conventional microscope, seeking to support the introduction of 
      digital slides into routine practice. METHODS AND RESULTS: A VR microscope was
      designed and implemented by combining ultra-high-resolution displays with VR
      technology, techniques for fast interaction, and high usability. It was evaluated
      using a mixed factorial experimental design with technology and task as
      within-participant variables and grade of histopathologist as a
      between-participant variable. Time to diagnosis was similar for the conventional 
      and VR microscopes. However, there was a significant difference in the mean
      magnification used between the two technologies, with participants working at a
      higher level of magnification on the VR microscope. CONCLUSIONS: The results
      suggest that, with the right technology, efficient use of digital pathology for
      routine practice is a realistic possibility. Further work is required to explore 
      what magnification is required on the VR microscope for histopathologists to
      identify diagnostic features, and the effect on this of the digital slide
      production process.
CI  - (c) 2012 Blackwell Publishing Limited.
FAU - Randell, Rebecca
AU  - Randell R
AD  - Leeds Institute of Molecular Medicine, University of Leeds, St James's University
      Hospital, Leeds, UK. r.randell@leeds.ac.uk
FAU - Ruddle, Roy A
AU  - Ruddle RA
FAU - Mello-Thoms, Claudia
AU  - Mello-Thoms C
FAU - Thomas, Rhys G
AU  - Thomas RG
FAU - Quirke, Phil
AU  - Quirke P
FAU - Treanor, Darren
AU  - Treanor D
LA  - eng
PT  - Comparative Study
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20120808
PL  - England
TA  - Histopathology
JT  - Histopathology
JID - 7704136
SB  - IM
MH  - Adolescent
MH  - Adult
MH  - Aged
MH  - Aged, 80 and over
MH  - Diagnosis, Differential
MH  - Diagnostic Techniques and Procedures
MH  - Female
MH  - Gastrointestinal Diseases/diagnosis
MH  - Humans
MH  - *Image Processing, Computer-Assisted
MH  - Male
MH  - Microscopy/*instrumentation/*methods
MH  - Middle Aged
MH  - Pathology, Surgical/*instrumentation/*methods
MH  - Reproducibility of Results
MH  - Skin Diseases/diagnosis
MH  - Time Factors
MH  - User-Computer Interface
EDAT- 2012/08/14 06:00
MHDA- 2013/06/14 06:00
CRDT- 2012/08/14 06:00
PHST- 2012/08/08 [aheadofprint]
AID - 10.1111/j.1365-2559.2012.04323.x [doi]
PST - ppublish
SO  - Histopathology. 2013 Jan;62(2):351-8. doi: 10.1111/j.1365-2559.2012.04323.x. Epub
      2012 Aug 8.

PMID- 22556316
OWN - NLM
STAT- MEDLINE
DA  - 20120712
DCOM- 20121212
LR  - 20141120
IS  - 1527-1323 (Electronic)
IS  - 0271-5333 (Linking)
VI  - 32
IP  - 4
DP  - 2012 Jul-Aug
TI  - Informatics in radiology: Intuitive user interface for 3D image manipulation
      using augmented reality and a smartphone as a remote control.
PG  - E169-74
LID - 10.1148/rg.324115086 [doi]
AB  - Although widely used as a pointing device on personal computers (PCs), the mouse 
      was originally designed for control of two-dimensional (2D) cursor movement and
      is not suited to complex three-dimensional (3D) image manipulation. Augmented
      reality (AR) is a field of computer science that involves combining the physical 
      world and an interactive 3D virtual world; it represents a new 3D user interface 
      (UI) paradigm. A system for 3D and four-dimensional (4D) image manipulation has
      been developed that uses optical tracking AR integrated with a smartphone remote 
      control. The smartphone is placed in a hard case (jacket) with a 2D printed
      fiducial marker for AR on the back. It is connected to a conventional PC with an 
      embedded Web camera by means of WiFi. The touch screen UI of the smartphone is
      then used as a remote control for 3D and 4D image manipulation. Using this
      system, the radiologist can easily manipulate 3D and 4D images from computed
      tomography and magnetic resonance imaging in an AR environment with high-quality 
      image resolution. Pilot assessment of this system suggests that radiologists will
      be able to manipulate 3D and 4D images in the reading room in the near future.
      Supplemental material available at
      http://radiographics.rsna.org/lookup/suppl/doi:10.1148/rg.324115086/-/DC1.
FAU - Nakata, Norio
AU  - Nakata N
AD  - Department of Radiology and Institute for High Dimensional Medical Imaging,
      Research Center for Medical Sciences, Jikei University School of Medicine, 3-25-8
      Nishi-Shinbashi, Minato-ku, Tokyo 1058461, Japan. nakata@jikei.ac.jp
FAU - Suzuki, Naoki
AU  - Suzuki N
FAU - Hattori, Asaki
AU  - Hattori A
FAU - Hirai, Naoya
AU  - Hirai N
FAU - Miyamoto, Yukio
AU  - Miyamoto Y
FAU - Fukuda, Kunihiko
AU  - Fukuda K
LA  - eng
PT  - Journal Article
DEP - 20120503
PL  - United States
TA  - Radiographics
JT  - Radiographics : a review publication of the Radiological Society of North
      America, Inc
JID - 8302501
SB  - IM
MH  - *Cell Phones
MH  - *Computer Peripherals
MH  - *Computers, Handheld
MH  - Equipment Design
MH  - Equipment Failure Analysis
MH  - Image Enhancement/instrumentation
MH  - Image Interpretation, Computer-Assisted/*instrumentation
MH  - Imaging, Three-Dimensional/*instrumentation
MH  - *Medical Informatics Applications
MH  - Telemetry/instrumentation
MH  - *User-Computer Interface
EDAT- 2012/05/05 06:00
MHDA- 2012/12/13 06:00
CRDT- 2012/05/05 06:00
PHST- 2012/05/03 [aheadofprint]
AID - rg.324115086 [pii]
AID - 10.1148/rg.324115086 [doi]
PST - ppublish
SO  - Radiographics. 2012 Jul-Aug;32(4):E169-74. doi: 10.1148/rg.324115086. Epub 2012
      May 3.

PMID- 22442752
OWN - NLM
STAT- PubMed-not-MEDLINE
DA  - 20120323
DCOM- 20120910
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 2
DP  - 2012
TI  - A fast and flexible panoramic virtual reality system for behavioural and
      electrophysiological experiments.
PG  - 324
LID - 10.1038/srep00324 [doi]
AB  - Ideally, neuronal functions would be studied by performing experiments with
      unconstrained animals whilst they behave in their natural environment. Although
      this is not feasible currently for most animal models, one can mimic the natural 
      environment in the laboratory by using a virtual reality (VR) environment. Here
      we present a novel VR system based upon a spherical projection of computer
      generated images using a modified commercial data projector with an add-on
      fish-eye lens. This system provides equidistant visual stimulation with extensive
      coverage of the visual field, high spatio-temporal resolution and flexible
      stimulus generation using a standard computer. It also includes a track-ball
      system for closed-loop behavioural experiments with walking animals. We present a
      detailed description of the system and characterize it thoroughly. Finally, we
      demonstrate the VR system's performance whilst operating in closed-loop
      conditions by showing the movement trajectories of the cockroaches during
      exploratory behaviour in a VR forest.
FAU - Takalo, Jouni
AU  - Takalo J
FAU - Piironen, Arto
AU  - Piironen A
FAU - Honkanen, Anna
AU  - Honkanen A
FAU - Lempea, Mikko
AU  - Lempea M
FAU - Aikio, Mika
AU  - Aikio M
FAU - Tuukkanen, Tuomas
AU  - Tuukkanen T
FAU - Vahasoyrinki, Mikko
AU  - Vahasoyrinki M
LA  - eng
PT  - Journal Article
DEP - 20120322
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
PMC - PMC3310229
OID - NLM: PMC3310229
EDAT- 2012/03/24 06:00
MHDA- 2012/03/24 06:01
CRDT- 2012/03/24 06:00
PHST- 2012/02/06 [received]
PHST- 2012/02/27 [accepted]
PHST- 2012/03/22 [epublish]
AID - 10.1038/srep00324 [doi]
PST - ppublish
SO  - Sci Rep. 2012;2:324. doi: 10.1038/srep00324. Epub 2012 Mar 22.

PMID- 22256201
OWN - NLM
STAT- MEDLINE
DA  - 20120118
DCOM- 20120531
LR  - 20140821
IS  - 1557-170X (Print)
IS  - 1557-170X (Linking)
VI  - 2011
DP  - 2011
TI  - Substituting depth for intensity and real-time phosphene rendering: visual
      navigation under low vision conditions.
PG  - 8017-20
LID - 10.1109/IEMBS.2011.6091977 [doi]
AB  - Navigation and way finding including obstacle avoidance is difficult when visual 
      perception is limited to low resolution, such as is currently available on a
      bionic eye. Depth visualisation may be a suitable alternative. Such an approach
      can be evaluated using simulated phosphenes with a wearable mobile virtual
      reality kit. In this paper, we present two novel approaches: (i) an
      implementation of depth visualisation; and, (ii) novel methods for rapid
      rendering of simulated phosphenes with an empirical comparison between them. Our 
      new software-based method for simulated phosphene rendering shows large speed
      improvements, facilitating the display in real-time of a large number of
      phosphenes with size and brightness dependent on pixel intensity, and with
      customised output dynamic range. Further, we describe the protocol, navigation
      environment and system used for visual navigation experiments to evaluate the use
      of depth on low resolution simulations of a bionic eye perceptual experience.
      Results for these experiments show that a depth-based representation is effective
      for navigation, and shows significant advantages over intensity-based approaches 
      when overhanging obstacles are present. The results of the experiments were
      reported in [1], [2].
FAU - Lieby, Paulette
AU  - Lieby P
AD  - NICTA Canberra Research Laboratory, Tower A, 7 London Circuit, Canberra ACT 2600,
      Locked Bag 8001, Canberra ACT 2601, Australia.
FAU - Barnes, Nick
AU  - Barnes N
FAU - McCarthy, Chris
AU  - McCarthy C
FAU - Liu, Nianjun
AU  - Liu N
FAU - Dennett, Hugh
AU  - Dennett H
FAU - Walker, Janine G
AU  - Walker JG
FAU - Botea, Viorica
AU  - Botea V
FAU - Scott, Adele F
AU  - Scott AF
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - United States
TA  - Conf Proc IEEE Eng Med Biol Soc
JT  - Conference proceedings : ... Annual International Conference of the IEEE
      Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and
      Biology Society. Annual Conference
JID - 101243413
SB  - IM
MH  - Algorithms
MH  - Depth Perception/*physiology
MH  - Female
MH  - Humans
MH  - Male
MH  - Movement/*physiology
MH  - Normal Distribution
MH  - Phosphenes/*physiology
MH  - Time Factors
MH  - Vision, Low/*physiopathology
MH  - Young Adult
EDAT- 2012/01/19 06:00
MHDA- 2012/06/01 06:00
CRDT- 2012/01/19 06:00
AID - 10.1109/IEMBS.2011.6091977 [doi]
PST - ppublish
SO  - Conf Proc IEEE Eng Med Biol Soc. 2011;2011:8017-20. doi:
      10.1109/IEMBS.2011.6091977.

PMID- 22027473
OWN - NLM
STAT- MEDLINE
DA  - 20111124
DCOM- 20120719
IS  - 1557-0584 (Electronic)
IS  - 1557-0576 (Linking)
VI  - 35
IP  - 4
DP  - 2011 Dec
TI  - Application of a mild traumatic brain injury rehabilitation program in a virtual 
      realty environment: a case study.
PG  - 185-93
LID - 10.1097/NPT.0b013e318235d7e6 [doi]
AB  - BACKGROUND AND PURPOSE: Mild traumatic brain injury (mTBI) can compromise
      reaction time, visual perception, memory, attention, balance, and gait. These
      deficits, especially if persistent, can restrict participation in daily
      activities and the resumption of personal and profession roles. The purpose of
      this case study is to describe an mTBI-specific clinical assessment and
      rehabilitation intervention administered in a virtual reality environment. CASE
      DESCRIPTION: The case involved a 31-year-old male service member who had
      sustained an mTBI (concussion) during a recreational softball game 36 days prior 
      to physical therapist evaluation. He had complaints of severe visual and physical
      motion intolerance. He demonstrated impaired static balance and was restricted
      from full military duty. INTERVENTIONS: The assessment included measurements of
      postural and gait balance during cognitive, visual, and vestibular challenges
      within a Computer-Assisted Rehabilitation Environment. Phase 1 of the
      intervention consisted of clinical techniques (ie, optokinetic
      stimulation/habituation, visual/physical perturbations, and postural stability
      exercises) targeting specific impairments. Phase 2 training consisted of weapon
      handling and target recognition tasks to simulate the requirements of his
      military occupation. OUTCOMES: At the conclusion of 6 treatments, the patient
      demonstrated significant increases in postural and gait balance with a near
      complete resolution of all postconcussion symptoms. He successfully returned to
      full duty and training for combat deployment. DISCUSSION: Service members and
      civilians exhibit similar impairments, limitations, and restrictions following
      mTBI. A rehabilitation program delivered in a virtual-reality environment can be 
      structured to manage complex mTBI symptoms through the integration of multiple
      treatment modalities specific to a patient's personal and professional roles.
FAU - Rabago, Christopher A
AU  - Rabago CA
AD  - Center for the Intrepid, Department of Orthopedics and Rehabilitation, Brooke
      Army Medical Center, Fort Sam Houston, Texas 78234, USA.
      Christopher.Rabago@amedd.army.mil
FAU - Wilken, Jason M
AU  - Wilken JM
LA  - eng
PT  - Case Reports
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - United States
TA  - J Neurol Phys Ther
JT  - Journal of neurologic physical therapy : JNPT
JID - 101193365
SB  - IM
MH  - Attention/physiology
MH  - Brain Concussion/physiopathology/*rehabilitation
MH  - Environment
MH  - Female
MH  - Gait/*physiology
MH  - Humans
MH  - Male
MH  - *Physical Therapy Modalities
MH  - Postural Balance/*physiology
MH  - Reaction Time/physiology
MH  - *User-Computer Interface
EDAT- 2011/10/27 06:00
MHDA- 2012/07/20 06:00
CRDT- 2011/10/27 06:00
AID - 10.1097/NPT.0b013e318235d7e6 [doi]
PST - ppublish
SO  - J Neurol Phys Ther. 2011 Dec;35(4):185-93. doi: 10.1097/NPT.0b013e318235d7e6.

PMID- 22025748
OWN - NLM
STAT- PubMed-not-MEDLINE
DA  - 20120402
DCOM- 20120628
IS  - 1941-0506 (Electronic)
IS  - 1077-2626 (Linking)
VI  - 18
IP  - 3
DP  - 2012 Mar
TI  - Autocalibration of multiprojector CAVE-like immersive environments.
PG  - 381-93
LID - 10.1109/TVCG.2011.271 [doi]
AB  - In this paper, we present the first method for the geometric autocalibration of
      multiple projectors on a set of CAVE-like immersive display surfaces including
      truncated domes and 4 or 5-wall CAVEs (three side walls, floor, and/or ceiling). 
      All such surfaces can be categorized as swept surfaces and multiple projectors
      can be registered on them using a single uncalibrated camera without using any
      physical markers on the surface. Our method can also handle nonlinear distortion 
      in the projectors, common in compact setups where a short throw lens is mounted
      on each projector. Further, when the whole swept surface is not visible from a
      single camera view, we can register the projectors using multiple pan and tilted 
      views of the same camera. Thus, our method scales well with different size and
      resolution of the display. Since we recover the 3D shape of the display, we can
      achieve registration that is correct from any arbitrary viewpoint appropriate for
      head-tracked single-user virtual reality systems. We can also achieve wallpapered
      registration, more appropriate for multiuser collaborative explorations. Though
      much more immersive than common surfaces like planes and cylinders, general swept
      surfaces are used today only for niche display environments. Even the more
      popular 4 or 5-wall CAVE is treated as a piecewise planar surface for calibration
      purposes and hence projectors are not allowed to be overlapped across the
      corners. Our method opens up the possibility of using such swept surfaces to
      create more immersive VR systems without compromising the simplicity of having a 
      completely automatic calibration technique. Such calibration allows completely
      arbitrary positioning of the projectors in a 5-wall CAVE, without respecting the 
      corners.
FAU - Sajadi, Behzad
AU  - Sajadi B
AD  - Department of Computer Science, University of California, Irvine, CA 92697, USA. 
      bsajadi@ics.uci.edu
FAU - Majumder, Aditi
AU  - Majumder A
LA  - eng
PT  - Journal Article
PT  - Research Support, U.S. Gov't, Non-P.H.S.
PL  - United States
TA  - IEEE Trans Vis Comput Graph
JT  - IEEE transactions on visualization and computer graphics
JID - 9891704
EDAT- 2011/10/26 06:00
MHDA- 2011/10/26 06:01
CRDT- 2011/10/26 06:00
AID - 10.1109/TVCG.2011.271 [doi]
PST - ppublish
SO  - IEEE Trans Vis Comput Graph. 2012 Mar;18(3):381-93. doi: 10.1109/TVCG.2011.271.

PMID- 21812639
OWN - NLM
STAT- MEDLINE
DA  - 20120131
DCOM- 20120525
IS  - 1530-8898 (Electronic)
IS  - 0898-929X (Linking)
VI  - 24
IP  - 3
DP  - 2012 Mar
TI  - Brain oscillatory activity during spatial navigation: theta and gamma activity
      link medial temporal and parietal regions.
PG  - 686-97
LID - 10.1162/jocn_a_00098 [doi]
AB  - Brain oscillatory correlates of spatial navigation were investigated using blind 
      source separation (BSS) and standardized low resolution electromagnetic
      tomography (sLORETA) analyses of 62-channel EEG recordings. Twenty-five
      participants were instructed to navigate to distinct landmark buildings in a
      previously learned virtual reality town environment. Data from periods of
      navigation between landmarks were subject to BSS analyses to obtain source
      components. Two of these cortical sources were found to exhibit significant
      spectral power differences during navigation with respect to a resting eyes open 
      condition and were subject to source localization using sLORETA. These two
      sources were localized as a right parietal component with gamma activation and a 
      right medial-temporal-parietal component with activation in theta and gamma
      bandwidths. The parietal gamma activity was thought to reflect visuospatial
      processing associated with the task. The medial-temporal-parietal activity was
      thought to be more specific to the navigational processing, representing the
      integration of ego- and allo-centric representations of space required for
      successful navigation, suggesting theta and gamma oscillations may have a role in
      integrating information from parietal and medial-temporal regions. Theta activity
      on this medial-temporal-parietal source was positively correlated with more
      efficient navigation performance. Results are discussed in light of the depth and
      proposed closed field structure of the hippocampus and potential implications for
      scalp EEG data. The findings of the present study suggest that appropriate BSS
      methods are ideally suited to minimizing the effects of volume conduction in
      noninvasive recordings, allowing more accurate exploration of deep brain
      processes.
FAU - White, David J
AU  - White DJ
AD  - Swinburne University of Technology, Australia. dawhite@groupwise.swin.edu.au
FAU - Congedo, Marco
AU  - Congedo M
FAU - Ciorciari, Joseph
AU  - Ciorciari J
FAU - Silberstein, Richard B
AU  - Silberstein RB
LA  - eng
PT  - Journal Article
DEP - 20110803
PL  - United States
TA  - J Cogn Neurosci
JT  - Journal of cognitive neuroscience
JID - 8910747
SB  - IM
MH  - Adult
MH  - Biological Clocks/*physiology
MH  - *Brain Mapping
MH  - Brain Waves/*physiology
MH  - Electroencephalography
MH  - Female
MH  - Humans
MH  - Male
MH  - Neural Pathways/physiology
MH  - Parietal Lobe/*physiology
MH  - Psychomotor Performance/physiology
MH  - Reaction Time/physiology
MH  - Spatial Behavior/*physiology
MH  - Temporal Lobe/*physiology
MH  - User-Computer Interface
MH  - Young Adult
EDAT- 2011/08/05 06:00
MHDA- 2012/05/26 06:00
CRDT- 2011/08/05 06:00
PHST- 2011/08/03 [aheadofprint]
AID - 10.1162/jocn_a_00098 [doi]
PST - ppublish
SO  - J Cogn Neurosci. 2012 Mar;24(3):686-97. doi: 10.1162/jocn_a_00098. Epub 2011 Aug 
      3.

PMID- 21790107
OWN - NLM
STAT- MEDLINE
DA  - 20110727
DCOM- 20120321
IS  - 1938-2375 (Electronic)
IS  - 1542-8877 (Linking)
VI  - 42 Suppl
DP  - 2011 Jul
TI  - Volumetric three-dimensional reconstruction and segmentation of spectral-domain
      OCT.
PG  - S116-20
LID - 10.3928/15428877-20110627-11 [doi]
AB  - Despite advances in optical coherence tomography (OCT), three-dimensional (3D)
      renderings of OCT images remain limited to scanning consecutive two-dimensional
      (2D) OCT slices. The authors describe a method of reconstructing 2D OCT data for 
      3D retinal analysis and visualization in a Computer Assisted Virtual Environment 
      (CAVE). Using customized signal processing software, raw data from 2D slice-based
      spectral-domain OCT images were rendered into high-resolution 3D images for
      segmentation and quantification analysis. Reconstructed OCT images were projected
      onto a four-walled space and viewed through stereoscopic glasses, resulting in a 
      virtual reality perception of the retina. These 3D retinal renderings offer a
      novel method for segmentation and isolation of volumetric images. The ability to 
      manipulate the images in a virtual reality environment allows visualization of
      complex spatial relationships that may aid our understanding of retinal
      pathology. More importantly, these 3D retinal renderings can be viewed,
      manipulated, and analyzed on traditional 2D monitors independent of the CAVE.
CI  - Copyright 2011, SLACK Incorporated.
FAU - Aaker, Grant D
AU  - Aaker GD
AD  - Department of Ophthalmology and HRH Prince Alwaleed Bin Talal Bin Abdulaziz
      Alsaud Institute for Computational Biomedicine, Weill Cornell Medical College,
      New York, NY, USA.
FAU - Gracia, Luis
AU  - Gracia L
FAU - Myung, Jane S
AU  - Myung JS
FAU - Borcherding, Vanessa
AU  - Borcherding V
FAU - Banfelder, Jason R
AU  - Banfelder JR
FAU - D'Amico, Donald J
AU  - D'Amico DJ
FAU - Kiss, Szilard
AU  - Kiss S
LA  - eng
PT  - Journal Article
PT  - Review
PL  - United States
TA  - Ophthalmic Surg Lasers Imaging
JT  - Ophthalmic surgery, lasers & imaging : the official journal of the International 
      Society for Imaging in the Eye
JID - 101155780
SB  - IM
MH  - *Diagnostic Techniques, Ophthalmological
MH  - Humans
MH  - *Imaging, Three-Dimensional
MH  - Tomography, Optical Coherence/*methods
EDAT- 2011/07/28 06:00
MHDA- 2012/03/22 06:00
CRDT- 2011/07/28 06:00
PHST- 2010/12/07 [received]
PHST- 2011/04/21 [accepted]
AID - 10.3928/15428877-20110627-11 [doi]
PST - ppublish
SO  - Ophthalmic Surg Lasers Imaging. 2011 Jul;42 Suppl:S116-20. doi:
      10.3928/15428877-20110627-11.

PMID- 21471846
OWN - NLM
STAT- MEDLINE
DA  - 20110805
DCOM- 20111201
LR  - 20140820
IS  - 1524-4040 (Electronic)
IS  - 0148-396X (Linking)
VI  - 69
IP  - 1 Suppl Operative
DP  - 2011 Sep
TI  - Learning retention of thoracic pedicle screw placement using a high-resolution
      augmented reality simulator with haptic feedback.
PG  - ons14-9; discussion ons19
LID - 10.1227/NEU.0b013e31821954ed [doi]
AB  - BACKGROUND: We evaluated the use of a part-task simulator with 3D and haptic
      feedback as a training tool for a common neurosurgical procedure--placement of
      thoracic pedicle screws. OBJECTIVE: To evaluate the learning retention of
      thoracic pedicle screw placement on a high-performance augmented reality and
      haptic technology workstation. METHODS: Fifty-one fellows and residents performed
      thoracic pedicle screw placement on the simulator. The virtual screws were
      drilled into a virtual patient's thoracic spine derived from a computed
      tomography data set of a real patient. RESULTS: With a 12.5% failure rate, a
      2-proportion z test yielded P = .08. For performance accuracy, an aggregate
      Euclidean distance deviation from entry landmark on the pedicle and a similar
      deviation from the target landmark in the vertebral body yielded P = .04 from a
      2-sample t test in which the rejected null hypothesis assumes no improvement in
      performance accuracy from the practice to the test sessions, and the alternative 
      hypothesis assumes an improvement. CONCLUSION: The performance accuracy on the
      simulator was comparable to the accuracy reported in literature on recent
      retrospective evaluation of such placements. The failure rates indicated a minor 
      drop from practice to test sessions, and also indicated a trend (P = .08) toward 
      learning retention resulting in improvement from practice to test sessions. The
      performance accuracy showed a 15% mean score improvement and more than a 50%
      reduction in standard deviation from practice to test. It showed evidence (P =
      .04) of performance accuracy improvement from practice to test session.
FAU - Luciano, Cristian J
AU  - Luciano CJ
AD  - Department of Mechanical and Industrial Engineering, College of Engineering,
      University of Illinois at Chicago, Illinois 60607, USA.
FAU - Banerjee, P Pat
AU  - Banerjee PP
FAU - Bellotte, Brad
AU  - Bellotte B
FAU - Oh, G Michael
AU  - Oh GM
FAU - Lemole, Michael Jr
AU  - Lemole M Jr
FAU - Charbel, Fady T
AU  - Charbel FT
FAU - Roitberg, Ben
AU  - Roitberg B
LA  - eng
GR  - 1R21EB007650-01A1/EB/NIBIB NIH HHS/United States
GR  - R21 EB007650-02/EB/NIBIB NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, Non-U.S. Gov't
PL  - United States
TA  - Neurosurgery
JT  - Neurosurgery
JID - 7802914
SB  - IM
MH  - Bone Screws
MH  - *Computer Simulation
MH  - Education, Medical, Graduate/*methods
MH  - Humans
MH  - Learning
MH  - Neurosurgery/*education
MH  - Retention (Psychology)
MH  - *Spinal Fusion/methods
MH  - Thoracic Vertebrae/surgery
MH  - *User-Computer Interface
PMC - PMC3153609
MID - NIHMS287737
OID - NLM: NIHMS287737
OID - NLM: PMC3153609
EDAT- 2011/04/08 06:00
MHDA- 2011/12/13 00:00
CRDT- 2011/04/08 06:00
AID - 10.1227/NEU.0b013e31821954ed [doi]
PST - ppublish
SO  - Neurosurgery. 2011 Sep;69(1 Suppl Operative):ons14-9; discussion ons19. doi:
      10.1227/NEU.0b013e31821954ed.

PMID- 21464515
OWN - NLM
STAT- MEDLINE
DA  - 20120629
DCOM- 20120919
IS  - 1557-9964 (Electronic)
IS  - 1545-5963 (Linking)
VI  - 9
IP  - 3
DP  - 2012 May-Jun
TI  - Constructing complex 3D biological environments from medical imaging using high
      performance computing.
PG  - 643-54
LID - 10.1109/TCBB.2011.69 [doi]
AB  - Extracting information about the structure of biological tissue from static image
      data is a complex task requiring computationally intensive operations. Here, we
      present how multicore CPUs and GPUs have been utilized to extract information
      about the shape, size, and path followed by the mammalian oviduct, called the
      fallopian tube in humans, from histology images, to create a unique but realistic
      3D virtual organ. Histology images were processed to identify the individual
      cross sections and determine the 3D path that the tube follows through the
      tissue. This information was then related back to the histology images, linking
      the 2D cross sections with their corresponding 3D position along the oviduct. A
      series of linear 2D spline cross sections, which were computationally generated
      for the length of the oviduct, were bound to the 3D path of the tube using a
      novel particle system technique that provides smooth resolution of
      self-intersections. This results in a unique 3D model of the oviduct, which is
      grounded in reality. The GPU is used for the processor intensive operations of
      image processing and particle physics based simulations, significantly reducing
      the time required to generate a complete model.
FAU - Burkitt, Mark
AU  - Burkitt M
AD  - Department of Computer Science, University of Sheffield, Regent Court, 211
      Portobello, Sheffield S1 4DP, United Kingdom. m.burkitt@sheffield.ac.uk
FAU - Walker, Dawn
AU  - Walker D
FAU - Romano, Daniela M
AU  - Romano DM
FAU - Fazeli, Alireza
AU  - Fazeli A
LA  - eng
PT  - Journal Article
PL  - United States
TA  - IEEE/ACM Trans Comput Biol Bioinform
JT  - IEEE/ACM transactions on computational biology and bioinformatics / IEEE, ACM
JID - 101196755
SB  - IM
MH  - Algorithms
MH  - *Computing Methodologies
MH  - Diagnostic Imaging/*methods
MH  - Fallopian Tubes/pathology
MH  - Female
MH  - Humans
MH  - Image Interpretation, Computer-Assisted/methods
EDAT- 2011/04/06 06:00
MHDA- 2012/09/20 06:00
CRDT- 2011/04/06 06:00
AID - 10.1109/TCBB.2011.69 [doi]
PST - ppublish
SO  - IEEE/ACM Trans Comput Biol Bioinform. 2012 May-Jun;9(3):643-54. doi:
      10.1109/TCBB.2011.69.

PMID- 21403720
OWN - NLM
STAT- PubMed-not-MEDLINE
DA  - 20110315
DCOM- 20110705
IS  - 1539-4794 (Electronic)
IS  - 0146-9592 (Linking)
VI  - 36
IP  - 6
DP  - 2011 Mar 15
TI  - Optical panel with full multitouch using patterned indium tin oxide.
PG  - 894-6
LID - 10.1364/OL.36.000894 [doi]
AB  - This study proposes an optical panel with full multitouch using the patterned
      indium tin oxide (ITO) and an algorithm matrix to avoid ghost points. The
      patterned ITOs include the virtual high and low impedances. The algorithm matrix 
      with two configurations of equivalent circuits for array scanning is derived
      using the voltage divider rule. The fabrication process of the multitouch panel
      is carried out using microelectromechanical systems technology. The optical
      characteristics of the multitouch panel in the UV, visible, and IR regions are
      measured using photometric analysis. The multitouch panel, containing sensing
      pixels of 30x30 arrays, has a pixel size of 2x2 mm2 and a pitch distance of 2 mm.
      The average values of high and low impedances are 53.23 and 9.3 k Omega,
      respectively. The maximum transmittance is about 74.2% at the wavelength of 692
      nm. The multitouch panel based on high and low impedance patterns has been
      specifically designed to offer good adjacent touch resolution and sensitivity for
      reality multitouch applications. In addition, the patterned design and the
      algorithm matrix provide unlimited multitouch points and avoid ghost points.
FAU - Chang, Wen-Yang
AU  - Chang WY
AD  - Department of Mechanical and Computer-Aided Engineering, National Formosa
      University, Yunlin , Taiwan. wenyang@nfu.edu.tw
FAU - Lin, Heng-Ju
AU  - Lin HJ
FAU - Chang, Jin-Sheng
AU  - Chang JS
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Opt Lett
JT  - Optics letters
JID - 7708433
EDAT- 2011/03/16 06:00
MHDA- 2011/03/16 06:01
CRDT- 2011/03/16 06:00
AID - 210654 [pii]
PST - ppublish
SO  - Opt Lett. 2011 Mar 15;36(6):894-6. doi: 10.1364/OL.36.000894.

PMID- 21395867
OWN - NLM
STAT- MEDLINE
DA  - 20110516
DCOM- 20110926
IS  - 1460-9568 (Electronic)
IS  - 0953-816X (Linking)
VI  - 33
IP  - 10
DP  - 2011 May
TI  - Alpha band oscillations correlate with illusory self-location induced by virtual 
      reality.
PG  - 1935-43
LID - 10.1111/j.1460-9568.2011.07647.x [doi]
AB  - Neuroscience of the self has focused on high-level mechanisms related to
      language, memory or imagery of the self. However, recent evidence suggests that
      low-level mechanisms such as multisensory and sensorimotor integration may play a
      fundamental role in self-related processing. Here we used virtual reality
      technology and visuo-tactile conflict to study such low-level mechanisms and
      manipulate where participants experienced their self to be localized
      (self-location). Frequency analysis and electrical neuroimaging of co-recorded
      high-resolution electroencephalography revealed body-specific alpha band power
      modulations in bilateral sensorimotor cortices. Furthermore, alpha power in the
      medial prefrontal cortex (mPFC) was correlated with the degree of experimentally 
      manipulated self-location. We argue that these alpha oscillations in sensorimotor
      cortex and mPFC reflect self-location as manipulated through multisensory
      conflict.
CI  - (c) 2011 The Authors. European Journal of Neuroscience (c) 2011 Federation of
      European Neuroscience Societies and Blackwell Publishing Ltd.
FAU - Lenggenhager, Bigna
AU  - Lenggenhager B
AD  - Laboratory of Cognitive Neuroscience, Federal Institute of Technology, Lausanne, 
      Switzerland Department of Neurology, University Hospital, Geneva, Switzerland.
      bigna.lenggenhager@gmail.com
FAU - Halje, Par
AU  - Halje P
FAU - Blanke, Olaf
AU  - Blanke O
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20110313
PL  - France
TA  - Eur J Neurosci
JT  - The European journal of neuroscience
JID - 8918110
SB  - IM
MH  - Behavior/physiology
MH  - Brain Mapping/methods
MH  - Electroencephalography/*methods
MH  - Female
MH  - Humans
MH  - *Illusions
MH  - Male
MH  - *Self Concept
MH  - Touch Perception/*physiology
MH  - *User-Computer Interface
MH  - Visual Perception/physiology
MH  - Young Adult
EDAT- 2011/03/15 06:00
MHDA- 2011/09/29 06:00
CRDT- 2011/03/15 06:00
PHST- 2011/03/13 [aheadofprint]
AID - 10.1111/j.1460-9568.2011.07647.x [doi]
PST - ppublish
SO  - Eur J Neurosci. 2011 May;33(10):1935-43. doi: 10.1111/j.1460-9568.2011.07647.x.
      Epub 2011 Mar 13.

PMID- 21304333
OWN - NLM
STAT- MEDLINE
DA  - 20110209
DCOM- 20110621
IS  - 1524-4040 (Electronic)
IS  - 0148-396X (Linking)
VI  - 68
IP  - 1 Suppl Operative
DP  - 2011 Mar
TI  - Virtual interactive presence and augmented reality (VIPAR) for remote surgical
      assistance.
PG  - 200-7; discussion 207
LID - 10.1227/NEU.0b013e3182077efd [doi]
AB  - BACKGROUND: Surgery is a highly technical field that combines continuous
      decision-making with the coordination of spatiovisual tasks. OBJECTIVE: We
      designed a virtual interactive presence and augmented reality (VIPAR) platform
      that allows a remote surgeon to deliver real-time virtual assistance to a local
      surgeon, over a standard Internet connection. METHODS: The VIPAR system consisted
      of a "local" and a "remote" station, each situated over a surgical field and a
      blue screen, respectively. Each station was equipped with a digital viewpiece,
      composed of 2 cameras for stereoscopic capture, and a high-definition viewer
      displaying a virtual field. The virtual field was created by digitally
      compositing selected elements within the remote field into the local field. The
      viewpieces were controlled by workstations mutually connected by the Internet,
      allowing virtual remote interaction in real time. Digital renderings derived from
      volumetric MRI were added to the virtual field to augment the surgeon's reality. 
      For demonstration, a fixed-formalin cadaver head and neck were obtained, and a
      carotid endarterectomy (CEA) and pterional craniotomy were performed under the
      VIPAR system. RESULTS: The VIPAR system allowed for real-time, virtual
      interaction between a local (resident) and remote (attending) surgeon. In both
      carotid and pterional dissections, major anatomic structures were visualized and 
      identified. Virtual interaction permitted remote instruction for the local
      surgeon, and MRI augmentation provided spatial guidance to both surgeons. Camera 
      resolution, color contrast, time lag, and depth perception were identified as
      technical issues requiring further optimization. CONCLUSION: Virtual interactive 
      presence and augmented reality provide a novel platform for remote surgical
      assistance, with multiple applications in surgical training and remote expert
      assistance.
FAU - Shenai, Mahesh B
AU  - Shenai MB
AD  - Division of Neurosurgery, Department of Surgery, University of
      Alabama-Birmingham, Alabama 35294-3410, USA.
FAU - Dillavou, Marcus
AU  - Dillavou M
FAU - Shum, Corey
AU  - Shum C
FAU - Ross, Douglas
AU  - Ross D
FAU - Tubbs, Richard S
AU  - Tubbs RS
FAU - Shih, Alan
AU  - Shih A
FAU - Guthrie, Barton L
AU  - Guthrie BL
LA  - eng
PT  - Journal Article
PT  - Research Support, U.S. Gov't, Non-P.H.S.
PL  - United States
TA  - Neurosurgery
JT  - Neurosurgery
JID - 7802914
SB  - IM
MH  - Cadaver
MH  - Computer Simulation
MH  - Craniotomy/education/*instrumentation/*methods
MH  - Endarterectomy, Carotid/education/*instrumentation/methods
MH  - Humans
MH  - Robotics/education/instrumentation/*methods
MH  - Software
MH  - Stereotaxic Techniques
MH  - *User-Computer Interface
EDAT- 2011/02/10 06:00
MHDA- 2011/06/22 06:00
CRDT- 2011/02/10 06:00
AID - 10.1227/NEU.0b013e3182077efd [doi]
AID - 00006123-201103001-00027 [pii]
PST - ppublish
SO  - Neurosurgery. 2011 Mar;68(1 Suppl Operative):200-7; discussion 207. doi:
      10.1227/NEU.0b013e3182077efd.

PMID- 21111828
OWN - NLM
STAT- MEDLINE
DA  - 20110131
DCOM- 20110513
LR  - 20150325
IS  - 1095-9572 (Electronic)
IS  - 1053-8119 (Linking)
VI  - 55
IP  - 1
DP  - 2011 Mar 1
TI  - Phasic and sustained fear in humans elicits distinct patterns of brain activity.
PG  - 389-400
LID - 10.1016/j.neuroimage.2010.11.057 [doi]
AB  - Aversive events are typically more debilitating when they occur unpredictably
      than predictably. Studies in humans and animals indicate that predictable and
      unpredictable aversive events can induce phasic and sustained fear, respectively.
      Research in rodents suggests that anatomically related but distinct neural
      circuits may mediate phasic and sustained fear. We explored this issue in humans 
      by examining threat predictability in three virtual reality contexts, one in
      which electric shocks were predictably signaled by a cue, a second in which
      shocks occurred unpredictably but never paired with a cue, and a third in which
      no shocks were delivered. Evidence of threat-induced phasic and sustained fear
      was presented using fear ratings and skin conductance. Utilizing recent advances 
      in functional magnetic resonance imaging (fMRI), we were able to conduct
      whole-brain fMRI at relatively high spatial resolution and still have enough
      sensitivity to detect transient and sustained signal changes in the basal
      forebrain. We found that both predictable and unpredictable threat evoked
      transient activity in the dorsal amygdala, but that only unpredictable threat
      produced sustained activity in a forebrain region corresponding to the bed
      nucleus of the stria terminalis complex. Consistent with animal models
      hypothesizing a role for the cortex in generating sustained fear, sustained
      signal increases to unpredictable threat were also found in anterior insula and a
      frontoparietal cortical network associated with hypervigilance. In addition,
      unpredictable threat led to transient activity in the ventral
      amygdala-hippocampal area and pregenual anterior cingulate cortex, as well as
      transient activation and subsequent deactivation of subgenual anterior cingulate 
      cortex, limbic structures that have been implicated in the regulation of
      emotional behavior and stress responses. In line with basic findings in rodents, 
      these results provide evidence that phasic and sustained fear in humans may
      manifest similar signs of distress, but appear to be associated with different
      patterns of neural activity in the human basal forebrain.
CI  - Copyright (c) 2010 Elsevier Inc. All rights reserved.
FAU - Alvarez, Ruben P
AU  - Alvarez RP
AD  - Mood and Anxiety Disorders Program, National Institute of Mental Health, National
      Institutes of Health, Bethesda, MD, USA. ralvarez@laureateinstitute.org
FAU - Chen, Gang
AU  - Chen G
FAU - Bodurka, Jerzy
AU  - Bodurka J
FAU - Kaplan, Raphael
AU  - Kaplan R
FAU - Grillon, Christian
AU  - Grillon C
LA  - eng
GR  - ZIA MH002798-09/Intramural NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Intramural
DEP - 20101125
PL  - United States
TA  - Neuroimage
JT  - NeuroImage
JID - 9215515
SB  - IM
MH  - Brain/*physiology
MH  - Fear/*physiology
MH  - Humans
MH  - *Magnetic Resonance Imaging
MH  - Male
MH  - Nerve Net/*physiology
MH  - Young Adult
PMC - PMC3100535
MID - NIHMS292873
OID - NLM: NIHMS292873
OID - NLM: PMC3100535
EDAT- 2010/11/30 06:00
MHDA- 2011/05/14 06:00
CRDT- 2010/11/30 06:00
PHST- 2010/04/01 [received]
PHST- 2010/11/09 [revised]
PHST- 2010/11/15 [accepted]
PHST- 2010/11/25 [aheadofprint]
AID - S1053-8119(10)01535-1 [pii]
AID - 10.1016/j.neuroimage.2010.11.057 [doi]
PST - ppublish
SO  - Neuroimage. 2011 Mar 1;55(1):389-400. doi: 10.1016/j.neuroimage.2010.11.057. Epub
      2010 Nov 25.

PMID- 20890294
OWN - NLM
STAT- MEDLINE
DA  - 20101026
DCOM- 20101112
LR  - 20140920
IS  - 1546-1726 (Electronic)
IS  - 1097-6256 (Linking)
VI  - 13
IP  - 11
DP  - 2010 Nov
TI  - Functional imaging of hippocampal place cells at cellular resolution during
      virtual navigation.
PG  - 1433-40
LID - 10.1038/nn.2648 [doi]
AB  - Spatial navigation is often used as a behavioral task in studies of the neuronal 
      circuits that underlie cognition, learning and memory in rodents. The combination
      of in vivo microscopy with genetically encoded indicators has provided an
      important new tool for studying neuronal circuits, but has been technically
      difficult to apply during navigation. Here we describe methods for imaging the
      activity of neurons in the CA1 region of the hippocampus with subcellular
      resolution in behaving mice. Neurons that expressed the genetically encoded
      calcium indicator GCaMP3 were imaged through a chronic hippocampal window.
      Head-restrained mice performed spatial behaviors in a setup combining a virtual
      reality system and a custom-built two-photon microscope. We optically identified 
      populations of place cells and determined the correlation between the location of
      their place fields in the virtual environment and their anatomical location in
      the local circuit. The combination of virtual reality and high-resolution
      functional imaging should allow a new generation of studies to investigate
      neuronal circuit dynamics during behavior.
FAU - Dombeck, Daniel A
AU  - Dombeck DA
AD  - Department of Molecular Biology and Princeton Neuroscience Institute, Princeton
      University, Princeton, New Jersey, USA. ddombeck@princeton.edu
FAU - Harvey, Christopher D
AU  - Harvey CD
FAU - Tian, Lin
AU  - Tian L
FAU - Looger, Loren L
AU  - Looger LL
FAU - Tank, David W
AU  - Tank DW
LA  - eng
GR  - 5R01MH083686-03/MH/NIMH NIH HHS/United States
GR  - R01 MH083686/MH/NIMH NIH HHS/United States
GR  - R01 MH083686-04/MH/NIMH NIH HHS/United States
GR  - Howard Hughes Medical Institute/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, Non-U.S. Gov't
DEP - 20101003
PL  - United States
TA  - Nat Neurosci
JT  - Nature neuroscience
JID - 9809671
RN  - 0 (Synapsins)
RN  - SY7Q814VUP (Calcium)
SB  - IM
CIN - Nat Methods. 2010 Dec;7(12):948-9. PMID: 21158013
MH  - Action Potentials/physiology
MH  - Animals
MH  - Calcium/metabolism
MH  - Cerebral Cortex/physiology
MH  - Dendrites/physiology
MH  - Hippocampus/*cytology
MH  - Image Processing, Computer-Assisted/methods
MH  - Male
MH  - Membrane Potentials/drug effects/physiology
MH  - Mice
MH  - Mice, Inbred C57BL
MH  - Neurons/classification/cytology/*physiology
MH  - Nonlinear Dynamics
MH  - Patch-Clamp Techniques/methods
MH  - Space Perception/*physiology
MH  - Spatial Behavior/*physiology
MH  - Synapsins/genetics/metabolism
MH  - Transduction, Genetic/methods
MH  - User-Computer Interface
PMC - PMC2967725
MID - NIHMS233575
OID - NLM: NIHMS233575
OID - NLM: PMC2967725
EDAT- 2010/10/05 06:00
MHDA- 2010/11/13 06:00
CRDT- 2010/10/05 06:00
PHST- 2010/05/03 [received]
PHST- 2010/09/01 [accepted]
PHST- 2010/10/03 [aheadofprint]
AID - nn.2648 [pii]
AID - 10.1038/nn.2648 [doi]
PST - ppublish
SO  - Nat Neurosci. 2010 Nov;13(11):1433-40. doi: 10.1038/nn.2648. Epub 2010 Oct 3.

PMID- 20802430
OWN - NLM
STAT- MEDLINE
DA  - 20100830
DCOM- 20110204
IS  - 0026-4733 (Print)
IS  - 0026-4733 (Linking)
VI  - 65
IP  - 4
DP  - 2010 Aug
TI  - Role of computer technology in neurosurgery.
PG  - 409-28
AB  - In the clinical office, during surgical planning, or in the operating room,
      neurosurgeons have been surrounded by the digital world either recreating old
      tools or introducing new ones. Technological refinements, chiefly based on the
      use of computer systems, have altered the modus operandi for neurosurgery. In the
      emergency room or in the office, patient data are entered, digitally dictated, or
      gathered from electronic medical records. Images from every modality can be
      examined on a Picture Archiving and Communication System (PACS) or can be seen
      remotely on cell phones. Surgical planning is based on high-resolution
      reconstructions, and microsurgical or radiosurgical approaches can be assessed
      precisely using stereotaxy. Tumor resection, abscess or hematoma evacuation, or
      the management of vascular lesions can be assisted intraoperatively by new
      imaging resources integrated into the surgical microscope. Mathematical models
      can dictate how a lesion may recur as well as how often a particular patient
      should be followed. Finally, virtual reality is being developed as a training
      tool for residents and surgeons by preoperatively simulating complex surgical
      scenarios. Altogether, computerization at each level of patient care has been
      affected by digital technology to help enhance the safety of procedures and
      thereby improve outcomes of patients undergoing neurosurgical procedures.
FAU - Abdelwahab, M G
AU  - Abdelwahab MG
AD  - Barrow Neurological Institute, St. Joseph's Hospital and Medical Center, Phoenix,
      AZ, USA.
FAU - Cavalcanti, D D
AU  - Cavalcanti DD
FAU - Preul, M C
AU  - Preul MC
LA  - eng
PT  - Journal Article
PT  - Review
PL  - Italy
TA  - Minerva Chir
JT  - Minerva chirurgica
JID - 0400726
SB  - IM
MH  - Brain Diseases/surgery
MH  - Computer Simulation
MH  - Humans
MH  - Image Processing, Computer-Assisted
MH  - Nervous System Diseases/*surgery
MH  - Neurosurgery/*trends
MH  - Neurosurgical Procedures/*methods
MH  - Software
MH  - Stereotaxic Techniques
MH  - Surgery, Computer-Assisted/*methods
EDAT- 2010/08/31 06:00
MHDA- 2011/02/05 06:00
CRDT- 2010/08/31 06:00
AID - R06105323 [pii]
PST - ppublish
SO  - Minerva Chir. 2010 Aug;65(4):409-28.

PMID- 20717033
OWN - NLM
STAT- MEDLINE
DA  - 20100909
DCOM- 20110103
IS  - 1531-6998 (Electronic)
IS  - 1068-9508 (Linking)
VI  - 18
IP  - 5
DP  - 2010 Oct
TI  - Laboratory testing of the vestibular system.
PG  - 425-30
LID - 10.1097/MOO.0b013e32833de137 [doi]
AB  - PURPOSE OF REVIEW: Recent reports on vestibular testing, relevant to clinical
      diagnosis, are reviewed.Besides the case history and bedside examination,
      objective measurement of the vestibuloocular reflex in all of its facets remains 
      the cornerstone in the diagnostic process. RECENT FINDINGS: In recent years, this
      has been enhanced considerably by reliable unilateral tests for the otolith
      organs, most notably by vestibular-evoked myogenic potential recording and
      estimation of subjective visual vertical. In addition, progress has been made in 
      the investigation of multisensory interaction, involving visual acuity and
      posturography.Technological developments include improved eye movement
      measurement techniques, electrotactile and vibrotactile sensory enhancement or
      substitution, the use of virtual reality devices and motion stimulators such as
      hexapods and the rediscovery of galvanic vestibular stimulation as a research and
      diagnostic tool. SUMMARY: The recent introduction of new tests, together with the
      development of novel technologies, is gradually increasing the scope of the
      physical and bedside examination of the dizzy patient (see chapter 'Medical
      management of peripheral disorders' in this issue). The use of more complex
      equipment, such as rotating chairs, linear sleds, hexapods and posturography
      platforms, is likely to become limited to specialized laboratories and
      rehabilitation centers in future years. Further, high resolution magnetic
      resonance tomography (MRT) and computed tomography have allowed insight into the 
      morphology and determination of malformations of the human labyrinth.
FAU - Clarke, Andrew H
AU  - Clarke AH
AD  - Vestibular Research Laboratory, Charite Medical School, Berlin, Germany.
      andrew.clarke@charite.de
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PT  - Review
PL  - United States
TA  - Curr Opin Otolaryngol Head Neck Surg
JT  - Current opinion in otolaryngology & head and neck surgery
JID - 9417024
SB  - IM
MH  - Humans
MH  - Reflex, Vestibulo-Ocular/*physiology
MH  - Vestibular Diseases/*diagnosis
MH  - *Vestibular Function Tests
MH  - Vestibule, Labyrinth/*physiopathology
EDAT- 2010/08/19 06:00
MHDA- 2011/01/05 06:00
CRDT- 2010/08/19 06:00
AID - 10.1097/MOO.0b013e32833de137 [doi]
PST - ppublish
SO  - Curr Opin Otolaryngol Head Neck Surg. 2010 Oct;18(5):425-30. doi:
      10.1097/MOO.0b013e32833de137.

PMID- 20548110
OWN - NLM
STAT- MEDLINE
DA  - 20111028
DCOM- 20120120
LR  - 20120424
IS  - 1941-0506 (Electronic)
IS  - 1077-2626 (Linking)
VI  - 17
IP  - 1
DP  - 2011 Jan
TI  - JanusVF: accurate navigation using SCAAT and virtual fiducials.
PG  - 3-13
LID - 10.1109/TVCG.2010.91 [doi]
AB  - Several critical limitations exist in the currently available tracking
      technologies for fully enclosed virtual reality (VR) systems. While several 6DOF 
      tracking projects such as Hedgehog have successfully demonstrated excellent
      accuracy, precision, and robustness within moderate budgets, these projects still
      include elements of hardware that can interfere with the user's visual
      experience. The objective of this project is to design a tracking solution for
      fully enclosed VR displays that achieves comparable performance to available
      commercial solutions but without any artifacts that can obscure the user's view. 
      JanusVF is a tracking solution involving a cooperation of both the hardware
      sensors and the software rendering system. A small, high-resolution camera is
      worn on the user's head, but faces backward (180 degree rotation about vertical
      from the user's perspective). After acquisition of the initial state, the VR
      rendering software draws specific fiducial markers with known size and absolute
      position inside the VR scene. These virtual markers are only drawn behind the
      user and in view of the camera. These fiducials are tracked by ARToolkitPlus and 
      integrated by a single-constraint-at-a-time (SCAAT) filter algorithm to update
      the head pose. Experiments analyzing accuracy, precision, and latency in a
      six-sided CAVE-like system show performance that is comparable to alternative
      commercial technologies.
CI  - (c) 2011 IEEE Published by the IEEE Computer Society
FAU - Hutson, Malcolm
AU  - Hutson M
AD  - University of Louisiana at Lafayette, 537 Cajundome Blvd #239, Lafayette, LA
      70506, USA. malcolm@louisiana.edu
FAU - Reiners, Dirk
AU  - Reiners D
LA  - eng
PT  - Journal Article
PL  - United States
TA  - IEEE Trans Vis Comput Graph
JT  - IEEE transactions on visualization and computer graphics
JID - 9891704
SB  - IM
MH  - *Algorithms
MH  - Computer Graphics
MH  - *Data Display
MH  - Equipment Design/methods
MH  - Humans
MH  - Imaging, Three-Dimensional/*instrumentation
MH  - *Software
MH  - *User-Computer Interface
EDAT- 2010/06/16 06:00
MHDA- 2012/01/21 06:00
CRDT- 2010/06/16 06:00
AID - 10.1109/TVCG.2010.91 [doi]
PST - ppublish
SO  - IEEE Trans Vis Comput Graph. 2011 Jan;17(1):3-13. doi: 10.1109/TVCG.2010.91.

PMID- 20083323
OWN - NLM
STAT- MEDLINE
DA  - 20100805
DCOM- 20110119
IS  - 1872-7565 (Electronic)
IS  - 0169-2607 (Linking)
VI  - 99
IP  - 1
DP  - 2010 Jul
TI  - A comprehensive cytogenetics tutorial program, encompassing changeable G-band
      resolutions.
PG  - 66-74
LID - 10.1016/j.cmpb.2009.12.007 [doi]
AB  - Chromosome analysis is a basic science with medical implication. Karyotyping is a
      procedure to study an individual's chromosome make-up. It is time consuming to
      train students and clinical technologists to recognize patterns of G-banded
      chromosomes because of the dynamic nature of G-band resolutions in different
      metaphase spreads. High resolution G-bands are desirable because they provide
      detailed information for structural analysis. However, it is challenging to
      identify chromosomes at higher resolution levels even for many cytogenetics
      technologists. In response to the need for training students to identify human
      chromosomes at variable G-band resolutions, we present in this paper an advanced 
      version of virtual reality (VR)-based interactive karyotyping program capable of 
      manipulating G-band resolutions for human cytogenetics education. The program can
      generate different metaphase spreads ranging from short and well separate
      chromosomes at low G-band resolutions to long, curved, and overlapped chromosomes
      at high G-band resolutions. Other features include a scoring system, helping
      strategies, and the progress reports. The traditional "cut and paste" karyotyping
      method for chromosome separation is incorporated in the software. This method is 
      compared with the "simple clicking" method which is based on an edge detection
      technique for outlining each chromosome. The comprehensive program is suitable
      for in-depth training of advanced students.
CI  - Copyright 2009 Elsevier Ireland Ltd. All rights reserved.
FAU - Yang, Xiaoli
AU  - Yang X
AD  - Department of Electrical and Computer Engineering, Purdue University Calumet,
      Hammond, IN 46323-2094, USA. yangx@calumet.purdue.edu
FAU - Wen, Ding
AU  - Wen D
FAU - Wu, Xiang
AU  - Wu X
FAU - Zhao, Zhenpeng
AU  - Zhao Z
FAU - Lacny, Jason
AU  - Lacny J
FAU - Tseng, Charles
AU  - Tseng C
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PT  - Research Support, U.S. Gov't, Non-P.H.S.
DEP - 20100118
PL  - Ireland
TA  - Comput Methods Programs Biomed
JT  - Computer methods and programs in biomedicine
JID - 8506513
SB  - IM
MH  - Chromosome Banding/*methods
MH  - Chromosomes, Human/ultrastructure
MH  - Cytogenetics/*education
MH  - Humans
MH  - Karyotyping
MH  - Metaphase
MH  - *Software
EDAT- 2010/01/20 06:00
MHDA- 2011/01/20 06:00
CRDT- 2010/01/20 06:00
PHST- 2009/04/16 [received]
PHST- 2009/12/16 [revised]
PHST- 2009/12/19 [accepted]
PHST- 2010/01/18 [aheadofprint]
AID - S0169-2607(09)00310-1 [pii]
AID - 10.1016/j.cmpb.2009.12.007 [doi]
PST - ppublish
SO  - Comput Methods Programs Biomed. 2010 Jul;99(1):66-74. doi:
      10.1016/j.cmpb.2009.12.007. Epub 2010 Jan 18.

PMID- 20033609
OWN - NLM
STAT- MEDLINE
DA  - 20091224
DCOM- 20100318
LR  - 20141120
IS  - 1861-6429 (Electronic)
IS  - 1861-6410 (Linking)
VI  - 4
IP  - 2
DP  - 2009 Mar
TI  - Inside the beating heart: an in vivo feasibility study on fusing pre- and
      intra-operative imaging for minimally invasive therapy.
PG  - 113-23
LID - 10.1007/s11548-008-0278-6 [doi]
AB  - OBJECTIVE: An interventional system for minimally invasive cardiac surgery was
      developed for therapy delivery inside the beating heart, in absence of direct
      vision. METHOD: A system was developed to provide a virtual reality (VR)
      environment that integrates pre-operative imaging, real-time intra-operative
      guidance using 2D trans-esophageal ultrasound, and models of the surgical tools
      tracked using a magnetic tracking system. Detailed 3D dynamic cardiac models were
      synthesized from high-resolution pre-operative MR data and registered within the 
      intra-operative imaging environment. The feature-based registration technique was
      employed to fuse pre- and intra-operative data during in vivo intracardiac
      procedures on porcine subjects. RESULTS: This method was found to be suitable for
      in vivo applications as it relies on easily identifiable landmarks, and hence, it
      ensures satisfactory alignment of pre- and intra-operative anatomy in the region 
      of interest (4.8 mm RMS alignment accuracy) within the VR environment. Our
      initial experience in translating this work to guide intracardiac interventions, 
      such as mitral valve implantation and atrial septal defect repair demonstrated
      feasibility of the methods. CONCLUSION: Surgical guidance in the absence of
      direct vision and with no exposure to ionizing radiation was achieved, so our
      virtual environment constitutes a feasible candidate for performing various
      off-pump intracardiac interventions.
FAU - Linte, Cristian A
AU  - Linte CA
AD  - Imaging Research Laboratories, Robarts Research Institute, 100 Perth Dr., P.O.
      Box 5015, London, ON, N6A 5K8, Canada. clinte@imaging.robarts.ca
FAU - Moore, John
AU  - Moore J
FAU - Wedlake, Chris
AU  - Wedlake C
FAU - Bainbridge, Daniel
AU  - Bainbridge D
FAU - Guiraudon, Gerard M
AU  - Guiraudon GM
FAU - Jones, Douglas L
AU  - Jones DL
FAU - Peters, Terry M
AU  - Peters TM
LA  - eng
GR  - Canadian Institutes of Health Research/Canada
PT  - Comparative Study
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20081115
PL  - Germany
TA  - Int J Comput Assist Radiol Surg
JT  - International journal of computer assisted radiology and surgery
JID - 101499225
SB  - IM
MH  - Animals
MH  - Cardiac Surgical Procedures/*methods
MH  - Disease Models, Animal
MH  - Feasibility Studies
MH  - Imaging, Three-Dimensional/*methods
MH  - Minimally Invasive Surgical Procedures/*methods
MH  - Monitoring, Intraoperative/*methods
MH  - Preoperative Period
MH  - Reproducibility of Results
MH  - Swine
MH  - *User-Computer Interface
EDAT- 2009/12/25 06:00
MHDA- 2010/03/20 06:00
CRDT- 2009/12/25 06:00
PHST- 2008/01/10 [received]
PHST- 2008/10/07 [accepted]
PHST- 2008/11/15 [aheadofprint]
AID - 10.1007/s11548-008-0278-6 [doi]
PST - ppublish
SO  - Int J Comput Assist Radiol Surg. 2009 Mar;4(2):113-23. doi:
      10.1007/s11548-008-0278-6. Epub 2008 Nov 15.

PMID- 20013851
OWN - NLM
STAT- MEDLINE
DA  - 20100126
DCOM- 20100216
IS  - 1531-4995 (Electronic)
IS  - 0023-852X (Linking)
VI  - 120
IP  - 2
DP  - 2010 Feb
TI  - Virtual reality: a new paranasal sinus surgery simulator.
PG  - 420-6
LID - 10.1002/lary.20676 [doi]
AB  - OBJECTIVES/HYPOTHESIS: Virtual surgical training systems are of growing value.
      Current prototypes for endonasal sinus surgery simulation are very expensive or
      lack running stability. No reliable system is available to a notable number of
      users yet. The purpose of this work was to develop a dependable simulator running
      on standard PC hardware including a detailed anatomic model, realistic tools and 
      handling, stereoscopic view, and force feedback. STUDY DESIGN: Descriptive.
      METHODS: A three-dimensional voxel model was created based on a high-resolution
      computed tomography study of a human skull, from which the bony structures were
      segmented. The mucosa and organs at risk were added manually. The model may be
      manipulated with virtual surgical tools controlled with a low-cost haptic device,
      which is also used to adjust microscopic or endoscopic views. Visualization,
      haptic rendering, and tissue removal are represented with subvoxel resolution.
      RESULTS: The handling of the model is convincing. The haptic device provides a
      realistic feeling regarding the interaction between tool tip and anatomy.
      Three-dimensional orientation and the look and feel of virtual surgical
      interventions get close to reality. CONCLUSIONS: The newly developed system is a 
      stable, fully operational simulator for sinus surgery based on standard PC
      hardware. Besides the limitations of a low-cost haptic device, the presented
      system is highly realistic regarding anatomy, visualization, manipulation, and
      the appearance of the tools. It is mainly intended for gaining surgical anatomy
      knowledge and for training navigation in a complex anatomical environment.
      Learning effects, including motor skills, have yet to be quantified.
FAU - Tolsdorff, Boris
AU  - Tolsdorff B
AD  - Department of Oto-Rhino-Laryngology, Plastic, Aesthetic and Reconstructive Head
      and Neck Surgery, University of Wurzburg, Wurzburg, Germany.
      tolsdorff_b@klinik.uni-wuerzburg.de
FAU - Pommert, Andreas
AU  - Pommert A
FAU - Hohne, Karl Heinz
AU  - Hohne KH
FAU - Petersik, Andreas
AU  - Petersik A
FAU - Pflesser, Bernhard
AU  - Pflesser B
FAU - Tiede, Ulf
AU  - Tiede U
FAU - Leuwer, Rudolf
AU  - Leuwer R
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Laryngoscope
JT  - The Laryngoscope
JID - 8607378
SB  - IM
MH  - *Computer Simulation
MH  - Endoscopy/*education
MH  - Humans
MH  - Otorhinolaryngologic Surgical Procedures/*education
MH  - Paranasal Sinuses/*surgery
MH  - *User-Computer Interface
EDAT- 2009/12/17 06:00
MHDA- 2010/02/17 06:00
CRDT- 2009/12/17 06:00
AID - 10.1002/lary.20676 [doi]
PST - ppublish
SO  - Laryngoscope. 2010 Feb;120(2):420-6. doi: 10.1002/lary.20676.

PMID- 19723144
OWN - NLM
STAT- MEDLINE
DA  - 20090902
DCOM- 20091105
IS  - 1365-2559 (Electronic)
IS  - 0309-0167 (Linking)
VI  - 55
IP  - 3
DP  - 2009 Sep
TI  - Virtual reality Powerwall versus conventional microscope for viewing pathology
      slides: an experimental comparison.
PG  - 294-300
LID - 10.1111/j.1365-2559.2009.03389.x [doi]
AB  - AIMS: Virtual slides could replace the conventional microscope. However, it can
      take 60% longer to make a diagnosis with a virtual slide, due to the small
      display size and inadequate user interface of current systems. The aim was to
      create and test a virtual reality (VR) microscope using a Powerwall (a
      high-resolution array of 28 computer screens) for viewing virtual slides more
      efficiently. METHODS AND RESULTS: A controlled user experiment was performed to
      compare the Powerwall with the microscope for four types of task: (i) a simple
      diagnosis, (ii) a decision about a lymph node, (iii) finding small objects, (iv) 
      scoring a tissue microarray. User behaviour was recorded by video and
      questionnaire. Time taken to perform all four tasks and diagnostic confidence
      were similar using the Powerwall and conventional microscope. CONCLUSIONS: After 
      just a few minutes' familiarization, a VR Powerwall allowed tasks to be performed
      as quickly and confidently as a microscope. Behavioural data indicated how
      histopathologists should be trained to make the best use of the large display
      provided by the VR microscope. Together with the potential for further
      improvements in the design of the VR microscope, future virtual slide systems
      could out-perform conventional microscopes in histopathological diagnosis.
FAU - Treanor, Darren
AU  - Treanor D
AD  - Pathology and Tumour Biology, Leeds Institute of Molecular Medicine, University
      of Leeds, Leeds LS9 7TF, UK. darrentreanor@nhs.net
FAU - Jordan-Owers, Naomi
AU  - Jordan-Owers N
FAU - Hodrien, John
AU  - Hodrien J
FAU - Wood, Jason
AU  - Wood J
FAU - Quirke, Phil
AU  - Quirke P
FAU - Ruddle, Roy A
AU  - Ruddle RA
LA  - eng
GR  - Department of Health/United Kingdom
PT  - Comparative Study
PT  - Evaluation Studies
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - England
TA  - Histopathology
JT  - Histopathology
JID - 7704136
SB  - IM
MH  - Carcinoma, Basal Cell/diagnosis
MH  - Carcinoma, Squamous Cell/diagnosis
MH  - Diagnosis, Differential
MH  - *Diagnostic Techniques and Procedures
MH  - Equipment Design
MH  - Humans
MH  - *Image Processing, Computer-Assisted
MH  - Lymph Nodes/pathology
MH  - Microscopy/instrumentation/*methods
MH  - Pathology, Surgical/instrumentation/*methods
MH  - Skin Neoplasms/diagnosis
MH  - Tissue Array Analysis/methods
MH  - *User-Computer Interface
EDAT- 2009/09/03 06:00
MHDA- 2009/11/06 06:00
CRDT- 2009/09/03 09:00
AID - HIS3389 [pii]
AID - 10.1111/j.1365-2559.2009.03389.x [doi]
PST - ppublish
SO  - Histopathology. 2009 Sep;55(3):294-300. doi: 10.1111/j.1365-2559.2009.03389.x.

PMID- 19706630
OWN - NLM
STAT- MEDLINE
DA  - 20090914
DCOM- 20091026
IS  - 1471-6771 (Electronic)
IS  - 0007-0912 (Linking)
VI  - 103
IP  - 4
DP  - 2009 Oct
TI  - Virtual reality-based simulator for training in regional anaesthesia.
PG  - 594-600
LID - 10.1093/bja/aep224 [doi]
AB  - BACKGROUND: The safe performance of regional anaesthesia (RA) requires
      theoretical knowledge and good manual skills. Virtual reality (VR)-based
      simulators may offer trainees a safe environment to learn and practice different 
      techniques. However, currently available VR simulators do not consider individual
      anatomy, which limits their use for realistic training. We have developed a
      VR-based simulator that can be used for individual anatomy and for different
      anatomical regions. METHODS: Individual data were obtained from magnetic
      resonance imaging (MRI) and magnetic resonance angiography (MRA) without contrast
      agent to represent morphology and the vascular system, respectively. For data
      handling, registration, and segmentation, an application based on the Medical
      Imaging Interaction Toolkit was developed. Suitable segmentation algorithms such 
      as the fuzzy c-means clustering approach were integrated, and a hierarchical tree
      data structure was created to model the flexible anatomical structures of
      peripheral nerve cords. The simulator was implemented in the VR toolkit ViSTA
      using modules for collision detection, virtual humanoids, interaction, and
      visualization. A novel algorithm for electric impulse transmission is the core of
      the simulation. RESULTS: In a feasibility study, MRI morphology and MRA were
      acquired from five subjects for the inguinal region. From these sources,
      three-dimensional anatomical data sets were created and nerves modelled. The
      resolution obtained from both MRI and MRA was sufficient for realistic
      simulations. Our high-fidelity simulator application allows trainees to perform
      virtual peripheral nerve blocks based on these data sets and models. CONCLUSIONS:
      Subject-specific training of RA is supported in a virtual environment. We have
      adapted segmentation algorithms and developed a VR-based simulator for the
      inguinal region for use in training for different peripheral nerve blocks. In
      contrast to available VR-based simulators, our simulation offers anatomical
      variety.
FAU - Grottke, O
AU  - Grottke O
AD  - Department of Anaesthesiology, Institute for Laboratory Animal Science, RWTH
      Aachen University Hospital, Germany. ogrottke@ukaachen.de
FAU - Ntouba, A
AU  - Ntouba A
FAU - Ullrich, S
AU  - Ullrich S
FAU - Liao, W
AU  - Liao W
FAU - Fried, E
AU  - Fried E
FAU - Prescher, A
AU  - Prescher A
FAU - Deserno, T M
AU  - Deserno TM
FAU - Kuhlen, T
AU  - Kuhlen T
FAU - Rossaint, R
AU  - Rossaint R
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20090825
PL  - England
TA  - Br J Anaesth
JT  - British journal of anaesthesia
JID - 0372541
SB  - IM
MH  - Adolescent
MH  - Adult
MH  - Algorithms
MH  - Anesthesia, Conduction/*standards
MH  - Anesthesiology/*education
MH  - *Computer Simulation
MH  - Education, Medical, Graduate/*methods
MH  - Feasibility Studies
MH  - Female
MH  - Humans
MH  - Inguinal Canal/blood supply/innervation
MH  - Magnetic Resonance Angiography
MH  - Magnetic Resonance Imaging
MH  - Male
MH  - User-Computer Interface
MH  - Young Adult
EDAT- 2009/08/27 09:00
MHDA- 2009/10/27 06:00
CRDT- 2009/08/27 09:00
PHST- 2009/08/25 [aheadofprint]
AID - aep224 [pii]
AID - 10.1093/bja/aep224 [doi]
PST - ppublish
SO  - Br J Anaesth. 2009 Oct;103(4):594-600. doi: 10.1093/bja/aep224. Epub 2009 Aug 25.

PMID- 19592749
OWN - NLM
STAT- In-Data-Review
DA  - 20090713
IS  - 0926-9630 (Print)
IS  - 0926-9630 (Linking)
VI  - 144
DP  - 2009
TI  - Transcranial Doppler: a non-invasive tool for monitoring brain activity in
      virtual reality therapy.
PG  - 133-7
AB  - In this work, we propose the use of Transcranial Doppler Monitoring (TCD) as a
      tool to measure brain activity during the exposure to Virtual Environments (VE)
      used in clinical therapy sessions. The technique is non-invasive, and can be
      easily integrated with Virtual Reality (VR) settings. Moreover, it provides a
      high temporal resolution, which grants the possibility to analyze changes in
      brain activity during the evolution of a clinical session and to correlate them
      with specific events that may occur in the VE. We have performed two studies
      combining TCD with VR. Results of these studies show that it is feasible to use
      this technique in combination with VR settings designed for virtual therapy. It
      was observed that immersion and navigation modifications in the VE generated
      changes in brain activity that can be detected using TCD.
FAU - Rey, Beatriz
AU  - Rey B
AD  - Instituto en Bioingenieria y Tecnologia Orientada al Ser Humano, Universidad
      Politecnica de Valencia, Camino Vera s/n, 46022 Valencia, Spain.
FAU - Parkhutik, Vera
AU  - Parkhutik V
FAU - Alcaniz, Mario
AU  - Alcaniz M
FAU - Tembl, Jose
AU  - Tembl J
FAU - Naranjo, Valery
AU  - Naranjo V
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - T
EDAT- 2009/07/14 09:00
MHDA- 2009/07/14 09:00
CRDT- 2009/07/14 09:00
PST - ppublish
SO  - Stud Health Technol Inform. 2009;144:133-7.

PMID- 19574833
OWN - NLM
STAT- MEDLINE
DA  - 20090703
DCOM- 20090915
IS  - 1524-4040 (Electronic)
IS  - 0148-396X (Linking)
VI  - 65
IP  - 1
DP  - 2009 Jul
TI  - Prediction of surgical view of neurovascular decompression using interactive
      computer graphics.
PG  - 121-8; discussion 128-9
LID - 10.1227/01.NEU.0000347890.19718.0A [doi]
AB  - OBJECTIVE: To assess the value of an interactive visualization method for
      detecting the offending vessels in neurovascular compression syndrome in patients
      with facial spasm and trigeminal neuralgia. Computer graphics models are created 
      by fusion of fast imaging employing steady-state acquisition and magnetic
      resonance angiography. METHODS: High-resolution magnetic resonance angiography
      and fast imaging employing steady-state acquisition were performed preoperatively
      in 17 patients with neurovascular compression syndromes (facial spasm, n = 10;
      trigeminal neuralgia, n = 7) using a 3.0-T magnetic resonance imaging scanner.
      Computer graphics models were created with computer software and observed
      interactively for detection of offending vessels by rotation, enlargement,
      reduction, and retraction on a graphic workstation. Two-dimensional images were
      reviewed by 2 radiologists blinded to the clinical details, and 2 neurosurgeons
      predicted the offending vessel with the interactive visualization method before
      surgery. Predictions from the 2 imaging approaches were compared with surgical
      findings. The vessels identified during surgery were assumed to be the true
      offending vessels. RESULTS: Offending vessels were identified correctly in 16 of 
      17 patients (94%) using the interactive visualization method and in 10 of 17
      patients using 2-dimensional images. These data demonstrated a significant
      difference (P = 0.015 by Fisher's exact method). CONCLUSION: The interactive
      visualization method data corresponded well with surgical findings (surgical
      field, offending vessels, and nerves). Virtual reality 3-dimensional computer
      graphics using fusion magnetic resonance angiography and fast imaging employing
      steady-state acquisition may be helpful for preoperative simulation.
FAU - Kin, Taichi
AU  - Kin T
AD  - Department of Neurosurgery, University of Tokyo, Tokyo, Japan.
      tkin-tky@umin.ac.jp
FAU - Oyama, Hiroshi
AU  - Oyama H
FAU - Kamada, Kyousuke
AU  - Kamada K
FAU - Aoki, Shigeki
AU  - Aoki S
FAU - Ohtomo, Kuni
AU  - Ohtomo K
FAU - Saito, Nobuhito
AU  - Saito N
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Neurosurgery
JT  - Neurosurgery
JID - 7802914
SB  - IM
MH  - Adult
MH  - Aged
MH  - Decompression, Surgical/methods
MH  - Female
MH  - Hemifacial Spasm/*radiography/surgery
MH  - Humans
MH  - Image Processing, Computer-Assisted/*methods
MH  - Magnetic Resonance Angiography/*methods
MH  - Magnetic Resonance Imaging/methods
MH  - Male
MH  - Microcirculation
MH  - Middle Aged
MH  - Predictive Value of Tests
MH  - Preoperative Care/*methods
MH  - Retrospective Studies
MH  - Surgery, Computer-Assisted/methods
MH  - Trigeminal Neuralgia/*radiography/surgery
EDAT- 2009/07/04 09:00
MHDA- 2009/09/16 06:00
CRDT- 2009/07/04 09:00
AID - 10.1227/01.NEU.0000347890.19718.0A [doi]
AID - 00006123-200907000-00024 [pii]
PST - ppublish
SO  - Neurosurgery. 2009 Jul;65(1):121-8; discussion 128-9. doi:
      10.1227/01.NEU.0000347890.19718.0A.

PMID- 19408999
OWN - NLM
STAT- MEDLINE
DA  - 20090504
DCOM- 20090728
LR  - 20141120
IS  - 1092-0684 (Electronic)
IS  - 1092-0684 (Linking)
VI  - 26
IP  - 5
DP  - 2009 May
TI  - Minimally invasive superficial temporal artery to middle cerebral artery bypass
      through a minicraniotomy: benefit of three-dimensional virtual reality planning
      using magnetic resonance angiography.
PG  - E20
LID - 10.3171/2009.2.FOCUS0917 [doi]
AB  - OBJECT: The aim of the authors in this study was to introduce a minimally
      invasive superficial temporal artery to middle cerebral artery (STA-MCA) bypass
      surgery by the preselection of appropriate donor and recipient branches in a 3D
      virtual reality setting based on 3-T MR angiography data. METHODS: An STA-MCA
      anastomosis was performed in each of 5 patients. Before surgery, 3-T MR imaging
      was performed with 3D magnetization-prepared rapid acquisition gradient echo
      sequences, and a high-resolution CT 3D dataset was obtained. Image fusion and the
      construction of a 3D virtual reality model of each patient were completed.
      RESULTS: In the 3D virtual reality setting, the skin surface, skull surface, and 
      extra- and intracranial arteries as well as the cortical brain surface could be
      displayed in detail. The surgical approach was successfully visualized in virtual
      reality. The anatomical relationship of structures of interest could be evaluated
      based on different values of translucency in all cases. The closest point of the 
      appropriate donor branch of the STA and the most suitable recipient M(3) or M(4) 
      segment could be calculated with high accuracy preoperatively and determined as
      the center point of the following minicraniotomy. Localization of the craniotomy 
      and the skin incision on top of the STA branch was calculated with the system,
      and these data were transferred onto the patient's skin before surgery. In all
      cases the preselected arteries could be found intraoperatively in exact agreement
      with the preoperative planning data. Successful extracranial-intracranial bypass 
      surgery was achieved without stereotactic neuronavigation via a preselected
      minimally invasive approach in all cases. Subsequent enlargement of the
      craniotomy was not necessary. Perioperative complications were not observed. All 
      bypasses remained patent on follow-up. CONCLUSIONS: With the application of a 3D 
      virtual reality planning system, the extent of skin incision and tissue trauma as
      well as the size of the bone flap was minimal. The closest point of the
      appropriate donor branch of the STA and the most suitable recipient M(3) or M(4) 
      segment could be preoperatively determined with high accuracy so that the STA-MCA
      bypass could be safely and effectively performed through an optimally located
      minicraniotomy with a mean diameter of 22 mm without the need for stereotactic
      guidance.
FAU - Fischer, Gerrit
AU  - Fischer G
AD  - Neurochirurgische Klinik und Poliklinik, Universitaetsmedizin,
      Johannes-Gutenberg-Universitaet, Mainz, Germany. gerrit.fischer@gmx.de
FAU - Stadie, Axel
AU  - Stadie A
FAU - Schwandt, Eike
AU  - Schwandt E
FAU - Gawehn, Joachim
AU  - Gawehn J
FAU - Boor, Stephan
AU  - Boor S
FAU - Marx, Juergen
AU  - Marx J
FAU - Oertel, Joachim
AU  - Oertel J
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Neurosurg Focus
JT  - Neurosurgical focus
JID - 100896471
SB  - IM
MH  - Aged
MH  - Cerebral Revascularization/*methods
MH  - Craniotomy/methods
MH  - Humans
MH  - Imaging, Three-Dimensional/*methods
MH  - Infarction, Middle Cerebral Artery/*pathology/physiopathology/*surgery
MH  - Intracranial Aneurysm/diagnosis/pathology/physiopathology
MH  - Magnetic Resonance Angiography/instrumentation/methods
MH  - Male
MH  - Middle Aged
MH  - Middle Cerebral Artery/pathology/physiopathology/surgery
MH  - Minimally Invasive Surgical Procedures/instrumentation/methods
MH  - Predictive Value of Tests
MH  - Preoperative Care/instrumentation/*methods
MH  - Temporal Arteries/anatomy & histology/physiology/surgery
MH  - *User-Computer Interface
EDAT- 2009/05/05 09:00
MHDA- 2009/07/29 09:00
CRDT- 2009/05/05 09:00
AID - 10.3171/2009.2.FOCUS0917 [doi]
PST - ppublish
SO  - Neurosurg Focus. 2009 May;26(5):E20. doi: 10.3171/2009.2.FOCUS0917.

PMID- 19285400
OWN - NLM
STAT- MEDLINE
DA  - 20090416
DCOM- 20090629
LR  - 20140831
IS  - 1879-0445 (Electronic)
IS  - 0960-9822 (Linking)
VI  - 19
IP  - 7
DP  - 2009 Apr 14
TI  - Decoding neuronal ensembles in the human hippocampus.
PG  - 546-54
LID - 10.1016/j.cub.2009.02.033 [doi]
AB  - BACKGROUND: The hippocampus underpins our ability to navigate, to form and
      recollect memories, and to imagine future experiences. How activity across
      millions of hippocampal neurons supports these functions is a fundamental
      question in neuroscience, wherein the size, sparseness, and organization of the
      hippocampal neural code are debated. RESULTS: Here, by using multivariate pattern
      classification and high spatial resolution functional MRI, we decoded activity
      across the population of neurons in the human medial temporal lobe while
      participants navigated in a virtual reality environment. Remarkably, we could
      accurately predict the position of an individual within this environment solely
      from the pattern of activity in his hippocampus even when visual input and task
      were held constant. Moreover, we observed a dissociation between responses in the
      hippocampus and parahippocampal gyrus, suggesting that they play differing roles 
      in navigation. CONCLUSIONS: These results show that highly abstracted
      representations of space are expressed in the human hippocampus. Furthermore, our
      findings have implications for understanding the hippocampal population code and 
      suggest that, contrary to current consensus, neuronal ensembles representing
      place memories must be large and have an anisotropic structure.
FAU - Hassabis, Demis
AU  - Hassabis D
AD  - Wellcome Trust Centre for Neuroimaging, Institute of Neurology, University
      College London, 12 Queen Square, London WC1N 3BG, UK.
      d.hassabis@fil.ion.ucl.ac.uk
FAU - Chu, Carlton
AU  - Chu C
FAU - Rees, Geraint
AU  - Rees G
FAU - Weiskopf, Nikolaus
AU  - Weiskopf N
FAU - Molyneux, Peter D
AU  - Molyneux PD
FAU - Maguire, Eleanor A
AU  - Maguire EA
LA  - eng
GR  - 082334/Wellcome Trust/United Kingdom
GR  - 084218/Wellcome Trust/United Kingdom
GR  - Wellcome Trust/United Kingdom
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20090312
PL  - England
TA  - Curr Biol
JT  - Current biology : CB
JID - 9107782
SB  - IM
MH  - Action Potentials/*physiology
MH  - Adult
MH  - *Hippocampus/cytology/physiology
MH  - Humans
MH  - Magnetic Resonance Imaging
MH  - Motor Activity/physiology
MH  - Multivariate Analysis
MH  - Nerve Net/anatomy & histology/physiology
MH  - Neurons/cytology/physiology
MH  - Orientation/*physiology
MH  - Space Perception/physiology
MH  - Synaptic Transmission/physiology
MH  - Young Adult
PMC - PMC2670980
OID - NLM: PMC2670980
EDAT- 2009/03/17 09:00
MHDA- 2009/06/30 09:00
CRDT- 2009/03/17 09:00
PHST- 2008/10/22 [received]
PHST- 2009/01/27 [revised]
PHST- 2009/02/10 [accepted]
PHST- 2009/03/12 [aheadofprint]
AID - S0960-9822(09)00741-6 [pii]
AID - 10.1016/j.cub.2009.02.033 [doi]
PST - ppublish
SO  - Curr Biol. 2009 Apr 14;19(7):546-54. doi: 10.1016/j.cub.2009.02.033. Epub 2009
      Mar 12.

PMID- 19177381
OWN - NLM
STAT- MEDLINE
DA  - 20090129
DCOM- 20090226
LR  - 20100930
IS  - 1935-9780 (Electronic)
IS  - 1935-9772 (Linking)
VI  - 1
IP  - 2
DP  - 2008 Mar-Apr
TI  - Transforming clinical imaging data for virtual reality learning objects.
PG  - 50-5
LID - 10.1002/ase.13 [doi]
AB  - Advances in anatomical informatics, three-dimensional (3D) modeling, and virtual 
      reality (VR) methods have made computer-based structural visualization a
      practical tool for education. In this article, the authors describe streamlined
      methods for producing VR "learning objects," standardized interactive software
      modules for anatomical sciences education, from newer high-resolution clinical
      imaging systems data. The key program is OsiriX, a free radiological image
      processing workstation software capable of directly reformatting and rendering
      volumetric 3D images. The transformed image arrays are then directly loaded into 
      a commercial VR program to produce a variety of learning objects. Multiple types 
      or "dimensions" of anatomical information can be embedded in these objects to
      provide different kinds of functions, including interactive atlases, examination 
      questions, and complex, multistructure presentations. The use of clinical imaging
      data and workstation software speeds up the production of VR simulations,
      compared with reconstruction-based modeling from segmented cadaver
      cross-sections, while providing useful examples of normal structural variation
      and pathological anatomy.
FAU - Trelease, Robert B
AU  - Trelease RB
AD  - Department of Pathology and Laboratory Medicine, UCLA Center for the Health
      Sciences, Los Angeles, California, USA. trelease@ucla.edu
FAU - Rosset, Antoine
AU  - Rosset A
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Anat Sci Educ
JT  - Anatomical sciences education
JID - 101392205
SB  - IM
MH  - Anatomy/*education
MH  - Computer Graphics
MH  - *Computer Simulation
MH  - *Computer-Assisted Instruction
MH  - Humans
MH  - Image Processing, Computer-Assisted
MH  - Imaging, Three-Dimensional
MH  - Magnetic Resonance Imaging
MH  - *Medical Informatics
MH  - *Models, Anatomic
MH  - Software
MH  - Tomography, X-Ray Computed
MH  - *User-Computer Interface
EDAT- 2009/01/30 09:00
MHDA- 2009/02/27 09:00
CRDT- 2009/01/30 09:00
AID - 10.1002/ase.13 [doi]
PST - ppublish
SO  - Anat Sci Educ. 2008 Mar-Apr;1(2):50-5. doi: 10.1002/ase.13.

PMID- 18999974
OWN - NLM
STAT- MEDLINE
DA  - 20091203
DCOM- 20091229
IS  - 1092-6429 (Print)
IS  - 1092-6429 (Linking)
VI  - 19 Suppl 1
DP  - 2009 Apr
TI  - A virtual reality environment for patient data visualization and endoscopic
      surgical planning.
PG  - S211-7
LID - 10.1089/lap.2008.0159 [doi]
AB  - Visualizing patient data in a three-dimensional (3D) representation can be an
      effective surgical planning tool.As medical imaging technologies improve with
      faster and higher resolution scans, the use of virtual reality for interacting
      with medical images adds another level of realism to a 3D representation. The
      software framework presented in this paper is designed to load and display any
      DICOM/PACS-compatible 3D image data for visualization and interaction in an
      immersive virtual environment. In "examiner" mode, the surgeon can interact with 
      a 3D virtual model of the patient by using an intuitive set of controls designed 
      to allow slicing, coloring,and windowing of the image to show different tissue
      densities and enhance important structures. In the simulated"endoscopic camera"
      mode, the surgeon can see through the point of view of a virtual endoscopic
      camera to navigate inside the patient. These tools allow the surgeon to perform
      virtual endoscopy on any suitable structure.The software is highly scalable, as
      it can be used on a single desktop computer to a cluster of computers in an
      immersive multiprojection virtual environment. By wearing a pair of stereo
      glasses, a surgeon becomes immersed within the model itself, thus providing a
      sense of realism, as if the surgeon is "inside" the patient.
FAU - Foo, Jung-Leng
AU  - Foo JL
AD  - Virtual Reality Applications Center, Iowa State University, Ames, Iowa, USA.
      foo@iastate.edu
FAU - Lobe, Thom
AU  - Lobe T
FAU - Winer, Eliot
AU  - Winer E
LA  - eng
PT  - Journal Article
PL  - United States
TA  - J Laparoendosc Adv Surg Tech A
JT  - Journal of laparoendoscopic & advanced surgical techniques. Part A
JID - 9706293
SB  - IM
MH  - *Endoscopy
MH  - Humans
MH  - Software
MH  - *Surgical Procedures, Operative
MH  - *User-Computer Interface
EDAT- 2008/11/13 09:00
MHDA- 2009/12/30 06:00
CRDT- 2008/11/13 09:00
AID - 10.1089/lap.2008.0159 [doi]
PST - ppublish
SO  - J Laparoendosc Adv Surg Tech A. 2009 Apr;19 Suppl 1:S211-7. doi:
      10.1089/lap.2008.0159.

PMID- 18431862
OWN - NLM
STAT- MEDLINE
DA  - 20080423
DCOM- 20080522
IS  - 0926-9630 (Print)
IS  - 0926-9630 (Linking)
VI  - 131
DP  - 2008
TI  - Telerehabilitation: current perspectives.
PG  - 191-209
AB  - Telerehabilitation in which rehabilitation services are provided at a distance
      using communication technologies is a new and developing field of telehealth.
      Primarily developed to provide equitable access to individuals who are
      geographically remote and to those who are physically and economically
      disadvantaged, telerehabilitation also has the capacity to improve the quality of
      rehabilitation health care. Online delivery of rehabilitation enables the
      rehabilitation therapist to optimize the timing, intensity and duration of
      therapy that is often not possible within the constraints of face-to-face
      treatment protocols in current health systems. This chapter outlines the advances
      made to date in telerehabilitation applications in the fields of physiotherapy,
      speech-language pathology, occupational therapy, and biomedical engineering and
      provides evidence for the success of these applications. Applications to date
      encompass systems ranging from low-bandwidth low-cost videophones, to highly
      expensive, fully immersive virtual reality systems with haptic interfaces. A
      number of barriers to the establishment and advancement of telerehabilitation
      within health care systems have been outlined and include professional issues
      relating to the inherent hands-on approach of some treatments, licensure laws,
      professional skill development, patient disability, reimbursement, and the
      paucity of online assessment and treatment tools and outcomes data. In response, 
      possible solutions to these barriers such as the development and validation of
      alternative assessment and treatment procedures, involvement in the international
      policy debate, as well as the resolution of national professional policies which 
      hinder the wider uptake of telerehabilitation technologies, have been outlined.
      The future of telerehabilitation is promising as a new, yet complex form of
      telehealth with the capacity to provide a wide range of services specifically
      designed to suit the needs of the individual.
FAU - Theodoros, Deborah
AU  - Theodoros D
AD  - Division of Speech Pathology, School of Health and Rehabilitation Services,
      University of Queensland, Brisbane, Australia. d.theodoros@uq.edu.au
FAU - Russell, Trevor
AU  - Russell T
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - T
MH  - Humans
MH  - Monitoring, Physiologic/methods
MH  - Rehabilitation/*methods
MH  - Telemedicine/*methods
MH  - Videoconferencing
EDAT- 2008/04/25 09:00
MHDA- 2008/05/23 09:00
CRDT- 2008/04/25 09:00
PST - ppublish
SO  - Stud Health Technol Inform. 2008;131:191-209.

PMID- 18238210
OWN - NLM
STAT- PubMed-not-MEDLINE
DA  - 20080201
DCOM- 20121002
IS  - 1083-4419 (Print)
IS  - 1083-4419 (Linking)
VI  - 33
IP  - 4
DP  - 2003
TI  - Superresolution modeling using an omnidirectional image sensor.
PG  - 607-15
LID - 10.1109/TSMCB.2003.814285 [doi]
AB  - Recently, many virtual reality and robotics applications have been called on to
      create virtual environments from real scenes. A catadioptric omnidirectional
      image sensor composed of a convex mirror can simultaneously observe a 360-degree 
      field of view making it useful for modeling man-made environments such as rooms, 
      corridors, and buildings, because any landmarks around the sensor can be taken in
      and tracked in its large field of view. However, the angular resolution of the
      omnidirectional image is low because of the large field of view captured. Hence, 
      the resolution of surface texture patterns on the three-dimensional (3-D) scene
      model generated is not sufficient for monitoring details. To overcome this, we
      propose a high resolution scene texture generation method that combines an
      omnidirectional image sequence using image mosaic and superresolution techniques.
FAU - Nagahara, H
AU  - Nagahara H
AD  - Graduate Sch. of Eng. Sci., Osaka Univ., Japan.
FAU - Yagi, Y
AU  - Yagi Y
FAU - Yachida, M
AU  - Yachida M
LA  - eng
PT  - Journal Article
PL  - United States
TA  - IEEE Trans Syst Man Cybern B Cybern
JT  - IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a
      publication of the IEEE Systems, Man, and Cybernetics Society
JID - 9890044
EDAT- 2008/02/02 09:00
MHDA- 2008/02/02 09:01
CRDT- 2008/02/02 09:00
AID - 10.1109/TSMCB.2003.814285 [doi]
PST - ppublish
SO  - IEEE Trans Syst Man Cybern B Cybern. 2003;33(4):607-15. doi:
      10.1109/TSMCB.2003.814285.

PMID- 17886549
OWN - NLM
STAT- MEDLINE
DA  - 20070924
DCOM- 20071011
IS  - 0022-3085 (Print)
IS  - 0022-3085 (Linking)
VI  - 107
IP  - 3
DP  - 2007 Sep
TI  - Accuracy of ventriculostomy catheter placement using a head- and hand-tracked
      high-resolution virtual reality simulator with haptic feedback.
PG  - 515-21
AB  - OBJECT: The purpose of this study was to evaluate the accuracy of ventriculostomy
      catheter placement on a head- and hand-tracked high-resolution and
      high-performance virtual reality and haptic technology workstation. METHODS:
      Seventy-eight fellows and residents performed simulated ventriculostomy catheter 
      placement on an ImmersiveTouch system. The virtual catheter was placed into a
      virtual patient's head derived from a computed tomography data set. Participants 
      were allowed one attempt each. The distance from the tip of the catheter to the
      Monro foramen was measured. RESULTS: The mean distance (+/- standard deviation)
      from the final position of the catheter tip to the Monro foramen was 16.09 mm
      (+/- 7.85 mm). CONCLUSIONS: The accuracy of virtual ventriculostomy catheter
      placement achieved by participants using the simulator is comparable to the
      accuracy reported in a recent retrospective evaluation of free-hand
      ventriculostomy placements in which the mean distance from the catheter tip to
      the Monro foramen was 16 mm (+/- 9.6 mm).
FAU - Banerjee, P Pat
AU  - Banerjee PP
AD  - Department of Mechanical and Industrial Engineering, College of Engineering,
      University of Illinois at Chicago 60607, USA. banerjee@uic.edu
FAU - Luciano, Cristian J
AU  - Luciano CJ
FAU - Lemole, G Michael Jr
AU  - Lemole GM Jr
FAU - Charbel, Fady T
AU  - Charbel FT
FAU - Oh, Michael Y
AU  - Oh MY
LA  - eng
PT  - Evaluation Studies
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PT  - Research Support, U.S. Gov't, Non-P.H.S.
PL  - United States
TA  - J Neurosurg
JT  - Journal of neurosurgery
JID - 0253357
SB  - AIM
SB  - IM
MH  - *Catheterization
MH  - Clinical Competence
MH  - Computer Simulation
MH  - Computer-Assisted Instruction/*instrumentation
MH  - Feedback
MH  - Humans
MH  - *Internship and Residency
MH  - Neuronavigation/*education
MH  - Reproducibility of Results
MH  - *User-Computer Interface
MH  - Ventriculostomy/*education
EDAT- 2007/09/25 09:00
MHDA- 2007/10/12 09:00
CRDT- 2007/09/25 09:00
AID - 10.3171/JNS-07/09/0515 [doi]
PST - ppublish
SO  - J Neurosurg. 2007 Sep;107(3):515-21.

PMID- 17762746
OWN - NLM
STAT- MEDLINE
DA  - 20070831
DCOM- 20070925
LR  - 20081121
IS  - 1524-4040 (Electronic)
IS  - 0148-396X (Linking)
VI  - 61
IP  - 2
DP  - 2007 Aug
TI  - Differential rate of recovery in athletes after first and second concussion
      episodes.
PG  - 338-44; discussion 344
AB  - OBJECTIVE: Clinical observations suggest that a history of previous concussions
      may cause a slower recovery of neurological function after recurrent concussion
      episodes. However, direct examination of this notion has not been provided. This 
      report investigates the differential rate of restoring the visual-kinesthetic
      integration in collegiate athletes experiencing single versus recurrent
      concussion episodes. METHODS: One hundred sixty collegiate athletes were tested
      preseason using multimodal research methodology. Of these, 38 experienced mild
      traumatic brain injury (MTBI) and were tested on Days 10, 15, and 30 after
      injury. Nine of these MTBI patients experienced a second MTBI within 1 year after
      the first brain injury and were retested. The postconcussion symptoms checklist, 
      neuropsychological evaluations, and postural responses to visual field motion
      were recorded using a virtual reality environment. RESULTS: All patients were
      asymptomatic at Day 10 of testing and were cleared for sport participation based 
      on clinical symptoms resolution. Balance deficits, as evident by incoherence with
      visual field motion postural responses, were present at least 30 days after
      injury (P < 0.001). Most importantly, the rate of balance symptoms restoration
      was significantly reduced after a recurrent, second concussion (P < 0.001)
      compared with those after the first concussion. CONCLUSION: The findings of this 
      study confirm our previous research indicating the presence of long-term residual
      visual-motor disintegration in concussed individuals with normal
      neuropsychological measures. Most importantly, athletes with a history of
      previous concussion demonstrate significantly slower rates of recovery of
      neurological functions after the second episode of MTBI.
FAU - Slobounov, Semyon
AU  - Slobounov S
AD  - Department of Kinesiology, Pennsylvania State University, University Park,
      Pennsylvania 16802, USA. sms18@psu.edu
FAU - Slobounov, Elena
AU  - Slobounov E
FAU - Sebastianelli, Wayne
AU  - Sebastianelli W
FAU - Cao, Cheng
AU  - Cao C
FAU - Newell, Karl
AU  - Newell K
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Neurosurgery
JT  - Neurosurgery
JID - 7802914
SB  - IM
MH  - Adolescent
MH  - Adult
MH  - Athletic Injuries/*diagnosis/*physiopathology
MH  - Brain Concussion/*diagnosis/*physiopathology
MH  - Diagnostic Techniques, Neurological/instrumentation
MH  - Female
MH  - Humans
MH  - Kinesthesis
MH  - Longitudinal Studies
MH  - Male
MH  - Models, Biological
MH  - Postural Balance
MH  - Posture
MH  - Psychomotor Performance
MH  - *Recovery of Function
MH  - Recurrence
MH  - User-Computer Interface
MH  - Visual Fields
EDAT- 2007/09/01 09:00
MHDA- 2007/09/26 09:00
CRDT- 2007/09/01 09:00
AID - 10.1227/01.NEU.0000280001.03578.FF [doi]
AID - 00006123-200708000-00014 [pii]
PST - ppublish
SO  - Neurosurgery. 2007 Aug;61(2):338-44; discussion 344.

PMID- 17619246
OWN - NLM
STAT- MEDLINE
DA  - 20070716
DCOM- 20070810
LR  - 20131121
IS  - 1478-596X (Electronic)
IS  - 1478-5951 (Linking)
VI  - 3
IP  - 2
DP  - 2007 Jun
TI  - Virtual surgery simulation for medical training using multi-resolution organ
      models.
PG  - 149-58
AB  - BACKGROUND: Real-time simulation of organ deformation is one of the biggest
      challenges in virtual surgery, due to the conflicting requirements of real-time
      interactivity and simulation realism. In this paper we propose a method to
      overcome this challenge by introducing a multi-resolution modelling technique.
      METHODS: In our approach a reasonably coarse global model is locally enhanced,
      using a mesh subdivision and smoothing algorithm. The global model is based on a 
      discretization of the boundary integral representation of three-dimensional
      deformable objects. Local refinements are provided at the tool-tissue interaction
      region by a local subdivision technique. RESULTS: As an example, we have
      developed a deformable human kidney model generated from the Visible Human
      Dataset, with tissue properties determined from in vivo animal experiments. A
      mixed reality laparoscopic surgical training system has been developed, using an 
      abdominal mannequin and force feedback devices. CONCLUSIONS: The use of
      precomputation and structural re-analysis techniques results in a very rapid
      computation procedure. Validation of the simulator is in progress.
CI  - Copyright 2007 John Wiley & Sons, Ltd.
FAU - Kim, Jung
AU  - Kim J
AD  - School of Mechanical, Aerospace and Systems Engineering, Korea Advanced Institute
      of Science and Technology, Daejeon, Korea. jungkim@kaist.ac.kr
FAU - Choi, Changmok
AU  - Choi C
FAU - De, Suvranu
AU  - De S
FAU - Srinivasan, Mandayam A
AU  - Srinivasan MA
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - England
TA  - Int J Med Robot
JT  - The international journal of medical robotics + computer assisted surgery : MRCAS
JID - 101250764
SB  - IM
MH  - Algorithms
MH  - Anatomy, Cross-Sectional
MH  - Biomechanical Phenomena
MH  - Computer Graphics
MH  - *Computer Simulation
MH  - *Computer-Assisted Instruction
MH  - Data Display
MH  - Education, Medical/*methods
MH  - Elasticity
MH  - Feedback
MH  - Imaging, Three-Dimensional
MH  - Kidney/*surgery
MH  - Manikins
MH  - *Models, Anatomic
MH  - Models, Biological
MH  - Phantoms, Imaging
MH  - Robotics
MH  - Software
MH  - Urologic Surgical Procedures/*education
MH  - User-Computer Interface
EDAT- 2007/07/10 09:00
MHDA- 2007/08/11 09:00
CRDT- 2007/07/10 09:00
AID - 10.1002/rcs.140 [doi]
PST - ppublish
SO  - Int J Med Robot. 2007 Jun;3(2):149-58.

PMID- 17584501
OWN - NLM
STAT- MEDLINE
DA  - 20070706
DCOM- 20070801
LR  - 20140904
IS  - 1743-0003 (Electronic)
IS  - 1743-0003 (Linking)
VI  - 4
DP  - 2007
TI  - Aging and selective sensorimotor strategies in the regulation of upright balance.
PG  - 19
AB  - BACKGROUND: The maintenance of upright equilibrium is essentially a sensorimotor 
      integration task. The central nervous system (CNS) has to generate appropriate
      and complex motor responses based on the selective and rapid integration of
      sensory information from multiple sources. Since each sensory system has its own 
      coordinate framework, specific time delay and reliability, sensory conflicts may 
      arise and represent situations in which the CNS has to recalibrate the weight
      attributed to each particular sensory input. The resolution of sensory conflicts 
      may represent a particular challenge for older adults given the age-related
      decline in the integrity of many postural regulating systems, including
      musculoskeletal and sensory systems, as well as neural processing and conduction 
      of information. The effects of aging and adaptation (by repeated exposures) on
      the capability of the CNS to select pertinent sensory information and resolve
      sensory conflicts were thus investigated with virtual reality (VR) in the present
      study. METHODS: Healthy young and older adults maintained quiet stance while
      immersed in a virtual environment (VE) for 1 hour during which transient visual
      and/or surface perturbations were randomly presented. Visual perturbations were
      induced by sudden pitch or roll plane tilts of the VE viewed through a
      helmet-mounted display, and combined with or without surface perturbations
      presented in a direction that was either identical or opposite to the visual
      perturbations. RESULTS: Results showed a profound influence of aging on postural 
      adjustments measured by electromyographic (EMG) responses and displacements of
      the center of pressure (COP) and body's center of mass (COM) in the recovery of
      upright stance, especially in the presence of sensory conflicts. Older adults
      relied more on vision as compared to young adults. Aging affects the interaction 
      of the somatosensory and visual systems on the control of equilibrium during
      standing and the ability of CNS to resolve sensory conflicts. However, even with 
      a one-hour immersion in VE and exposure to sensory conflicts, it is possible for 
      the CNS to recalibrate and adapt to the changes, while improving balance
      capability in older adults. CONCLUSION: Preventive and rehabilitation programs
      targeting postural control in older adults should take into account the possible 
      impairment of sensory organization or sensorimotor integration and include VE
      training under conditions of sensory conflicts.
FAU - Bugnariu, Nicoleta
AU  - Bugnariu N
AD  - School of Rehabilitation Sciences, University of Ottawa, 451 Smyth Road, Room
      3057, Ottawa, Ontario, K1H 8M5, Canada. nicoleta.bugnariu@uottawa.ca
FAU - Fung, Joyce
AU  - Fung J
LA  - eng
PT  - Journal Article
DEP - 20070620
PL  - England
TA  - J Neuroeng Rehabil
JT  - Journal of neuroengineering and rehabilitation
JID - 101232233
SB  - IM
MH  - Adult
MH  - Aged
MH  - *Aging
MH  - Central Nervous System/*physiology
MH  - Female
MH  - Humans
MH  - Male
MH  - Motor Skills
MH  - Motor Skills Disorders/rehabilitation
MH  - Postural Balance/*physiology
MH  - *User-Computer Interface
MH  - *Visual Perception
PMC - PMC1910603
OID - NLM: PMC1910603
EDAT- 2007/06/23 09:00
MHDA- 2007/06/23 09:01
CRDT- 2007/06/23 09:00
PHST- 2007/02/01 [received]
PHST- 2007/06/20 [accepted]
PHST- 2007/06/20 [aheadofprint]
AID - 1743-0003-4-19 [pii]
AID - 10.1186/1743-0003-4-19 [doi]
PST - epublish
SO  - J Neuroeng Rehabil. 2007 Jun 20;4:19.

PMID- 17574194
OWN - NLM
STAT- MEDLINE
DA  - 20070618
DCOM- 20070822
LR  - 20071107
IS  - 1932-2275 (Print)
IS  - 1932-2275 (Linking)
VI  - 25
IP  - 2
DP  - 2007 Jun
TI  - Virtual reality simulations.
PG  - 337-48
AB  - The current virtual reality and haptic technologies being researched for
      potential use in high-fidelity simulations in anesthesiology are attempting to
      overcome a number of limitations, such as low resolution, low visual acuity, and 
      lack of robust haptics-graphics collocation. A new prototype device invented by
      the authors, known as ImmersiveTouch, addresses how to overcome these technologic
      limitations.
FAU - Banerjee, P Pat
AU  - Banerjee PP
AD  - Department of Mechanical and Industrial Engineering (M/C 251), University of
      Illinois-Chicago, 3029 Engineering Research Facility, 842 West Taylor Street,
      Chicago, IL 60607, USA. banerjee@uic.edu
FAU - Luciano, Cristian J
AU  - Luciano CJ
FAU - Rizzi, Silvio
AU  - Rizzi S
LA  - eng
PT  - Journal Article
PT  - Review
PL  - United States
TA  - Anesthesiol Clin
JT  - Anesthesiology clinics
JID - 101273663
SB  - IM
EIN - Anesthesiol Clin. 2007 Sep;25(3):687
MH  - Anesthesiology/*standards
MH  - *Computer Graphics
MH  - *Computer Simulation
MH  - Humans
MH  - Manikins
MH  - Touch
RF  - 21
EDAT- 2007/06/19 09:00
MHDA- 2007/08/23 09:00
CRDT- 2007/06/19 09:00
AID - S1932-2275(07)00021-3 [pii]
AID - 10.1016/j.anclin.2007.03.005 [doi]
PST - ppublish
SO  - Anesthesiol Clin. 2007 Jun;25(2):337-48.

PMID- 16916105
OWN - NLM
STAT- MEDLINE
DA  - 20060818
DCOM- 20060920
LR  - 20091111
IS  - 0018-9294 (Print)
IS  - 0018-9294 (Linking)
VI  - 53
IP  - 8
DP  - 2006 Aug
TI  - A virtual reality simulator for remote interventional radiology: concept and
      prototype design.
PG  - 1696-700
AB  - We present a virtual reality simulator to realize interventional radiology (IR)
      procedures remotely. The simulator contains two subsystems: one at the local site
      and the other at the remote site. At the local site, the interventional
      radiologist interacts with a three-dimensional (3-D) vascular model extracted
      from the patient's data and inserts IR devices through the Motion Tracking Box
      (MTB), which converts physical motion (translation and rotation) of IR devices
      into digital signal. This signal is transferred to the Actuator Box (AB) at the
      remote site that drives the IR devices in the patient. The status of the IR
      devices is subsequently fed back to the local site and displayed on the vascular 
      model. To prove the concept, the prototype developed employs a physical
      angiography phantom (mimicking the patient) and its corresponding 3-D digital
      model. A magnetic tracking system provides information about positioning of the
      IR devices in the phantom. The initial results are encouraging. The AB controlled
      remotely drives IR devices with resolution of 0.00288 mm/step in translation and 
      0.079 deg/step in rotation.
FAU - Xin, Ma
AU  - Xin M
AD  - Biomedical Imaging Laboratory, Singapore Bioimaging Consortium.
      maxin@sbic.a-star.edu.sg
FAU - Lei, Zhao
AU  - Lei Z
FAU - Volkau, Ihar
AU  - Volkau I
FAU - Weili, Zheng
AU  - Weili Z
FAU - Aziz, Aamer
AU  - Aziz A
FAU - Ang, Marcelo H Jr
AU  - Ang MH Jr
FAU - Nowinski, Wieslaw L
AU  - Nowinski WL
LA  - eng
PT  - Evaluation Studies
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PT  - Validation Studies
PL  - United States
TA  - IEEE Trans Biomed Eng
JT  - IEEE transactions on bio-medical engineering
JID - 0012737
SB  - IM
MH  - Angiography/*methods
MH  - Catheterization/methods
MH  - Computer Graphics
MH  - Computer Simulation
MH  - Humans
MH  - Imaging, Three-Dimensional/*methods
MH  - *Models, Biological
MH  - Pilot Projects
MH  - Radiographic Image Interpretation, Computer-Assisted/*methods
MH  - Radiography, Interventional/*methods
MH  - *User-Computer Interface
MH  - Vascular Surgical Procedures/*methods
EDAT- 2006/08/19 09:00
MHDA- 2006/09/21 09:00
CRDT- 2006/08/19 09:00
AID - 10.1109/TBME.2006.873762 [doi]
PST - ppublish
SO  - IEEE Trans Biomed Eng. 2006 Aug;53(8):1696-700.

PMID- 16640246
OWN - NLM
STAT- MEDLINE
DA  - 20060427
DCOM- 20060523
LR  - 20061115
IS  - 1077-2626 (Print)
IS  - 1077-2626 (Linking)
VI  - 12
IP  - 3
DP  - 2006 May-Jun
TI  - CAVE and fishtank virtual-reality displays: a qualitative and quantitative
      comparison.
PG  - 323-30
AB  - We present the results from a qualitative and quantitative user study comparing
      fishtank virtual-reality (VR) and CAVE displays. The results of the qualitative
      study show that users preferred the fishtank VR display to the CAVE system for
      our scientific visualization application because of perceived higher resolution, 
      brightness and crispness of imagery, and comfort of use. The results of the
      quantitative study show that users performed an abstract visual search task
      significantly more quickly and more accurately on the fishtank VR display system 
      than in the CAVE. The same study also showed that visual context had no
      significant effect on task performance for either of the platforms. We suggest
      that fishtank VR displays are more effective than CAVEs for applications in which
      the task occurs outside the user's reference frame, the user views and
      manipulates the virtual world from the outside in, and the size of the virtual
      object that the user interacts with is smaller than the user's body and fits into
      the fishtank VR display. The results of both studies support this proposition.
FAU - Demiralp, Cagatay
AU  - Demiralp C
AD  - Computer Science Department, Brown University, Providence, RI 02912, USA.
      cad@cs.brown.edu
FAU - Jackson, Cullen D
AU  - Jackson CD
FAU - Karelitz, David B
AU  - Karelitz DB
FAU - Zhang, Song
AU  - Zhang S
FAU - Laidlaw, David H
AU  - Laidlaw DH
LA  - eng
PT  - Comparative Study
PT  - Evaluation Studies
PT  - Journal Article
PT  - Research Support, U.S. Gov't, Non-P.H.S.
PL  - United States
TA  - IEEE Trans Vis Comput Graph
JT  - IEEE transactions on visualization and computer graphics
JID - 9891704
SB  - IM
MH  - *Data Display
MH  - Equipment Design
MH  - Equipment Failure Analysis
MH  - Image Enhancement/*instrumentation/methods
MH  - Image Interpretation, Computer-Assisted/*instrumentation/methods
MH  - Imaging, Three-Dimensional/*instrumentation/methods
MH  - *User-Computer Interface
EDAT- 2006/04/28 09:00
MHDA- 2006/05/24 09:00
CRDT- 2006/04/28 09:00
AID - 10.1109/TVCG.2006.42 [doi]
PST - ppublish
SO  - IEEE Trans Vis Comput Graph. 2006 May-Jun;12(3):323-30.

PMID- 16628606
OWN - NLM
STAT- MEDLINE
DA  - 20061127
DCOM- 20070123
LR  - 20131121
IS  - 1065-9471 (Print)
IS  - 1065-9471 (Linking)
VI  - 27
IP  - 12
DP  - 2006 Dec
TI  - Toward brain correlates of natural behavior: fMRI during violent video games.
PG  - 948-56
AB  - Modern video games represent highly advanced virtual reality simulations and
      often contain virtual violence. In a significant amount of young males, playing
      video games is a quotidian activity, making it an almost natural behavior.
      Recordings of brain activation with functional magnetic resonance imaging (fMRI) 
      during gameplay may reflect neuronal correlates of real-life behavior. We
      recorded 13 experienced gamers (18-26 years; average 14 hrs/week playing) while
      playing a violent first-person shooter game (a violent computer game played in
      self-perspective) by means of distortion and dephasing reduced fMRI (3 T;
      single-shot triple-echo echo-planar imaging [EPI]). Content analysis of the video
      and sound with 100 ms time resolution achieved relevant behavioral variables.
      These variables explained significant signal variance across large distributed
      networks. Occurrence of violent scenes revealed significant neuronal correlates
      in an event-related design. Activation of dorsal and deactivation of rostral
      anterior cingulate and amygdala characterized the mid-frontal pattern related to 
      virtual violence. Statistics and effect sizes can be considered large at these
      areas. Optimized imaging strategies allowed for single-subject and for
      single-trial analysis with good image quality at basal brain structures. We
      propose that virtual environments can be used to study neuronal processes
      involved in semi-naturalistic behavior as determined by content analysis.
      Importantly, the activation pattern reflects brain-environment interactions
      rather than stimulus responses as observed in classical experimental designs. We 
      relate our findings to the general discussion on social effects of playing
      first-person shooter games.
CI  - (c) 2006 Wiley-Liss, Inc.
FAU - Mathiak, Klaus
AU  - Mathiak K
AD  - Department of Psychiatry & Psychotherapy, RWTH Aachen University, Aachen,
      Germany.
FAU - Weber, Rene
AU  - Weber R
LA  - eng
PT  - Comparative Study
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - United States
TA  - Hum Brain Mapp
JT  - Human brain mapping
JID - 9419065
RN  - S88TT14065 (Oxygen)
SB  - IM
MH  - Adolescent
MH  - Adult
MH  - Behavior/*physiology
MH  - Brain/*blood supply/physiology
MH  - *Brain Mapping
MH  - Cluster Analysis
MH  - Humans
MH  - Image Processing, Computer-Assisted/methods
MH  - *Magnetic Resonance Imaging
MH  - Male
MH  - Oxygen/blood
MH  - Photic Stimulation/methods
MH  - Video Games
MH  - *Violence
EDAT- 2006/04/22 09:00
MHDA- 2007/01/24 09:00
CRDT- 2006/04/22 09:00
AID - 10.1002/hbm.20234 [doi]
PST - ppublish
SO  - Hum Brain Mapp. 2006 Dec;27(12):948-56.

PMID- 16534461
OWN - NLM
STAT- MEDLINE
DA  - 20060314
DCOM- 20060420
LR  - 20131121
IS  - 1040-5488 (Print)
IS  - 1040-5488 (Linking)
VI  - 83
IP  - 3
DP  - 2006 Mar
TI  - Susceptibility to induced visual discomfort during the menstrual cycle while
      viewing a visual display unit.
PG  - 190-4
AB  - PURPOSE: Consistent variations in reports of visual discomfort during the female 
      menstrual cycle are found when virtual reality headsets are used to display
      moving images. Because little is known about the influence of this cycle on
      susceptibility to visual discomfort in other situations, we performed a
      laboratory study using an intensive visual task. METHODS: Twelve female
      participants, with normal-length menstrual cycles, completed the study. This
      required them to play a computer game for 30 minutes while viewing the screen
      through -2.00-D lenses. Questionnaires were used to record symptom changes;
      visual acuity and near points of accommodation (NPA) and convergence (NPC) were
      also recorded both before and after the game. The participants performed this
      task on designated days (5, 12, 19, and 26) of their menstrual cycle chosen
      because they fall in line with peaks and troughs of ovarian hormone levels. Cycle
      phase was confirmed by the measurement of salivary estradiol and progesterone
      levels. RESULTS: The task performed produced clear changes in all metrics
      examined. Visual discomfort first increased, on average, after 6 minutes; VA
      declined on average by 0.02 logarithm of the minimum angle of resolution and NPC 
      and NPA both receded by just over 1 cm. However, none of these changes differed
      significantly at any stage of the menstrual cycle. CONCLUSIONS: We conclude that 
      visual discomfort, generated by providing increased accommodative demand while
      viewing a visual display unit, does not vary significantly during the menstrual
      cycle.
FAU - Howarth, Peter A
AU  - Howarth PA
AD  - Visual Ergonomics Research Group, Department of Human Sciences, Loughborough
      University, United Kingdom. p.a.howarth@lboro.ac.uk
FAU - Clemes, Stacy A
AU  - Clemes SA
LA  - eng
PT  - Comparative Study
PT  - Journal Article
PL  - United States
TA  - Optom Vis Sci
JT  - Optometry and vision science : official publication of the American Academy of
      Optometry
JID - 8904931
RN  - 4G7DS2Q64Y (Progesterone)
RN  - 4TI98Z838E (Estradiol)
SB  - IM
MH  - Accommodation, Ocular/*physiology
MH  - Adolescent
MH  - Adult
MH  - Asthenopia/metabolism/*physiopathology
MH  - Estradiol/metabolism
MH  - Female
MH  - Humans
MH  - Menstrual Cycle/*physiology
MH  - Progesterone/metabolism
MH  - Saliva/metabolism
MH  - Single-Blind Method
MH  - Vision Tests/*instrumentation
MH  - Visual Acuity/*physiology
EDAT- 2006/03/15 09:00
MHDA- 2006/04/21 09:00
CRDT- 2006/03/15 09:00
AID - 10.1097/01.opx.0000208626.35109.21 [doi]
AID - 00006324-200603000-00012 [pii]
PST - ppublish
SO  - Optom Vis Sci. 2006 Mar;83(3):190-4.

PMID- 16506219
OWN - NLM
STAT- MEDLINE
DA  - 20060403
DCOM- 20060912
LR  - 20061115
IS  - 0897-3806 (Print)
IS  - 0897-3806 (Linking)
VI  - 19
IP  - 3
DP  - 2006 Apr
TI  - Photorealistic virtual anatomy based on Chinese Visible Human data.
PG  - 232-9
AB  - Virtual reality based learning of human anatomy is feasible when a database of 3D
      organ models is available for the learner to explore, visualize, and dissect in
      virtual space interactively. In this article, we present our latest work on
      photorealistic virtual anatomy applications based on the Chinese Visible Human
      (CVH) data. We have focused on the development of state-of-the-art virtual
      environments that feature interactive photo-realistic visualization and
      dissection of virtual anatomical models constructed from ultra-high resolution
      CVH datasets. We also outline our latest progress in applying these highly
      accurate virtual and functional organ models to generate realistic look and feel 
      to advanced surgical simulators.
CI  - (c) 2006 Wiley-Liss, Inc.
FAU - Heng, P A
AU  - Heng PA
AD  - Department of Computer Science and Engineering, The Chinese University of Hong
      Kong, Hong Kong. pheng@cse.cuhk.edu.hk
FAU - Zhang, S X
AU  - Zhang SX
FAU - Xie, Y M
AU  - Xie YM
FAU - Wong, T T
AU  - Wong TT
FAU - Chui, Y P
AU  - Chui YP
FAU - Cheng, C Y
AU  - Cheng CY
LA  - eng
PT  - Comparative Study
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - United States
TA  - Clin Anat
JT  - Clinical anatomy (New York, N.Y.)
JID - 8809128
SB  - IM
MH  - Adult
MH  - *Asian Continental Ancestry Group
MH  - Hong Kong
MH  - Humans
MH  - *Imaging, Three-Dimensional
MH  - Male
MH  - National Library of Medicine (U.S.)
MH  - Nervous System/anatomy & histology
MH  - United States
MH  - *User-Computer Interface
MH  - *Visible Human Projects
EDAT- 2006/03/01 09:00
MHDA- 2006/09/13 09:00
CRDT- 2006/03/01 09:00
AID - 10.1002/ca.20314 [doi]
PST - ppublish
SO  - Clin Anat. 2006 Apr;19(3):232-9.

PMID- 16497116
OWN - NLM
STAT- MEDLINE
DA  - 20060224
DCOM- 20061011
LR  - 20061115
IS  - 1094-9313 (Print)
IS  - 1094-9313 (Linking)
VI  - 9
IP  - 1
DP  - 2006 Feb
TI  - Neural correlate of spatial presence in an arousing and noninteractive virtual
      reality: an EEG and psychophysiology study.
PG  - 30-45
AB  - Using electroencephalography (EEG), psychophysiology, and psychometric measures, 
      this is the first study which investigated the neurophysiological underpinnings
      of spatial presence. Spatial presence is considered a sense of being physically
      situated within a spatial environment portrayed by a medium (e.g., television,
      virtual reality). Twelve healthy children and 11 healthy adolescents were
      watching different virtual roller coaster scenarios. During a control session,
      the roller coaster cab drove through a horizontal roundabout track. The following
      realistic roller coaster rides consisted of spectacular ups, downs, and loops.
      Low-resolution brain electromagnetic tomography (LORETA) and event-related
      desynchronization (ERD) were used to analyze the EEG data. As expected, we found 
      that, compared to the control condition, experiencing a virtual roller coaster
      ride evoked in both groups strong SP experiences, increased electrodermal
      reactions, and activations in parietal brain areas known to be involved in
      spatial navigation. In addition, brain areas that receive homeostatic afferents
      from somatic and visceral sensations of the body were strongly activated. Most
      interesting, children (as compared to adolescents) reported higher spatial
      presence experiences and demonstrated a different frontal activation pattern.
      While adolescents showed increased activation in prefrontal areas known to be
      involved in the control of executive functions, children demonstrated a decreased
      activity in these brain regions. Interestingly, recent neuroanatomical and
      neurophysiological studies have shown that the frontal brain continues to develop
      to adult status well into adolescence. Thus, the result of our study implies that
      the increased spatial presence experience in children may result from the not
      fully developed control functions of the frontal cortex.
FAU - Baumgartner, Thomas
AU  - Baumgartner T
AD  - Institute for Empirical Research in Economics and Neuroeconomics, University of
      Zurich, Switzerland. t.baumgartner@iew.unizh.ch
FAU - Valko, Lilian
AU  - Valko L
FAU - Esslen, Michaela
AU  - Esslen M
FAU - Jancke, Lutz
AU  - Jancke L
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - United States
TA  - Cyberpsychol Behav
JT  - Cyberpsychology & behavior : the impact of the Internet, multimedia and virtual
      reality on behavior and society
JID - 9804397
SB  - IM
MH  - Adolescent
MH  - Afferent Pathways/physiology
MH  - Age Factors
MH  - Arousal/*physiology
MH  - Cerebral Cortex/*physiology
MH  - Child
MH  - Contingent Negative Variation/*physiology
MH  - *Electroencephalography
MH  - Electromagnetic Fields
MH  - Female
MH  - Frontal Lobe/physiology
MH  - Galvanic Skin Response/physiology
MH  - Homeostasis/physiology
MH  - Humans
MH  - Kinesthesis/*physiology
MH  - Male
MH  - Prefrontal Cortex/physiology
MH  - Psychophysiology
MH  - Sensation/physiology
MH  - Space Perception/*physiology
MH  - Tomography
MH  - *User-Computer Interface
MH  - Visual Perception/*physiology
EDAT- 2006/02/25 09:00
MHDA- 2006/10/13 09:00
CRDT- 2006/02/25 09:00
AID - 10.1089/cpb.2006.9.30 [doi]
PST - ppublish
SO  - Cyberpsychol Behav. 2006 Feb;9(1):30-45.

PMID- 16404080
OWN - NLM
STAT- MEDLINE
DA  - 20060111
DCOM- 20060417
LR  - 20141120
IS  - 0926-9630 (Print)
IS  - 0926-9630 (Linking)
VI  - 119
DP  - 2006
TI  - Image-guided laser projection for port placement in minimally invasive surgery.
PG  - 367-72
AB  - We present an application of an augmented reality laser projection system in
      which procedure-specific optimal incision sites, computed from pre-operative
      image acquisition, are superimposed on a patient to guide port placement in
      minimally invasive surgery. Tests were conducted to evaluate the fidelity of
      computed and measured port configurations, and to validate the accuracy with
      which a surgical tool-tip can be placed at an identified virtual target. A high
      resolution volumetric image of a thorax phantom was acquired using helical
      computed tomography imaging. Oriented within the thorax, a phantom organ with
      marked targets was visualized in a virtual environment. A graphical interface
      enabled marking the locations of target anatomy, and calculation of a grid of
      potential port locations along the intercostal rib lines. Optimal configurations 
      of port positions and tool orientations were determined by an objective measure
      reflecting image-based indices of surgical dexterity, hand-eye alignment, and
      collision detection. Intra-operative registration of the computed virtual model
      and the phantom anatomy was performed using an optical tracking system. Initial
      trials demonstrated that computed and projected port placement provided direct
      access to target anatomy with an accuracy of 2 mm.
FAU - Marmurek, Jonathan
AU  - Marmurek J
AD  - The University of Western Ontario, London, Ontario, Canada.
FAU - Wedlake, Chris
AU  - Wedlake C
FAU - Pardasani, Utsav
AU  - Pardasani U
FAU - Eagleson, Roy
AU  - Eagleson R
FAU - Peters, Terry
AU  - Peters T
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - T
MH  - Canada
MH  - Diagnostic Imaging
MH  - Humans
MH  - *Lasers
MH  - *Minimally Invasive Surgical Procedures
MH  - *Surgery, Computer-Assisted
EDAT- 2006/01/13 09:00
MHDA- 2006/04/18 09:00
CRDT- 2006/01/13 09:00
PST - ppublish
SO  - Stud Health Technol Inform. 2006;119:367-72.

PMID- 16404033
OWN - NLM
STAT- MEDLINE
DA  - 20060111
DCOM- 20060417
IS  - 0926-9630 (Print)
IS  - 0926-9630 (Linking)
VI  - 119
DP  - 2006
TI  - A haptic VR milling surgery simulator--using high-resolution CT-data.
PG  - 138-43
AB  - A haptic virtual reality milling simulator using high resolution volumetric data 
      is presented in this paper. We discuss the graphical rendering performed from an 
      iso-surface generated using marching cubes with a hierarchical storage method to 
      optimize for fast dynamic changes to the data during the milling process. We also
      present a stable proxy-based haptic algorithm used to maintain a tip position on 
      the surface avoiding haptic fall-through.
FAU - Eriksson, Magnus
AU  - Eriksson M
AD  - The Mechatronics Lab/Machine Design, KTH, Stockholm, Sweden.
FAU - Dixon, Mark
AU  - Dixon M
FAU - Wikander, Jan
AU  - Wikander J
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - T
MH  - Algorithms
MH  - Bone and Bones/surgery
MH  - *Computer Simulation
MH  - Humans
MH  - Surgical Procedures, Operative/*education
MH  - Sweden
MH  - *Tomography, X-Ray Computed
MH  - *User-Computer Interface
EDAT- 2006/01/13 09:00
MHDA- 2006/04/18 09:00
CRDT- 2006/01/13 09:00
PST - ppublish
SO  - Stud Health Technol Inform. 2006;119:138-43.

PMID- 16394740
OWN - NLM
STAT- MEDLINE
DA  - 20060105
DCOM- 20060323
LR  - 20140711
IS  - 0009-921X (Print)
IS  - 0009-921X (Linking)
VI  - 442
DP  - 2006 Jan
TI  - Virtual-reality-assisted interventional procedures.
PG  - 63-73
AB  - Observable objects in biology and medicine extend across a range of scale, from
      individual molecules and cells; through the varieties of tissue and interstitial 
      interfaces; and to complete organs, organ systems, and body parts. These objects 
      include functional attributes of these systems such as biophysical,
      biomechanical, and physiologic properties. Imaging in three dimensions of such
      objects and their functions is possible now with the advent of high-resolution
      tomographic scanners and imaging systems. Medical applications include accurate
      anatomy and function mapping, enhanced diagnosis, accurate treatment planning and
      rehearsal, and education and training. Biologic applications include study and
      analysis of structure-to-function relationships in individual cells and
      organelles. The potential for revolutionary innovation in the practice of
      medicine and in biologic investigations lies in direct, fully immersive,
      real-time multisensory fusion of real and virtual information data streams into
      online, real-time images available during actual clinical procedures or biologic 
      experiments. Current high-performance computing, advanced image processing and
      high-fidelity rendering capabilities have facilitated major progress toward
      realization of these goals. With these advances in hand, there are several
      important applications of three-dimensional viewing that will have a substantial 
      impact on the practice of medicine.
FAU - Cameron, Bruce M
AU  - Cameron BM
AD  - Biomedical Imaging Resource, Mayo Clinic College of Medicine, Rochester, MN
      55905, USA.
FAU - Robb, Richard A
AU  - Robb RA
LA  - eng
GR  - DK68055/DK/NIDDK NIH HHS/United States
GR  - EB002834/EB/NIBIB NIH HHS/United States
GR  - HR46158/HR/NHLBI NIH HHS/United States
GR  - IR33 CA107933/CA/NCI NIH HHS/United States
GR  - P01 DK068055/DK/NIDDK NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Review
PL  - United States
TA  - Clin Orthop Relat Res
JT  - Clinical orthopaedics and related research
JID - 0075674
SB  - AIM
SB  - IM
MH  - Computer Simulation
MH  - Computer-Assisted Instruction
MH  - Education, Medical/methods
MH  - Humans
MH  - Image Processing, Computer-Assisted
MH  - *Imaging, Three-Dimensional
MH  - Magnetic Resonance Imaging
MH  - Models, Anatomic
MH  - Patient Care Planning
MH  - Therapy, Computer-Assisted
MH  - Tomography, X-Ray Computed
MH  - *User-Computer Interface
RF  - 39
EDAT- 2006/01/06 09:00
MHDA- 2006/03/24 09:00
CRDT- 2006/01/06 09:00
AID - 00003086-200601000-00011 [pii]
PST - ppublish
SO  - Clin Orthop Relat Res. 2006 Jan;442:63-73.

PMID- 16202755
OWN - NLM
STAT- MEDLINE
DA  - 20051005
DCOM- 20060119
LR  - 20061115
IS  - 1097-6868 (Electronic)
IS  - 0002-9378 (Linking)
VI  - 193
IP  - 4
DP  - 2005 Oct
TI  - Diagnosis of an interstitial pregnancy with 4-dimensional volume contrast
      imaging.
PG  - 1551-3
AB  - OBJECTIVE: The purpose of this study was to investigate the use of a new
      ultrasound technique, termed 4-dimensional volume contrast imaging in
      coronal-plane to facilitate the early detection of interstitial pregnancy. STUDY 
      DESIGN: A case of interstitial pregnancy was diagnosed accurately at 6 weeks of
      gestation with 4-dimensional transvaginal volume contrast imaging in coronal
      plane technology. A scan of the uterus revealed that the eccentric gestational
      sac was located in the right uterotubal junctional area, lying 1 cm outside the
      most upper lateral edge of the uterine cavity with thick endometrial echoes.
      RESULTS: After the appropriate counseling, the patient was treated with an
      ultrasonographically guided intracardiac injection of 2.5 mEq of potassium
      chloride followed by aspiration of the gestational sac. A transvaginal scan
      immediately after the procedure demonstrated a collapsed empty gestational sac.
      Three months after the conservative treatment, the serum beta-human chorionic
      gonadotropin level fell to 1.17 mIU/mL, and normal echotexture of the uterus was 
      noted. CONCLUSION: Four-dimensional volume contrast imaging in coronal-plane
      technology provides scan planes that are not accessible by conventional
      2-dimensional scanning, with enhanced tissue contrast resolution in region of
      interest. This new ultrasound technique has the potential to provide more
      accurate, inexpensive and less variable virtual reality image-guided
      interventional options through more realistic interaction with the virtualized in
      utero condition, particularly when 2-dimensional transvaginal scan fails to
      differentiate between interstitial, angular, and cornual pregnancies.
FAU - Chou, Min M
AU  - Chou MM
AD  - Department of Obstetrics and Gynecology, Taichung Veterans General Hospital,
      Chung Shan Medical University, Huang Kung University, Taichung, Taiwan.
      mmchou@vghtc.gov.tw
FAU - Tseng, Jenn J
AU  - Tseng JJ
FAU - Yi, Yu C
AU  - Yi YC
FAU - Chen, Wei C
AU  - Chen WC
FAU - Ho, Esther Shih C
AU  - Ho ES
LA  - eng
PT  - Case Reports
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - United States
TA  - Am J Obstet Gynecol
JT  - American journal of obstetrics and gynecology
JID - 0370476
SB  - AIM
SB  - IM
MH  - Adult
MH  - Female
MH  - Humans
MH  - Pregnancy
MH  - Pregnancy, Ectopic/*ultrasonography
MH  - Ultrasonography, Prenatal/*methods
MH  - Uterus/*ultrasonography
EDAT- 2005/10/06 09:00
MHDA- 2006/01/20 09:00
CRDT- 2005/10/06 09:00
PHST- 2005/01/17 [received]
PHST- 2005/02/04 [revised]
PHST- 2005/02/17 [accepted]
AID - S0002-9378(05)00317-0 [pii]
AID - 10.1016/j.ajog.2005.02.088 [doi]
PST - ppublish
SO  - Am J Obstet Gynecol. 2005 Oct;193(4):1551-3.

PMID- 16123867
OWN - NLM
STAT- MEDLINE
DA  - 20050826
DCOM- 20050930
LR  - 20061115
IS  - 1438-9029 (Print)
IS  - 1438-9010 (Linking)
VI  - 177
IP  - 9
DP  - 2005 Sep
TI  - [The role of 3-D imaging and computer-based postprocessing for surgery of the
      liver and pancreas].
PG  - 1219-26
AB  - Cross-sectional imaging based on navigation and virtual reality planning tools
      are well-established in the surgical routine in orthopedic surgery and
      neurosurgery. In various procedures, they have achieved a significant clinical
      relevance and efficacy and have enhanced the discipline's resection capabilities.
      In abdominal surgery, however, these tools have gained little attraction so far. 
      Even with the advantage of fast and high resolution cross-sectional liver and
      pancreas imaging, it remains unclear whether 3D planning and interactive planning
      tools might increase precision and safety of liver and pancreas surgery. The
      inability to simply transfer the methodology from orthopedic or neurosurgery is
      mainly a result of intraoperative organ movements and shifting and corresponding 
      technical difficulties in the on-line applicability of presurgical cross
      sectional imaging data. For the interactive planning of liver surgery, three
      systems partly exist in daily routine: HepaVision2 (MeVis GmbH, Bremen),
      LiverLive (Navidez Ltd, Slovenia) and OrgaNicer (German Cancer Research Center,
      Heidelberg). All these systems have realized a half- or full-automatic
      liver-segmentation procedure to visualize liver segments, vessel trees, resected 
      volumes or critical residual organ volumes, either for preoperative planning or
      intraoperative visualization. Acquisition of data is mainly based on computed
      tomography. Three-dimensional navigation for intraoperative surgical guidance
      with ultrasound is part of the clinical testing. There are only few reports about
      the transfer of the visualization of the pancreas, probably caused by the
      difficulties with the segmentation routine due to inflammation or organ-exceeding
      tumor growth. With this paper, we like to evaluate and demonstrate the present
      status of software planning tools and pathways for future pre- and intraoperative
      resection planning in liver and pancreas surgery.
FAU - Grenacher, L
AU  - Grenacher L
AD  - Abteilung Radiodiagnostik der Universitat Heidelberg.
      lars_grenacher@med.uni-heidelberg.de
FAU - Thorn, M
AU  - Thorn M
FAU - Knaebel, H P
AU  - Knaebel HP
FAU - Vetter, M
AU  - Vetter M
FAU - Hassenpflug, P
AU  - Hassenpflug P
FAU - Kraus, T
AU  - Kraus T
FAU - Meinzer, H P
AU  - Meinzer HP
FAU - Buchler, M W
AU  - Buchler MW
FAU - Kauffmann, G W
AU  - Kauffmann GW
FAU - Richter, G M
AU  - Richter GM
LA  - ger
PT  - English Abstract
PT  - Journal Article
PT  - Review
TT  - Bedeutung der 3-D-Bildgebung und computerbasierten Nachverarbeitung fur die
      Chirurgie der Leber und des Pankreas.
PL  - Germany
TA  - Rofo
JT  - RoFo : Fortschritte auf dem Gebiete der Rontgenstrahlen und der Nuklearmedizin
JID - 7507497
SB  - IM
MH  - Hepatectomy/instrumentation/*methods
MH  - Humans
MH  - *Image Interpretation, Computer-Assisted
MH  - Imaging, Three-Dimensional/*methods
MH  - Liver/radiography/*surgery/ultrasonography
MH  - Liver Neoplasms/radiography/surgery
MH  - Magnetic Resonance Imaging
MH  - Pancreas/radiography/*surgery/ultrasonography
MH  - Pancreatic Neoplasms/radiography/surgery
MH  - Planning Techniques
MH  - Software
MH  - Surgery, Computer-Assisted/instrumentation/*methods
MH  - *Tomography, X-Ray Computed
RF  - 35
EDAT- 2005/08/27 09:00
MHDA- 2005/10/01 09:00
CRDT- 2005/08/27 09:00
AID - 10.1055/s-2005-858376 [doi]
PST - ppublish
SO  - Rofo. 2005 Sep;177(9):1219-26.

PMID- 15876646
OWN - NLM
STAT- MEDLINE
DA  - 20050506
DCOM- 20050720
LR  - 20081121
IS  - 1741-2560 (Print)
IS  - 1741-2552 (Linking)
VI  - 2
IP  - 1
DP  - 2005 Mar
TI  - Design of a high-resolution optoelectronic retinal prosthesis.
PG  - S105-20
AB  - It has been demonstrated that electrical stimulation of the retina can produce
      visual percepts in blind patients suffering from macular degeneration and
      retinitis pigmentosa. However, current retinal implants provide very low
      resolution (just a few electrodes), whereas at least several thousand pixels
      would be required for functional restoration of sight. This paper presents the
      design of an optoelectronic retinal prosthetic system with a stimulating pixel
      density of up to 2500 pix mm(-2) (corresponding geometrically to a maximum visual
      acuity of 20/80). Requirements on proximity of neural cells to the stimulation
      electrodes are described as a function of the desired resolution. Two basic
      geometries of sub-retinal implants providing required proximity are presented:
      perforated membranes and protruding electrode arrays. To provide for natural eye 
      scanning of the scene, rather than scanning with a head-mounted camera, the
      system operates similar to 'virtual reality' devices. An image from a video
      camera is projected by a goggle-mounted collimated infrared LED-LCD display onto 
      the retina, activating an array of powered photodiodes in the retinal implant.
      The goggles are transparent to visible light, thus allowing for the simultaneous 
      use of remaining natural vision along with prosthetic stimulation. Optical
      delivery of visual information to the implant allows for real-time image
      processing adjustable to retinal architecture, as well as flexible control of
      image processing algorithms and stimulation parameters.
FAU - Palanker, Daniel
AU  - Palanker D
AD  - Department of Ophthalmology and Hansen Experimental Physics Laboratory, Stanford 
      University, Stanford, CA 94305-4085, USA. palanker@stanford.edu
FAU - Vankov, Alexander
AU  - Vankov A
FAU - Huie, Phil
AU  - Huie P
FAU - Baccus, Stephen
AU  - Baccus S
LA  - eng
PT  - Evaluation Studies
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20050222
PL  - England
TA  - J Neural Eng
JT  - Journal of neural engineering
JID - 101217933
SB  - IM
MH  - *Artificial Intelligence
MH  - *Computer-Aided Design
MH  - Electric Stimulation Therapy/*instrumentation/methods
MH  - Electronics, Medical
MH  - Equipment Failure Analysis
MH  - Humans
MH  - Image Interpretation, Computer-Assisted/instrumentation/*methods
MH  - Optics and Photonics/instrumentation
MH  - *Prostheses and Implants
MH  - Prosthesis Design/*methods
MH  - Retinal Diseases/*rehabilitation
MH  - *Sensory Aids
MH  - User-Computer Interface
EDAT- 2005/05/07 09:00
MHDA- 2005/07/21 09:00
CRDT- 2005/05/07 09:00
PHST- 2005/02/22 [aheadofprint]
AID - S1741-2560(05)89231-6 [pii]
AID - 10.1088/1741-2560/2/1/012 [doi]
PST - ppublish
SO  - J Neural Eng. 2005 Mar;2(1):S105-20. Epub 2005 Feb 22.

PMID- 15755538
OWN - NLM
STAT- MEDLINE
DA  - 20050309
DCOM- 20050708
LR  - 20051205
IS  - 0895-6111 (Print)
IS  - 0895-6111 (Linking)
VI  - 29
IP  - 2-3
DP  - 2005 Mar-Apr
TI  - User interface paradigms for patient-specific surgical planning: lessons learned 
      over a decade of research.
PG  - 203-22
AB  - This paper covers work in virtual reality-based, patient-specific surgical
      planning over the past decade. It aims to comprehensively examine the user
      interface paradigms and system designs during that period of time and to
      objectively analyze their effectiveness for the task. The goal is to provide
      useful feedback on these interface and implementation paradigms to aid other
      researchers in this field. First, specialized systems for specific clinical use
      were produced with a limited set of visualization tools. Later, through
      collaboration with NASA, an immersive virtual environment was created to produce 
      high-fidelity images for surgical simulation, but it underestimated the
      importance of collaboration. The next system, a networked, distributed virtual
      environment, provided immersion and collaboration, but the immersive paradigm was
      found to be of a disadvantage and the uniqueness of the framework unwieldy. A
      virtual model, workbench-style display was then created using a commercial
      package, but limitations of each were soon apparent. Finally, a specialized
      display, with an integrated visualization and simulation system is described and 
      evaluated. Lessons learned include: surgical planning is an abstract process
      unlike surgical simulation; collaboration is important, as is stereo
      visualization; and that high-resolution preoperative images from standard
      viewpoints are desirable, but interaction is truly the key to planning.
FAU - Montgomery, Kevin
AU  - Montgomery K
AD  - National Biocomputation Center, Stanford University Medical Center, 701A Weich
      Road, Stanford, CA 94305, USA. kevin@biocomp.stanford.edu
FAU - Stephanides, Michael
AU  - Stephanides M
FAU - Schendel, Stephen
AU  - Schendel S
FAU - Ross, Muriel
AU  - Ross M
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Comput Med Imaging Graph
JT  - Computerized medical imaging and graphics : the official journal of the
      Computerized Medical Imaging Society
JID - 8806104
SB  - IM
SB  - S
MH  - *Patient-Centered Care
MH  - *Surgical Procedures, Operative
MH  - United States
MH  - User-Computer Interface
OTO - NASA
OT  - NASA Discipline General Space Life Sciences
OT  - Non-NASA Center
IR  - Ross MD
FIR - Ross, M D
IRAD- U NM, Albuquerque
EDAT- 2005/03/10 09:00
MHDA- 2005/07/09 09:00
CRDT- 2005/03/10 09:00
PHST- 2004/04/06 [received]
PHST- 2004/08/20 [revised]
PHST- 2004/09/30 [accepted]
AID - S0895-6111(04)00120-X [pii]
AID - 10.1016/j.compmedimag.2004.09.014 [doi]
PST - ppublish
SO  - Comput Med Imaging Graph. 2005 Mar-Apr;29(2-3):203-22.

PMID- 15718731
OWN - NLM
STAT- MEDLINE
DA  - 20050218
DCOM- 20050825
LR  - 20091103
IS  - 0926-9630 (Print)
IS  - 0926-9630 (Linking)
VI  - 111
DP  - 2005
TI  - Adaptive soft tissue deformation for a virtual reality surgical trainer.
PG  - 219-22
AB  - Real time tissue deformation is an important aspect of interactive virtual
      reality (VR) environments such as medical trainers. Most approaches in deformable
      modelling use a fixed space discretization. A surgical trainer requires high
      plausibility of the deformations especially in the area close to the instrument. 
      As the area of intervention is not known a priori, adaptive techniques have to be
      applied. We present an approach for real time deformation of soft tissue based on
      a regular FEM mesh of cube elements as opposed to a mesh of tetrahedral elements 
      used by the majority of soft tissue simulators. A regular mesh structure
      simplifies the local refinement operation as the elements topology and stiffness 
      are known implicitly. We propose an octree-based adaptive multiresolution
      extension of our basic approach. The volumetric representation of the deformed
      object is created automatically from medical images or by voxelization of a
      surface model. The resolution of the volumetric representation is independent of 
      the surface geometry resolution. The surface is deformed according to the
      simulation performed on the underlying volumetric mesh.
FAU - Jerabkova, Lenka
AU  - Jerabkova L
AD  - Center for Computing and Communication, RWTH Aachen University, Germany.
      jerabkova@rz.rwth-aachen.de
FAU - Wolter, Timm P
AU  - Wolter TP
FAU - Pallua, Norbert
AU  - Pallua N
FAU - Kuhlen, Torsten
AU  - Kuhlen T
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - T
MH  - *Computer Simulation
MH  - *Connective Tissue
MH  - *Elasticity
MH  - Humans
MH  - Surgical Procedures, Operative/*education
EDAT- 2005/02/19 09:00
MHDA- 2005/08/27 09:00
CRDT- 2005/02/19 09:00
PST - ppublish
SO  - Stud Health Technol Inform. 2005;111:219-22.

PMID- 15661112
OWN - NLM
STAT- MEDLINE
DA  - 20050121
DCOM- 20050315
LR  - 20081121
IS  - 1388-2457 (Print)
IS  - 1388-2457 (Linking)
VI  - 116
IP  - 2
DP  - 2005 Feb
TI  - The 'F-complex' and MMN tap different aspects of deviance.
PG  - 336-52
AB  - OBJECTIVE: To compare the 'F(fusion)-complex' with the Mismatch negativity (MMN),
      both components associated with automatic detection of changes in the acoustic
      stimulus flow. METHODS: Ten right-handed adult native Hebrew speakers
      discriminated vowel-consonant-vowel (V-C-V) sequences /ada/ (deviant) and /aga/
      (standard) in an active auditory 'Oddball' task, and the brain potentials
      associated with performance of the task were recorded from 21 electrodes. Stimuli
      were generated by fusing the acoustic elements of the V-C-V sequences as follows:
      base was always presented in front of the subject, and formant transitions were
      presented to the front, left or right in a virtual reality room. An illusion of a
      lateralized echo (duplex sensation) accompanied base fusion with the lateralized 
      formant locations. Source current density estimates were derived for the net
      response to the fusion of the speech elements (F-complex) and for the MMN, using 
      low-resolution electromagnetic tomography (LORETA). Statistical non-parametric
      mapping was used to estimate the current density differences between the brain
      sources of the F-complex and the MMN. RESULTS: Occipito-parietal regions and
      prefrontal regions were associated with the F-complex in all formant locations,
      whereas the vicinity of the supratemporal plane was bilaterally associated with
      the MMN, but only in case of front-fusion (no duplex effect). CONCLUSIONS: MMN is
      sensitive to the novelty of the auditory object in relation to other stimuli in a
      sequence, whereas the F-complex is sensitive to the acoustic features of the
      auditory object and reflects a process of matching them with target categories.
      SIGNIFICANCE: The F-complex and MMN reflect different aspects of auditory
      processing in a stimulus-rich and changing environment: content analysis of the
      stimulus and novelty detection, respectively.
FAU - Laufer, Ilan
AU  - Laufer I
AD  - Evoked Potentials Laboratory, Technion-Israel Institute of Technology, Gutwirth
      Building, 3200 Haifa, Israel.
FAU - Pratt, Hillel
AU  - Pratt H
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - Netherlands
TA  - Clin Neurophysiol
JT  - Clinical neurophysiology : official journal of the International Federation of
      Clinical Neurophysiology
JID - 100883319
SB  - IM
MH  - Adult
MH  - Brain Mapping
MH  - Cerebral Cortex/*physiology
MH  - Electroencephalography
MH  - Electromagnetic Phenomena
MH  - Electrophysiology
MH  - *Evoked Potentials, Auditory
MH  - Female
MH  - Functional Laterality
MH  - Humans
MH  - Illusions
MH  - Male
MH  - Speech Perception/*physiology
MH  - Tomography
MH  - User-Computer Interface
EDAT- 2005/01/22 09:00
MHDA- 2005/03/16 09:00
CRDT- 2005/01/22 09:00
PHST- 2004/08/19 [accepted]
AID - S1388-2457(04)00324-4 [pii]
AID - 10.1016/j.clinph.2004.08.007 [doi]
PST - ppublish
SO  - Clin Neurophysiol. 2005 Feb;116(2):336-52.

PMID- 15544312
OWN - NLM
STAT- MEDLINE
DA  - 20041116
DCOM- 20041230
IS  - 0926-9630 (Print)
IS  - 0926-9630 (Linking)
VI  - 98
DP  - 2004
TI  - Reaction-time measurement and real-time data acquisition for neuroscientific
      experiments in virtual environments.
PG  - 391-3
AB  - This paper describes an approach to neuroscientific reaction-time experiments and
      resulting methods for data processing under real-time constraints in virtual
      environments (VE). Immersive VEs produce huge amounts of data, which has to be
      processed in real-time to meet the interactivity requirement of VE. Furthermore, 
      data is needed often with a timing resolution and even more crucial with an
      accuracy in the range of milliseconds. Unfortunately recent operating systems do 
      not in general guarantee timing precision in this range. For these purposes we
      have researched possibilities for reaction-time measurement and real-time data
      acquisition. Our system enables neuroscientists to perform reaction-time
      experiments in platform-independent virtual environments.
FAU - Valvoda, Jakob T
AU  - Valvoda JT
AD  - Center for Computing and Communication, Virtual Reality Group, Aachen University.
      valvoda@rz.rwth-aachen.de
FAU - Assenmacher, Ingo
AU  - Assenmacher I
FAU - Kuhlen, Torsten
AU  - Kuhlen T
FAU - Bischof, Christian H
AU  - Bischof CH
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - T
MH  - *Neurosciences
MH  - *Reaction Time
MH  - *User-Computer Interface
EDAT- 2004/11/17 09:00
MHDA- 2004/12/31 09:00
CRDT- 2004/11/17 09:00
PST - ppublish
SO  - Stud Health Technol Inform. 2004;98:391-3.

PMID- 15460902
OWN - NLM
STAT- MEDLINE
DA  - 20041005
DCOM- 20041104
LR  - 20061115
IS  - 1343-1420 (Print)
IS  - 1343-1420 (Linking)
VI  - 51
IP  - 3-4
DP  - 2004 Aug
TI  - Three-dimensional imaging of thoracic diseases with multi-detector row CT.
PG  - 163-70
AB  - The benefits of multi-detector row CT (MDCT) relative to single-detector row
      helical CT are considerable. Multi-detector row CT allows shorter acquisition
      times, greater coverage, and superior image resolution. These factors
      substantially increase the diagnostic accuracy of the examination.
      Three-dimensional (3D) volume data from MDCT provides various unique applications
      on thoracic diseases. These includes isotropic viewings, use of multiplanar
      reformation (MPR), maximum and minimum intensity projections (MIP and minIP), and
      volume rendering performed from external and internal perspectives allowing the
      user to "fly around" and "fly through" the structures. Recent advances in 3D
      volume rendering put real-time, interactive virtual reality guidance of the
      procedures such as bronchoscopy and surgery into practice.
FAU - Ueno, Junji
AU  - Ueno J
AD  - Department of Radiologic Technology, School of Health Sciences, The University of
      Tokushima, Tokushima, Japan.
FAU - Murase, Tomoya
AU  - Murase T
FAU - Yoneda, Kazuhide
AU  - Yoneda K
FAU - Tsujikawa, Tetsuya
AU  - Tsujikawa T
FAU - Sakiyama, Shoji
AU  - Sakiyama S
FAU - Kondoh, Kazuya
AU  - Kondoh K
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PT  - Review
PL  - Japan
TA  - J Med Invest
JT  - The journal of medical investigation : JMI
JID - 9716841
SB  - IM
MH  - Cardiovascular Diseases/radiography
MH  - Humans
MH  - Image Processing, Computer-Assisted
MH  - Imaging, Three-Dimensional/methods
MH  - Respiratory Tract Diseases/radiography
MH  - Thoracic Diseases/*radiography
MH  - Thoracic Wall/radiography
MH  - Tomography, X-Ray Computed/*methods
RF  - 20
EDAT- 2004/10/06 09:00
MHDA- 2004/11/05 09:00
CRDT- 2004/10/06 09:00
PST - ppublish
SO  - J Med Invest. 2004 Aug;51(3-4):163-70.

PMID- 15458139
OWN - NLM
STAT- MEDLINE
DA  - 20041001
DCOM- 20041102
LR  - 20071114
IS  - 0926-9630 (Print)
IS  - 0926-9630 (Linking)
VI  - 85
DP  - 2002
TI  - Visualization of conserved structures by fusing highly variable datasets.
PG  - 494-500
AB  - INTRODUCTION: Skill, effort, and time are required to identify and visualize
      anatomic structures in three-dimensions from radiological data. Fundamentally,
      automating these processes requires a technique that uses symbolic information
      not in the dynamic range of the voxel data. We were developing such a technique
      based on mutual information for automatic multi-modality image fusion (MIAMI
      Fuse, University of Michigan). This system previously demonstrated facility at
      fusing one voxel dataset with integrated symbolic structure information to a CT
      dataset (different scale and resolution) from the same person. The next step of
      development of our technique was aimed at accommodating the variability of
      anatomy from patient to patient by using warping to fuse our standard dataset to 
      arbitrary patient CT datasets. METHODS: A standard symbolic information dataset
      was created from the full color Visible Human Female by segmenting the liver
      parenchyma, portal veins, and hepatic veins and overwriting each set of voxels
      with a fixed color. Two arbitrarily selected patient CT scans of the abdomen were
      used for reference datasets. We used the warping functions in MIAMI Fuse to align
      the standard structure data to each patient scan. The key to successful fusion
      was the focused use of multiple warping control points that place themselves
      around the structure of interest automatically. The user assigns only a few
      initial control points to align the scans. Fusion 1 and 2 transformed the atlas
      with 27 points around the liver to CT1 and CT2 respectively. Fusion 3 transformed
      the atlas with 45 control points around the liver to CT1 and Fusion 4 transformed
      the atlas with 5 control points around the portal vein. The CT dataset is
      augmented with the transformed standard structure dataset, such that the warped
      structure masks are visualized in combination with the original patient dataset. 
      This combined volume visualization is then rendered interactively in stereo on
      the ImmersaDesk in an immersive Virtual Reality (VR) environment. RESULTS: The
      accuracy of the fusions was determined qualitatively by comparing the transformed
      atlas overlaid on the appropriate CT. It was examined for where the transformed
      structure atlas was incorrectly overlaid (false positive) and where it was
      incorrectly not overlaid (false negative). According to this method, fusions 1
      and 2 were correct roughly 50-75% of the time, while fusions 3 and 4 were correct
      roughly 75-100%. The CT dataset augmented with transformed dataset was viewed
      arbitrarily in user-centered perspective stereo taking advantage of features such
      as scaling, windowing and volumetric region of interest selection. CONCLUSIONS:
      This process of auto-coloring conserved structures in variable datasets is a step
      toward the goal of a broader, standardized automatic structure visualization
      method for radiological data. If successful it would permit identification,
      visualization or deletion of structures in radiological data by
      semi-automatically applying canonical structure information to the radiological
      data (not just processing and visualization of the data's intrinsic dynamic
      range). More sophisticated selection of control points and patterns of warping
      may allow for more accurate transforms, and thus advances in visualization,
      simulation, education, diagnostics, and treatment planning.
FAU - Silverstein, Jonathan C
AU  - Silverstein JC
AD  - University of Chicago, Center for Clinical Information, Chicago, IL 60637-1470,
      USA. jcs@uchicago.edu
FAU - Chhadia, Ankur
AU  - Chhadia A
FAU - Dech, Fred
AU  - Dech F
LA  - eng
GR  - R01-LM-06756-01/LM/NLM NIH HHS/United States
PT  - Journal Article
PT  - Research Support, U.S. Gov't, P.H.S.
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - T
MH  - Algorithms
MH  - Anatomy, Cross-Sectional
MH  - *Automatic Data Processing
MH  - *Computer Simulation
MH  - Female
MH  - Hepatic Veins/*radiography
MH  - Humans
MH  - *Image Enhancement
MH  - *Image Processing, Computer-Assisted
MH  - *Imaging, Three-Dimensional
MH  - Liver/*radiography
MH  - Portal Vein/*radiography
MH  - Reference Values
MH  - Software
MH  - *Tomography, X-Ray Computed
MH  - *User-Computer Interface
EDAT- 2004/10/02 05:00
MHDA- 2004/11/04 09:00
CRDT- 2004/10/02 05:00
PST - ppublish
SO  - Stud Health Technol Inform. 2002;85:494-500.

PMID- 15455880
OWN - NLM
STAT- MEDLINE
DA  - 20040930
DCOM- 20041028
LR  - 20061115
IS  - 0926-9630 (Print)
IS  - 0926-9630 (Linking)
VI  - 94
DP  - 2003
TI  - A haptic sensor-actor-system based on ultrasound elastography and
      electrorheological fluids for virtual reality applications in medicine.
PG  - 144-50
AB  - Mechanical properties of biological tissue represent important diagnostic
      information and are of histological relevance (hard lesions, "nodes" in organs:
      tumors; calcifications in vessels: arteriosclerosis). The problem is, that such
      information is usually obtained by digital palpation only, which is limited with 
      respect to sensitivity. It requires intuitive assessment and does not allow
      quantitative documentation. A suitable sensor is required for quantitative
      detection of mechanical tissue properties. On the other hand, there is also some 
      need for a realistic mechanical display of those tissue properties. Suitable
      actuator arrays with high spatial resolution and real-time capabilities are
      required operating in a haptic sensor actuator system with different
      applications. The sensor system uses real time ultrasonic elastography whereas
      the tactile actuator is based on electrorheological fluids. Due to their small
      size the actuator array elements have to be manufactured by micro-mechanical
      production methods. In order to supply the actuator elements with individual high
      voltages a sophisticated switching and control concept have been designed. This
      haptic system has the potential of inducing real time substantial forces, using a
      compact lightweight mechanism which can be applied to numerous areas including
      intraoperative navigation, telemedicine, teaching, space and telecommunication.
FAU - Khaled, W
AU  - Khaled W
AD  - Ruhr-University Bochum, Bochum, Germany.
FAU - Ermert, H
AU  - Ermert H
FAU - Bruhns, O
AU  - Bruhns O
FAU - Boese, H
AU  - Boese H
FAU - Baumann, M
AU  - Baumann M
FAU - Monkman, G J
AU  - Monkman GJ
FAU - Egersdoerfer, S
AU  - Egersdoerfer S
FAU - Meier, A
AU  - Meier A
FAU - Klein, D
AU  - Klein D
FAU - Freimuth, H
AU  - Freimuth H
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PT  - Research Support, U.S. Gov't, Non-P.H.S.
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - T
MH  - *Computer Simulation
MH  - Elasticity
MH  - Germany
MH  - Humans
MH  - Rheology
MH  - User-Computer Interface
EDAT- 2004/10/01 05:00
MHDA- 2004/10/29 09:00
CRDT- 2004/10/01 05:00
PST - ppublish
SO  - Stud Health Technol Inform. 2003;94:144-50.

PMID- 15381580
OWN - NLM
STAT- MEDLINE
DA  - 20040921
DCOM- 20041223
LR  - 20120924
IS  - 1521-2491 (Print)
IS  - 1521-2491 (Linking)
VI  - 6
IP  - 5
DP  - 2004 Sep-Oct
TI  - The virtual nose: a 3-dimensional virtual reality model of the human nose.
PG  - 328-33
AB  - BACKGROUND: The 3-dimensionally complex interplay of soft tissue, cartilaginous, 
      and bony elements makes the mastery of nasal anatomy difficult. Conventional
      methods of learning nasal anatomy exist, but they often involve a steep learning 
      curve. Computerized models and virtual reality applications have been used to
      facilitate teaching in a number of other complex anatomical regions, such as the 
      human temporal bone and pelvic floor. We present a 3-dimensional (3-D) virtual
      reality model of the human nose. METHODS: Human cadaveric axial cross-sectional
      (0.33-mm cuts) photographic data of the head and neck were used. With 460
      digitized images, individual structures were traced and programmed to create a
      computerized polygonal model of the nose. Further refinements to this model were 
      made using a number of specialized computer programs. This 3-D computer model of 
      the nose was then programmed to operate as a virtual reality model. RESULTS:
      Anatomically correct 3-D model of the nose was produced. High-resolution images
      of the "virtual nose" demonstrate the nasal septum, lower lateral cartilages,
      middle vault, bony dorsum, and other structural details of the nose. Also, the
      model can be combined with a separate virtual reality model of the face and its
      skin cover as well as the skull. The user can manipulate the model in space,
      examine 3-D anatomical relationships, and fade superficial structures to reveal
      deeper ones. CONCLUSIONS: The virtual nose is a 3-D virtual reality model of the 
      nose that is accurate and easy to use. It can be run on a personal computer or in
      a specialized virtual reality environment. It can serve as an effective teaching 
      tool. As the first virtual reality model of the nose, it establishes a virtual
      reality platform from which future applications can be launched.
FAU - Vartanian, A John
AU  - Vartanian AJ
AD  - Division of Facial Plastic and Reconstructive Surgery, Department of
      Otolaryngology--Head and Neck Surgery, University of Illinois at Chicago, IL,
      USA. drvartanian@yahoo.com
FAU - Holcomb, Joi
AU  - Holcomb J
FAU - Ai, Zhuming
AU  - Ai Z
FAU - Rasmussen, Mary
AU  - Rasmussen M
FAU - Tardy, M Eugene
AU  - Tardy ME
FAU - Thomas, J Regan
AU  - Thomas JR
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Arch Facial Plast Surg
JT  - Archives of facial plastic surgery
JID - 100883500
SB  - IM
MH  - Humans
MH  - Imaging, Three-Dimensional
MH  - Nose/*anatomy & histology
MH  - Rhinoplasty/*methods
MH  - *User-Computer Interface
EDAT- 2004/09/24 05:00
MHDA- 2004/12/24 09:00
CRDT- 2004/09/24 05:00
AID - 10.1001/archfaci.6.5.328 [doi]
AID - 6/5/328 [pii]
PST - ppublish
SO  - Arch Facial Plast Surg. 2004 Sep-Oct;6(5):328-33.

PMID- 15360930
OWN - NLM
STAT- MEDLINE
DA  - 20040913
DCOM- 20050610
LR  - 20080710
IS  - 0926-9630 (Print)
IS  - 0926-9630 (Linking)
VI  - 107
IP  - Pt 2
DP  - 2004
TI  - Morpho-functional visualization of dynamic MR-mammography.
PG  - 838-41
AB  - In view of an increasing use of breast MRI supplementing X-ray mammography, the
      purpose of this study was the development of a method for fast and efficient
      analysis of dynamic MR image series of the female breast. The image data sets
      were acquired with a saturation-recovery-turbo-FLASH sequence facilitating the
      detection of the kinetics of the contrast agent concentration in the whole breast
      with a high temporal and spatial resolution. In addition, a morphological
      3D-FLASH data set was acquired. The dynamic image data sets were analyzed by
      tracer kinetic modeling in order to describe the physiological processes
      underlying the contrast enhancement in mathematical terms and thus enable the
      estimation of functional tissue specific parameters, reflecting the status of
      microcirculation. To display morphological and functional tissue information
      simultaneously, a multidimensional real-time visualization system (using
      3D-texture mapping) was developed, which enables a practical and intuitive
      human-computer interface in virtual reality. The spatially differentiated
      representation of the computed functional tissue parameters superimposed on the
      anatomical information offers several possibilities: improved discernibility of
      contrast enhancement, inspection of the data volume in 3D-space and localization 
      of lesions in space and thus fast and more natural recognition of topological
      coherencies. In a feasibility study, it could be demonstrated that
      multidimensional visualization of contrast enhancement in virtual reality is
      practical. Especially, detection and localization of multiple breast lesions may 
      be an important application
FAU - Englmeier, K-H
AU  - Englmeier KH
AD  - GSF--National Research Center for Environment and Health, Institute of Medical
      Informatics Ingolstader Landstrasse 1, Neuherberg, Germany. engelmeier@gsf.de
FAU - Hellwig, G
AU  - Hellwig G
FAU - Griebel, J
AU  - Griebel J
FAU - Delorme, S
AU  - Delorme S
FAU - Siebert, M
AU  - Siebert M
FAU - Brix, G
AU  - Brix G
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
RN  - 0 (Contrast Media)
SB  - IM
MH  - Breast Neoplasms/*diagnosis
MH  - Contrast Media/pharmacokinetics
MH  - Female
MH  - Humans
MH  - *Imaging, Three-Dimensional
MH  - *Magnetic Resonance Imaging
MH  - Models, Chemical
EDAT- 2004/09/14 05:00
MHDA- 2005/06/11 09:00
CRDT- 2004/09/14 05:00
AID - D040004198 [pii]
PST - ppublish
SO  - Stud Health Technol Inform. 2004;107(Pt 2):838-41.

PMID- 15253996
OWN - NLM
STAT- MEDLINE
DA  - 20050105
DCOM- 20050303
LR  - 20071114
IS  - 0268-1153 (Print)
IS  - 0268-1153 (Linking)
VI  - 20
IP  - 1
DP  - 2005 Feb
TI  - Psychometric properties of virtual reality vignette performance measures: a novel
      approach for assessing adolescents' social competency skills.
PG  - 61-70
AB  - This study examined the psychometric properties of performance measures for three
      novel, interactive virtual reality vignette exercises developed to assess social 
      competency skills of at-risk adolescents. Performance data were collected from
      117 African-American male 15-17 year olds. Data for 18 performance measures were 
      obtained, based on adolescents' interaction with a provocative virtual teenage
      character. Twelve of the 18 performance measures loaded on two factors
      corresponding to emotional control and interpersonal communication skills,
      providing support for their factorial validity. The internal reliability
      coefficients for the two multi-item measures were 0.88 and 0.91, respectively.
      Additional analyses with established measures of three psychosocial factors
      (beliefs supporting aggression, aggressive conflict-resolution style and
      hostility) and behavioral criteria (e.g., self-reported behavioral misconduct and
      drug use) provided limited support for the construct and criterion-related
      validity of the performance measures. Study findings suggest that the virtual
      reality vignette exercises may represent a promising approach for assessing
      adolescents' social competency skills.
FAU - Paschall, Mallie J
AU  - Paschall MJ
AD  - Prevention Research Center, Pacific Institute for Research and Evaluation,
      Berkeley, CA 94704, USA. paschall@pire.org
FAU - Fishbein, Diana H
AU  - Fishbein DH
FAU - Hubal, Robert C
AU  - Hubal RC
FAU - Eldreth, Diana
AU  - Eldreth D
LA  - eng
GR  - R01 DA14813/DA/NIDA NIH HHS/United States
PT  - Journal Article
PT  - Research Support, U.S. Gov't, P.H.S.
DEP - 20040714
PL  - England
TA  - Health Educ Res
JT  - Health education research
JID - 8608459
SB  - T
MH  - Adolescent
MH  - *Adolescent Behavior
MH  - Humans
MH  - *Psychometrics
MH  - *Self Efficacy
MH  - *Social Behavior
MH  - *User-Computer Interface
EDAT- 2004/07/16 05:00
MHDA- 2005/03/04 09:00
CRDT- 2004/07/16 05:00
PHST- 2004/07/14 [aheadofprint]
AID - 10.1093/her/cyg103 [doi]
AID - cyg103 [pii]
PST - ppublish
SO  - Health Educ Res. 2005 Feb;20(1):61-70. Epub 2004 Jul 14.

PMID- 15008377
OWN - NLM
STAT- MEDLINE
DA  - 20040310
DCOM- 20040928
LR  - 20071114
IS  - 0090-6964 (Print)
IS  - 0090-6964 (Linking)
VI  - 32
IP  - 2
DP  - 2004 Feb
TI  - Three dimensional virtual reality model of the normal female pelvic floor.
PG  - 292-6
AB  - The anatomy of the pelvic floor is complex and difficult to visualize from
      conventional two-dimensional anatomy pictures. The goal of this project was to
      establish the methods necessary to develop a static three-dimensional virtual
      reality model of the normal female pelvic floor from high-resolution magnetic
      resonance imaging (MRI) scans. An asymptomatic nulliparous 23-year-old female
      with no urinary incontinence symptoms underwent a high-resolution pelvic floor
      MRI scan. Selected pelvic floor structures were manually segmented: bladder,
      urethra, vagina, uterus, cervix, levator ani, obturator externus, obturator
      internus, and pubic bone. With high-resolution scans, accurate segmentation of
      the structures was possible. The completed models were displayed on an
      ImmersaDesk Virtual Reality system and three clinicians verified their accuracy. 
      Stereovision glasses were used to enhance the model while a receiver tracked head
      position. Three-dimensional virtual reality models of the female pelvic floor can
      enhance our understanding of anatomy and physiology of this complex part of the
      body. They can be used as tools for both research and teaching, facilitating
      improved treatment of pelvic floor pathologies.
FAU - Parikh, Mansi
AU  - Parikh M
AD  - Research Service, Hines VA Hospital, Hines, IL 60141, USA.
FAU - Rasmussen, Mary
AU  - Rasmussen M
FAU - Brubaker, Linda
AU  - Brubaker L
FAU - Salomon, Caryl
AU  - Salomon C
FAU - Sakamoto, Kyoko
AU  - Sakamoto K
FAU - Evenhouse, Raymond
AU  - Evenhouse R
FAU - Ai, Zhumming
AU  - Ai Z
FAU - Damaser, Margot S
AU  - Damaser MS
LA  - eng
GR  - N01-LM-9-3543/LM/NLM NIH HHS/United States
PT  - Evaluation Studies
PT  - Journal Article
PT  - Research Support, U.S. Gov't, Non-P.H.S.
PT  - Research Support, U.S. Gov't, P.H.S.
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Adult
MH  - *Computer Graphics
MH  - Computer Simulation
MH  - Environment
MH  - Feasibility Studies
MH  - Female
MH  - Humans
MH  - Image Interpretation, Computer-Assisted/*methods
MH  - Imaging, Three-Dimensional/*methods
MH  - Magnetic Resonance Imaging
MH  - *Models, Anatomic
MH  - Online Systems
MH  - Pelvic Floor/*anatomy & histology
MH  - Reference Values
MH  - *User-Computer Interface
EDAT- 2004/03/11 05:00
MHDA- 2004/09/29 05:00
CRDT- 2004/03/11 05:00
PST - ppublish
SO  - Ann Biomed Eng. 2004 Feb;32(2):292-6.

PMID- 14756930
OWN - NLM
STAT- MEDLINE
DA  - 20040203
DCOM- 20040506
LR  - 20081121
IS  - 1094-9313 (Print)
IS  - 1094-9313 (Linking)
VI  - 6
IP  - 6
DP  - 2003 Dec
TI  - A magnet-friendly virtual reality fiberoptic image delivery system.
PG  - 645-8
AB  - A custom display was built into the MR radiofrequency headcoil to project
      high-resolution, wide field-of-view stereographic images. Advanced stimulus
      presentation technologies such as the one described could potentially contribute 
      to a better understanding of the relation between what people are thinking or
      experiencing, and their associated patterns of brain activity (www.vrpain.com).
FAU - Hoffman, Hunter G
AU  - Hoffman HG
AD  - Human Interface Technology Laboratory, University of Washington, Seattle,
      Washington 98195, USA. hunter@hitL.washington.edu
FAU - Richards, Todd L
AU  - Richards TL
FAU - Magula, Jeff
AU  - Magula J
FAU - Seibel, Eric J
AU  - Seibel EJ
FAU - Hayes, Cecil
AU  - Hayes C
FAU - Mathis, Mark
AU  - Mathis M
FAU - Sharar, Sam R
AU  - Sharar SR
FAU - Maravilla, Kenneth
AU  - Maravilla K
LA  - eng
GR  - HD40954-01/HD/NICHD NIH HHS/United States
GR  - P-50-33812/PHS HHS/United States
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PT  - Research Support, U.S. Gov't, P.H.S.
PL  - United States
TA  - Cyberpsychol Behav
JT  - Cyberpsychology & behavior : the impact of the Internet, multimedia and virtual
      reality on behavior and society
JID - 9804397
SB  - IM
MH  - Computer Graphics/*instrumentation
MH  - *Computer Simulation
MH  - Equipment Design
MH  - Fiber Optic Technology/*instrumentation
MH  - Humans
MH  - Illusions/*psychology
MH  - Magnetic Resonance Imaging/instrumentation/*methods
MH  - Photic Stimulation/*instrumentation
MH  - *User-Computer Interface
EDAT- 2004/02/06 05:00
MHDA- 2004/05/07 05:00
CRDT- 2004/02/06 05:00
AID - 10.1089/109493103322725423 [doi]
PST - ppublish
SO  - Cyberpsychol Behav. 2003 Dec;6(6):645-8.

PMID- 14712872
OWN - NLM
STAT- MEDLINE
DA  - 20040109
DCOM- 20040203
LR  - 20051116
IS  - 0039-6109 (Print)
IS  - 0039-6109 (Linking)
VI  - 83
IP  - 6
DP  - 2003 Dec
TI  - Incorporating robotics into an open-heart program.
PG  - 1369-80
AB  - The above described clinical series show that after a careful and thorough
      training program and stepwise introduction of surgical telemanipulation systems, 
      application of telemanipulations is safe and shows acceptable results. Still, OR 
      times are longer than for conventional procedures, and the operation is
      demanding, and expensive. The main shortcoming is that the procedure is only
      suitable for a highly selected patient population. However, despite all the
      clinical experience gathered in various centers, this technique is still evolving
      and in its beginning. There are some very promising developments that will
      improve the benefit of telemanipulators. For the first time, the separation of
      the surgeon from the surgical field facilitates training of surgeons on
      simulators. This might lead to a higher standard of surgical performance.
      Progress in sensor technology will make tactile-force feedback available, and new
      3 D-visualization systems are designed to provide a better depth perception and
      higher resolution of the endoscopic image. Virtual stabilizing systems will
      enable robotic systems to operate on a virtual arrested heart without the need
      for CPB or mechanical stabilizers. These and other research topics summarized
      under the term augmented reality will enhance the natural senses and abilities of
      the surgeon. More and more, automatization will find its way into the OR.
      Preoperatively collected data about the patient's anatomy will be used to create 
      safety margins, the robotic system will allow for the surgeon's movements, and
      instruments will be able to find their way to the surgical site without remote
      control. Because a stepwise approach has led to the clinical results that we and 
      others have now achieved, it is the basis for further step-by-step development of
      the application of telemanipulation systems in coronary artery bypass grafting,
      and possibly other endoscopic procedures in cardiac surgery.
FAU - Boehm, Dieter H
AU  - Boehm DH
AD  - Department of Cardiovascular Surgery, University Hospital Eppendorf, University
      of Hamburg Medical School, Martinistrasse 52, 22521 Hamburg, Germany.
      dboehm@uke.uni-hamburg.de
FAU - Arnold, Martin B
AU  - Arnold MB
FAU - Detter, Christian
AU  - Detter C
FAU - Reichenspurner, Hermann C
AU  - Reichenspurner HC
LA  - eng
PT  - Journal Article
PT  - Review
PL  - United States
TA  - Surg Clin North Am
JT  - The Surgical clinics of North America
JID - 0074243
SB  - AIM
SB  - IM
MH  - Animals
MH  - Cardiac Surgical Procedures/*methods
MH  - Endoscopy/methods
MH  - *Robotics/methods
RF  - 28
EDAT- 2004/01/10 05:00
MHDA- 2004/02/05 05:00
CRDT- 2004/01/10 05:00
AID - S0039-6109(03)00170-1 [pii]
AID - 10.1016/S0039-6109(03)00170-1 [doi]
PST - ppublish
SO  - Surg Clin North Am. 2003 Dec;83(6):1369-80.

PMID- 14653917
OWN - NLM
STAT- MEDLINE
DA  - 20031205
DCOM- 20040227
LR  - 20051117
IS  - 0022-2151 (Print)
IS  - 0022-2151 (Linking)
VI  - 117
IP  - 10
DP  - 2003 Oct
TI  - Virtual reality modelling language: freely available cross-platform visualization
      technique for 3-D visualization of the inner ear.
PG  - 766-74
AB  - This was a study of the use of virtual reality modelling language (VRML) for
      cross-platform interactive three-dimensional (3-D) visualization of
      high-resolution magnetic resonance (MR) images of the inner ear in the assessment
      of cochlear implant candidates. A retrospective case review was made of cochlear 
      implant candidates undergoing pre-operative high-resolution MR studies to
      determine their suitability for implantation. 3-D visualizations of MR scans of
      the inner ear structures were created using surface rendering and exported as
      portable VRML files. Case studies are presented to illustrate different points of
      interest. VRML reconstructions aided the interpretation of two-dimensional (2-D) 
      source images in a variety of inner ear abnormalities. VRML is an internationally
      recognized standard for cross-platform 3-D visualization that creates a means of 
      providing the implanting surgeon with a portable 3-D representation of the inner 
      ear, aiding interpretation of the complex cross-sectional anatomy of these
      structures, and guiding selection of patients for implantation as well as
      implantation technique. The elucidation of the mechanisms behind inner ear
      malformations can also be aided by detailed imaging studies of the temporal bone,
      with VRML reconstructions providing an easily interpreted representation of
      deformities.
FAU - Hans, Paul
AU  - Hans P
AD  - University Department of Otolaryngology Head and Neck Surgery, Manchester Royal
      Infirmary, UK.
FAU - Jackson, Alan
AU  - Jackson A
FAU - Gillespie, James E
AU  - Gillespie JE
FAU - Ramsden, Richard T
AU  - Ramsden RT
LA  - eng
PT  - Case Reports
PT  - Journal Article
PL  - England
TA  - J Laryngol Otol
JT  - The Journal of laryngology and otology
JID - 8706896
SB  - AIM
SB  - IM
MH  - Adolescent
MH  - Adult
MH  - *Cochlear Implantation
MH  - Ear, Inner/abnormalities/*pathology
MH  - Female
MH  - Hearing Loss/pathology/*surgery
MH  - Humans
MH  - Image Processing, Computer-Assisted/*methods
MH  - Infant
MH  - Magnetic Resonance Imaging/methods
MH  - Male
MH  - Patient Selection
MH  - Preoperative Care/methods
MH  - Retrospective Studies
MH  - Software
EDAT- 2003/12/05 05:00
MHDA- 2004/02/28 05:00
CRDT- 2003/12/05 05:00
AID - 10.1258/002221503770716179 [doi]
PST - ppublish
SO  - J Laryngol Otol. 2003 Oct;117(10):766-74.

PMID- 14643215
OWN - NLM
STAT- MEDLINE
DA  - 20031203
DCOM- 20040719
LR  - 20081121
IS  - 1047-8477 (Print)
IS  - 1047-8477 (Linking)
VI  - 144
IP  - 1-2
DP  - 2003 Oct-Nov
TI  - Interactive fitting augmented by force-feedback and virtual reality.
PG  - 123-31
AB  - The synthesis of low-resolution electron microscopy data with high-resolution
      molecular structures has become a common routine in the modeling of biomolecular 
      assemblies. In contrast to algorithmic "black box" solutions, the interactive
      "fitting by eye" takes advantage of an expert's structural or biochemical
      knowledge and can be used with very noisy experimental data. In the solution
      proposed in this paper, we support the expert user in an interactive fitting
      session by haptic rendering and virtual reality. The quantitative and tactile
      feedback facilitates and objectifies the otherwise unrestrained modeling. We
      introduce a highly accurate reduced representation of the gradient of the
      cross-correlation coefficient that sustains force updates for haptic rendering at
      sufficiently high refresh rates.
FAU - Birmanns, Stefan
AU  - Birmanns S
AD  - School of Health Information Sciences, University of Texas Health Science Center 
      at Houston, 7000 Fannin Street Suite 600, Houston, TX 77030, USA.
FAU - Wriggers, Willy
AU  - Wriggers W
LA  - eng
GR  - 1R01-GM62968/GM/NIGMS NIH HHS/United States
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PT  - Research Support, U.S. Gov't, P.H.S.
PL  - United States
TA  - J Struct Biol
JT  - Journal of structural biology
JID - 9011206
SB  - IM
MH  - Algorithms
MH  - Biophysical Phenomena
MH  - Biophysics
MH  - Image Processing, Computer-Assisted/*methods
MH  - Models, Statistical
MH  - Normal Distribution
MH  - *Software
EDAT- 2003/12/04 05:00
MHDA- 2004/07/20 05:00
CRDT- 2003/12/04 05:00
AID - S1047847703001850 [pii]
PST - ppublish
SO  - J Struct Biol. 2003 Oct-Nov;144(1-2):123-31.

PMID- 14529201
OWN - NLM
STAT- MEDLINE
DA  - 20031007
DCOM- 20031112
LR  - 20061115
IS  - 0018-7208 (Print)
IS  - 0018-7208 (Linking)
VI  - 45
IP  - 2
DP  - 2003 Summer
TI  - Gaze-contingent multiresolutional displays: an integrative review.
PG  - 307-28
AB  - Gaze-contingent multiresolutional displays (GCMRDs) center high-resolution
      information on the user's gaze position, matching the user's area of interest
      (AOI). Image resolution and details outside the AOI are reduced, lowering the
      requirements for processing resources and transmission bandwidth in demanding
      display and imaging applications. This review provides a general framework within
      which GCMRD research can be integrated, evaluated, and guided. GCMRDs (or "moving
      windows") are analyzed in terms of (a) the nature of their images (i.e.,
      "multiresolution," "variable resolution," "space variant," or "level of detail"),
      and (b) the movement of the AOI (i.e., "gaze contingent," "foveated," or "eye
      slaved"). We also synthesize the known human factors research on GCMRDs and point
      out important questions for future research and development. Actual or potential 
      applications of this research include flight, medical, and driving simulators;
      virtual reality; remote piloting and teleoperation; infrared and indirect vision;
      image transmission and retrieval; telemedicine; video teleconferencing; and
      artificial vision systems.
FAU - Reingold, Eyal M
AU  - Reingold EM
AD  - Department of Psychology, University of Toronto, Toronto, Ontario, Canada.
      reingold@psych.utoronto.ca
FAU - Loschky, Lester C
AU  - Loschky LC
FAU - McConkie, George W
AU  - McConkie GW
FAU - Stampe, David M
AU  - Stampe DM
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PT  - Research Support, U.S. Gov't, Non-P.H.S.
PT  - Review
PL  - United States
TA  - Hum Factors
JT  - Human factors
JID - 0374660
SB  - IM
SB  - S
MH  - *Data Display
MH  - *Fixation, Ocular
MH  - Humans
MH  - User-Computer Interface
MH  - Vision, Binocular
MH  - Visual Acuity
MH  - *Visual Fields
RF  - 133
EDAT- 2003/10/08 05:00
MHDA- 2003/11/13 05:00
CRDT- 2003/10/08 05:00
PST - ppublish
SO  - Hum Factors. 2003 Summer;45(2):307-28.

PMID- 12691369
OWN - NLM
STAT- MEDLINE
DA  - 20030414
DCOM- 20030611
LR  - 20061115
IS  - 0018-7208 (Print)
IS  - 0018-7208 (Linking)
VI  - 44
IP  - 4
DP  - 2002 Winter
TI  - Variable-resolution displays: a theoretical, practical, and behavioral
      evaluation.
PG  - 611-29
AB  - Variable-resolution display techniques present visual information in a display
      using more than one resolution. For example, gaze-contingent variable-resolution 
      displays allocate computational resources for image generation preferentially to 
      the area around the center of gaze, where visual sensitivity to detail is the
      greatest. Using such displays reduces the amount of computational resources
      required as compared with traditional uniform-resolution displays. The
      theoretical benefits, implementational issues, and behavioral consequences of
      variable-resolution displays are reviewed. A mathematical analysis of
      computational efficiency for a two-region variable-resolution display is
      conducted. The results are discussed in relation to applications that are limited
      by computational resources, such as virtual reality, and applications that are
      limited by bandwidth, such as internet image transmission. The potential for
      variable-resolution display techniques as a viable future technology is
      discussed.
FAU - Parkhurst, Derrick J
AU  - Parkhurst DJ
AD  - Zanvyl Krieger Mind/Brain Institute, Johns Hopkins University, Baltimore,
      Maryland 21218, USA.
FAU - Niebur, Ernst
AU  - Niebur E
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PT  - Research Support, U.S. Gov't, Non-P.H.S.
PT  - Research Support, U.S. Gov't, P.H.S.
PL  - United States
TA  - Hum Factors
JT  - Human factors
JID - 0374660
SB  - IM
SB  - S
MH  - *Attention
MH  - *Data Display
MH  - Humans
MH  - Mathematical Computing
MH  - *Orientation
MH  - Pattern Recognition, Visual
MH  - Psychophysics
MH  - *User-Computer Interface
MH  - Visual Acuity
MH  - Visual Fields
EDAT- 2003/04/15 05:00
MHDA- 2003/06/12 05:00
CRDT- 2003/04/15 05:00
PST - ppublish
SO  - Hum Factors. 2002 Winter;44(4):611-29.

PMID- 12564561
OWN - NLM
STAT- MEDLINE
DA  - 20030204
DCOM- 20030303
LR  - 20061115
IS  - 0743-3808 (Print)
IS  - 0743-3808 (Linking)
VI  - 34
IP  - 4
DP  - 2002 Nov
TI  - 3-D eye movement analysis.
PG  - 573-91
AB  - This paper presents a novel three-dimensional (3-D) eye movement analysis
      algorithm for binocular eye tracking within virtual reality (VR). The user's gaze
      direction, head position, and orientation are tracked in order to allow recording
      of the user's fixations within the environment. Although the linear signal
      analysis approach is itself not new, its application to eye movement analysis in 
      three dimensions advances traditional two-dimensional approaches, since it takes 
      into account the six degrees of freedom of head movements and is resolution
      independent. Results indicate that the 3-D eye movement analysis algorithm can
      successfully be used for analysis of visual process measures in VR. Process
      measures not only can corroborate performance measures, but also can lead to
      discoveries of the reasons for performance improvements. In particular, analysis 
      of users' eye movements in VR can potentially lead to further insights into the
      underlying cognitive processes of VR subjects.
FAU - Duchowski, Andrew
AU  - Duchowski A
AD  - Department of Computer Science, Clemson University, Clemson, South Carolina
      29634-0974, USA. andrewd@cs.clemson.edu
FAU - Medlin, Eric
AU  - Medlin E
FAU - Cournia, Nathan
AU  - Cournia N
FAU - Murphy, Hunter
AU  - Murphy H
FAU - Gramopadhye, Anand
AU  - Gramopadhye A
FAU - Nair, Santosh
AU  - Nair S
FAU - Vorah, Jeenal
AU  - Vorah J
FAU - Melloy, Brian
AU  - Melloy B
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PT  - Research Support, U.S. Gov't, Non-P.H.S.
PL  - United States
TA  - Behav Res Methods Instrum Comput
JT  - Behavior research methods, instruments, & computers : a journal of the
      Psychonomic Society, Inc
JID - 8413015
SB  - IM
MH  - Adult
MH  - Algorithms
MH  - Fixation, Ocular/physiology
MH  - Humans
MH  - Models, Statistical
MH  - Random Allocation
MH  - Saccades/*physiology
MH  - User-Computer Interface
EDAT- 2003/02/05 04:00
MHDA- 2003/03/04 04:00
CRDT- 2003/02/05 04:00
PST - ppublish
SO  - Behav Res Methods Instrum Comput. 2002 Nov;34(4):573-91.

PMID- 12493098
OWN - NLM
STAT- MEDLINE
DA  - 20021220
DCOM- 20030318
LR  - 20041117
IS  - 0148-396X (Print)
IS  - 0148-396X (Linking)
VI  - 52
IP  - 1
DP  - 2003 Jan
TI  - The genesis of neurosurgery and the evolution of the neurosurgical operative
      environment: part II--concepts for future development, 2003 and beyond.
PG  - 20-33; discussion 33-5
AB  - The future development of the neurosurgical operative environment is driven
      principally by concurrent development in science and technology. In the new
      millennium, these developments are taking on a Jules Verne quality, with the
      ability to construct and manipulate the human organism and its surroundings at
      the level of atoms and molecules seemingly at hand. Thus, an examination of
      currents in technology advancement from the neurosurgical perspective can provide
      insight into the evolution of the neurosurgical operative environment. In the
      future, the optimal design solution for the operative environment requirements of
      specialized neurosurgery may take the form of composites of venues that are
      currently mutually distinct. Advances in microfabrication technology and laser
      optical manipulators are expanding the scope and role of robotics, with novel
      opportunities for bionic integration. Assimilation of biosensor technology into
      the operative environment promises to provide neurosurgeons of the future with a 
      vastly expanded set of physiological data, which will require concurrent
      simplification and optimization of analysis and presentation schemes to
      facilitate practical usefulness. Nanotechnology derivatives are shattering the
      maximum limits of resolution and magnification allowed by conventional
      microscopes. Furthermore, quantum computing and molecular electronics promise to 
      greatly enhance computational power, allowing the emerging reality of simulation 
      and virtual neurosurgery for rehearsal and training purposes. Progressive
      minimalism is evident throughout, leading ultimately to a paradigm shift as the
      nanoscale is approached. At the interface between the old and new technological
      paradigms, issues related to integration may dictate the ultimate emergence of
      the products of the new paradigm. Once initiated, however, history suggests that 
      the process of change will proceed rapidly and dramatically, with the ultimate
      neurosurgical operative environment of the future being far more complex in
      functional capacity but strikingly simple in apparent form.
FAU - Liu, Charles Y
AU  - Liu CY
AD  - Department of Neurological Surgery, Keck School of Medicine, University of
      Southern California, Los Angeles, California, USA.
FAU - Spicer, Mark
AU  - Spicer M
FAU - Apuzzo, Michael L J
AU  - Apuzzo ML
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Neurosurgery
JT  - Neurosurgery
JID - 7802914
SB  - IM
MH  - Forecasting
MH  - Humans
MH  - Microsurgery/*trends
MH  - Neuronavigation/*trends
MH  - Neurosurgery/*trends
MH  - Operating Rooms/*trends
MH  - Robotics/*trends
MH  - Surgery, Computer-Assisted/*trends
MH  - Surgical Equipment/trends
MH  - *User-Computer Interface
EDAT- 2002/12/21 04:00
MHDA- 2003/03/19 04:00
CRDT- 2002/12/21 04:00
PHST- 2002/05/31 [received]
PHST- 2002/09/11 [accepted]
PST - ppublish
SO  - Neurosurgery. 2003 Jan;52(1):20-33; discussion 33-5.

PMID- 12449358
OWN - NLM
STAT- MEDLINE
DA  - 20021125
DCOM- 20030313
LR  - 20061115
IS  - 1076-6332 (Print)
IS  - 1076-6332 (Linking)
VI  - 9
IP  - 11
DP  - 2002 Nov
TI  - Dynamic MR mammography: three-dimensional real-time visualization of contrast
      enhancement in virtual reality.
PG  - 1255-63
AB  - RATIONALE AND OBJECTIVES: In view of the increasing use of breast magnetic
      resonance (MR) imaging to supplement x-ray mammography. the authors developed a
      method for fast and efficient analysis of dynamic MR images of the female breast.
      MATERIALS AND METHODS: The MR image data sets were acquired with a
      saturation-recovery turbo fast low-angle shot sequence to detect the kinetics of 
      the contrast agent concentration in the whole breast at a high temporal and
      spatial resolution. A morphologic three-dimensional fast low-angle shot data set 
      was also acquired. The dynamic image data sets were analyzed with tracer kinetic 
      modeling to describe the physiologic processes underlying the contrast
      enhancement in mathematical terms and enable the estimation of functional
      tissue-specific parameters, which reflect the status of microcirculation. To
      display morphologic and functional tissue information simultaneously, the authors
      developed a multidimensional real-time visualization system (with
      three-dimensional texture mapping), which enables a practical and intuitive human
      computer interface in virtual reality. RESULTS: The spatially differentiated
      representation of the computed functional tissue parameters superimposed on the
      anatomic information offers several possibilities: (a) more discernible contrast 
      enhancement, (b) inspection of the data volume in three-dimensional space by
      means of rotation and transparency variation, (c) location of lesions in space
      and thus faster and more natural recognition of topologic coherencies, and (d)
      fast and efficient overview in compressed form. CONCLUSION: A feasibility study
      demonstrated that multidimensional visualization of contrast enhancement in
      virtual reality is a practicable idea. Detection and location of multiple breast 
      lesions may be an important application.
FAU - Hellwig, Gesine
AU  - Hellwig G
AD  - GSF-National Research Center for Environment and Health, In- stitute of Medical
      Informatics, Neuherberg, Germany.
FAU - Brix, Gunnar
AU  - Brix G
FAU - Griebel, Jurgen
AU  - Griebel J
FAU - Lucht, Robert
AU  - Lucht R
FAU - Delorme, Stefan
AU  - Delorme S
FAU - Siebert, Markus
AU  - Siebert M
FAU - Engimeier, Karl-Hans
AU  - Engimeier KH
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - United States
TA  - Acad Radiol
JT  - Academic radiology
JID - 9440159
RN  - 0 (Contrast Media)
SB  - IM
MH  - Breast/*pathology
MH  - Breast Neoplasms/*diagnosis/radiography
MH  - Contrast Media/pharmacokinetics
MH  - Feasibility Studies
MH  - Female
MH  - Humans
MH  - Imaging, Three-Dimensional/*methods
MH  - Magnetic Resonance Imaging/*methods
MH  - Mammography/*methods
MH  - User-Computer Interface
EDAT- 2002/11/27 04:00
MHDA- 2003/03/14 04:00
CRDT- 2002/11/27 04:00
PST - ppublish
SO  - Acad Radiol. 2002 Nov;9(11):1255-63.

PMID- 12244471
OWN - NLM
STAT- MEDLINE
DA  - 20020923
DCOM- 20030303
LR  - 20061115
IS  - 0033-832X (Print)
IS  - 0033-832X (Linking)
VI  - 42
IP  - 9
DP  - 2002 Sep
TI  - [Virtual endoscopy of the upper, central and peripheral airways with multirow
      detector CT].
PG  - 703-11
AB  - Virtual endoscopy of the upper, central and peripheral airways (virtual
      laryngoscopy or virtual bronchoscopy) produces endoluminal images similar to
      those of fiberoptic endoscopy. In particular, virtual endoscopy is useful for the
      assessment of endoluminal tumor extent and tracheobronchial stenosis. Especially 
      since the introduction of multirow detector CT, high-resolution
      virtual-endoscopic images of the airways can be reconstructed. Either surface
      rendering or volume rendering can be used for realistic depiction of the airways.
      Semitransparent color-coded volume rendering is advantageous, because adjacent
      structures can be displayed in addition to endoluminal views. A major advantage
      of virtual endoscopy over fiberoptic endoscopy is its non-invasiveness. With
      virtual endoscopy, even a high-grade stenosis is passable, enabling evaluation of
      the distal airways. Disadvantages are its inability to depict mucosal color and
      to perform therapeutic maneuvers. In comparison to other CT display modes,
      virtual endoscopy allows a more realistic assessment of tracheobronchial stenosis
      than axial CT slices and multiplanar reformats. Virtual endoscopy of the airways 
      can be used complementary to fiberoptic endoscopy before tracheotomy, stent
      implantation or lung resection and for post-operative follow-up. In the future,
      virtual airway endoscopy will be increasingly applied for interactive virtual
      reality guidance of airway procedures such as bronchoscopy and surgery.
FAU - Hoppe, H
AU  - Hoppe H
AD  - Institut fur Diagnostische Radiologie, Universitatsspital Bern, Germany.
      hanno.hoppe@insel.ch
FAU - Dinkel, H-P
AU  - Dinkel HP
FAU - Thoeny, H
AU  - Thoeny H
FAU - Gugger, M
AU  - Gugger M
FAU - Vock, P
AU  - Vock P
LA  - ger
PT  - English Abstract
PT  - Evaluation Studies
PT  - Journal Article
PT  - Review
TT  - Virtuelle Endoskopie der oberen, zentralen und peripheren Atemwege mit
      Mehrzeilen-Spiral-CT.
PL  - Germany
TA  - Radiologe
JT  - Der Radiologe
JID - 0401257
SB  - IM
MH  - Bronchial Diseases/*radiography
MH  - Bronchoscopy/*methods
MH  - Humans
MH  - Image Processing, Computer-Assisted/*methods
MH  - *Imaging, Three-Dimensional
MH  - Lung Neoplasms/*radiography
MH  - Sensitivity and Specificity
MH  - Tomography, X-Ray Computed/*methods
MH  - Tracheal Stenosis/*radiography
MH  - *User-Computer Interface
RF  - 53
EDAT- 2002/09/24 06:00
MHDA- 2003/03/04 04:00
CRDT- 2002/09/24 06:00
AID - 10.1007/s00117-002-0790-6 [doi]
PST - ppublish
SO  - Radiologe. 2002 Sep;42(9):703-11.

PMID- 11745684
OWN - NLM
STAT- MEDLINE
DA  - 20011217
DCOM- 20020204
LR  - 20041117
IS  - 0022-3417 (Print)
IS  - 0022-3417 (Linking)
VI  - 195
IP  - 4
DP  - 2001 Nov
TI  - Automated complete slide digitization: a medium for simultaneous viewing by
      multiple pathologists.
PG  - 508-14
AB  - Developments in telepathology robotic systems have evolved the concept of a
      'virtual microscope' handling 'digital slides'. Slide digitization is a method of
      archiving salient histological features in numerical (digital) form. The value
      and potential of this have begun to be recognized by several international
      centres. Automated complete slide digitization has application at all levels of
      clinical practice and will benefit undergraduate, postgraduate, and continuing
      education. Unfortunately, as the volume of potential data on a histological slide
      represents a significant problem in terms of digitization, storage, and
      subsequent manipulation, the reality of virtual microscopy to date has comprised 
      limited views at inadequate resolution. This paper outlines a system refined in
      the authors' laboratory, which employs a combination of enhanced hardware, image 
      capture, and processing techniques designed for telepathology. The system is able
      to scan an entire slide at high magnification and create a library of such slides
      that may exist on an internet server or be distributed on removable media (such
      as CD-ROM or DVD). A digital slide allows image data manipulation at a level not 
      possible with conventional light microscopy. Combinations of multiple users,
      multiple magnifications, annotations, and addition of ancillary textual and
      visual data are now possible. This demonstrates that with increased
      sophistication, the applications of telepathology technology need not be confined
      to second opinion, but can be extended on a wider front.
CI  - Copyright 2001 John Wiley & Sons, Ltd.
FAU - Leong, F J
AU  - Leong FJ
AD  - University of Oxford, Nuffield Department of Clinical Laboratory Sciences, Level 
      4 Academic Block, John Radcliffe Hospital, Oxford OX3 9DU, UK.
FAU - McGee, J O
AU  - McGee JO
LA  - eng
PT  - Journal Article
PL  - England
TA  - J Pathol
JT  - The Journal of pathology
JID - 0204634
SB  - IM
MH  - *Analog-Digital Conversion
MH  - CD-ROM
MH  - Histological Techniques
MH  - Humans
MH  - Image Processing, Computer-Assisted
MH  - Telepathology/*methods
EDAT- 2001/12/18 10:00
MHDA- 2002/02/05 10:01
CRDT- 2001/12/18 10:00
AID - 10.1002/path.972 [pii]
AID - 10.1002/path.972 [doi]
PST - ppublish
SO  - J Pathol. 2001 Nov;195(4):508-14.

PMID- 11669131
OWN - NASA
STAT- MEDLINE
DA  - 20011022
DCOM- 20011226
LR  - 20071115
IS  - 0094-5765 (Print)
IS  - 0094-5765 (Linking)
VI  - 49
IP  - 3-10
DP  - 2001 Aug-Nov
TI  - A 6 D.O.F. opto-inertial tracker for virtual reality experiments in microgravity.
PG  - 451-62
AB  - Gravity plays a role in many different levels of human motor behavior. It
      dictates the laws of motion of our body and limbs, as well as of the objects in
      the external world with which we wish to interact. The dynamic interaction of our
      body with the world is molded within gravity's constraints. The role played by
      gravity in the perception of visual stimuli and the elaboration of human movement
      is an active research theme in the field of Neurophysiology. Conditions of
      microgravity, coupled with techniques from the world of virtual reality, provide 
      a unique opportunity to address these questions concerning the function of the
      human sensorimotor system. The ability to measure movements of the head and to
      update in real time the visual scene presented to the subject based on these
      measurements is a key element in producing a realistic virtual environment. A
      variety of head-tracking hardware exists on the market today, but none seem
      particularly well suited to the constraints of working with a space station
      environment. Nor can any of the existing commercial systems meet the more
      stringent requirements for physiological experimentation (high accuracy, high
      resolution, low jitter, low lag) in a wireless configuration. To this end, we
      have developed and tested a hybrid opto-inertial 6 degree-of-freedom tracker
      based on existing inertial technology. To confirm that the inertial components
      and algorithms will function properly, this system was tested in the microgravity
      conditions of parabolic flight. Here we present the design goals of this tracker,
      the system configuration and the results of 0g and 1g testing.
CI  - c 2001. Elsevier Science Ltd. All rights reserved.
FAU - Zaoui, M
AU  - Zaoui M
AD  - LPPA/CNRS--College de France, Paris, France.
FAU - Wormell, D
AU  - Wormell D
FAU - Altshuler, Y
AU  - Altshuler Y
FAU - Foxlin, E
AU  - Foxlin E
FAU - McIntyre, J
AU  - McIntyre J
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - England
TA  - Acta Astronaut
JT  - Acta astronautica
JID - 9890631
SB  - S
MH  - Acceleration
MH  - Algorithms
MH  - Computers
MH  - Equipment Design
MH  - Evaluation Studies as Topic
MH  - Gravitation
MH  - *Head Movements
MH  - Humans
MH  - *Psychomotor Performance
MH  - Space Flight/*instrumentation
MH  - *User-Computer Interface
MH  - *Weightlessness
SFM - Flight Experiment
SFM - Parabolic Flight
SFM - manned
SFM - short duration
EDAT- 2001/10/24 10:00
MHDA- 2002/01/05 10:01
CRDT- 2001/10/24 10:00
PST - ppublish
SO  - Acta Astronaut. 2001 Aug-Nov;49(3-10):451-62.

PMID- 11472090
OWN - NLM
STAT- MEDLINE
DA  - 20010726
DCOM- 20020117
LR  - 20111117
IS  - 1047-8477 (Print)
IS  - 1047-8477 (Linking)
VI  - 133
IP  - 2-3
DP  - 2001 Feb-Mar
TI  - Using situs for flexible and rigid-body fitting of multiresolution
      single-molecule data.
PG  - 193-202
AB  - We describe here a set of multiresolution visualization and docking procedures
      that we refer to as the Situs package. The package was developed to provide an
      efficient and robust method for the fitting of atomic structures into
      low-resolution data. The current release was optimized specifically for the
      visualization and docking of single molecules. A novel 3D graphics viewer,
      volslice3d, was developed for the package to provide an immersive virtual reality
      environment for measuring and rendering volumetric data sets. The precision of
      single-molecule, rigid-body docking was tested on simulated (noise-free)
      low-resolution density maps. For spatial resolutions near 20 A typically arising 
      in electron microscopy image reconstructions, a docking precision on the order of
      1 A can be achieved. The shape-matching score captured the correct solutions in
      all 10 trial cases and was sufficiently stringent to yield unique matches in 8
      systems. Novel routines were developed for the flexible docking of atomic
      structures whose shape deviates from the corresponding low-resolution shape. Test
      calculations on isoforms of actin and lactoferrin demonstrate that the flexible
      docking faithfully reproduces conformational differences with a precision < 2 A
      if atomic structures are locally conserved.
CI  - Copyright 2001 Academic Press.
FAU - Wriggers, W
AU  - Wriggers W
AD  - Department of Molecular Biology, The Scripps Research Institute, 10550 N. Torrey 
      Pines Road, La Jolla, California 92037, USA. wriggers@scripps.edu
FAU - Birmanns, S
AU  - Birmanns S
LA  - eng
GR  - 1R01-GM62968-01/GM/NIGMS NIH HHS/United States
GR  - P41-RR-12255-02/RR/NCRR NIH HHS/United States
PT  - Journal Article
PT  - Research Support, U.S. Gov't, P.H.S.
PL  - United States
TA  - J Struct Biol
JT  - Journal of structural biology
JID - 9011206
RN  - 0 (Actins)
RN  - 0 (Protein Isoforms)
RN  - EC 3.4.21.- (Lactoferrin)
SB  - IM
MH  - Actins/chemistry
MH  - Animals
MH  - *Computer Graphics
MH  - Computer Simulation
MH  - Crystallography, X-Ray
MH  - Humans
MH  - Imaging, Three-Dimensional/*methods/standards
MH  - Lactoferrin/chemistry
MH  - Microscopy, Electron
MH  - *Models, Molecular
MH  - Protein Conformation
MH  - Protein Isoforms/chemistry
MH  - Sensitivity and Specificity
MH  - Software
EDAT- 2001/07/27 10:00
MHDA- 2002/01/18 10:01
CRDT- 2001/07/27 10:00
AID - 10.1006/jsbi.2000.4350 [doi]
AID - S1047-8477(00)94350-8 [pii]
PST - ppublish
SO  - J Struct Biol. 2001 Feb-Mar;133(2-3):193-202.

PMID- 11458243
OWN - NLM
STAT- MEDLINE
DA  - 20010717
DCOM- 20011025
LR  - 20081121
IS  - 1079-2104 (Print)
IS  - 1079-2104 (Linking)
VI  - 92
IP  - 1
DP  - 2001 Jul
TI  - Principles of computer-assisted arthroscopy of the temporomandibular joint with
      optoelectronic tracking technology.
PG  - 30-7
AB  - PURPOSE: This preliminary clinical study evaluated the applicability, accuracy,
      and benefits of computer-assisted arthroscopy of the temporomandibular joint
      (TMJ) with optoelectronic tracking technology. MATERIALS AND METHODS: A hybrid of
      reality and virtual reality is built as a composite-reality environment by
      extracting 3-dimensional anatomical structures through use of computed
      tomography, magnetic resonance imaging, radiography, and other types of imaging
      procedures commonly used in clinical praxis. These various independent sources of
      imaging data of a particular patient can be combined with and complemented by
      complex graphic simulations. Intraoperatively they are merged with online
      position data of surgical instruments inside the patient's TMJ. This hybrid model
      of detailed anatomical structures, guidelines, and real-time instrument positions
      allows the surgeon to accurately plan the arthroscopic intervention as well as to
      navigate effectively intraoperatively. RESULTS: In the first 10 cases of
      computer-assisted TMJ arthroscopy, composite reality environment technology
      permitted the online visualization of TMJ structures, puncture sites, instrument 
      positions, and virtual pathways in relation to anatomical landmarks with high
      spatial accuracy (minimum, 0.0 mm; maximum, 2.5 mm; mean, 1.4 mm; SD, 0.6 mm) and
      high temporal resolution (100 ms). Past, present, and possible future instrument 
      positions can be displayed. The application of computer-assisted arthroscopy
      caused little immobility for either surgeon or patient. CONCLUSION: Even
      experienced surgeons profit from improved precision in the handling of the
      arthroscope; thus this technology was found to be particularly useful in
      degenerative temporomandibular disorders and for triangulation procedures.
FAU - Wagner, A
AU  - Wagner A
AD  - University Clinic of Maxillofacial Surgery, Medical School, University of Vienna,
      Austria.
FAU - Undt, G
AU  - Undt G
FAU - Watzinger, F
AU  - Watzinger F
FAU - Wanschitz, F
AU  - Wanschitz F
FAU - Schicho, K
AU  - Schicho K
FAU - Yerit, K
AU  - Yerit K
FAU - Kermer, C
AU  - Kermer C
FAU - Birkfellner, W
AU  - Birkfellner W
FAU - Ewers, R
AU  - Ewers R
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - United States
TA  - Oral Surg Oral Med Oral Pathol Oral Radiol Endod
JT  - Oral surgery, oral medicine, oral pathology, oral radiology, and endodontics
JID - 9508562
SB  - D
SB  - IM
MH  - Arthroscopes
MH  - *Arthroscopy
MH  - Calibration
MH  - Computer Graphics
MH  - Computer Simulation
MH  - Electronics, Medical/*instrumentation
MH  - Humans
MH  - Image Enhancement
MH  - Image Processing, Computer-Assisted
MH  - Imaging, Three-Dimensional
MH  - Intraoperative Care
MH  - Magnetic Resonance Imaging
MH  - Online Systems
MH  - Optics and Photonics/*instrumentation
MH  - Patient Care Planning
MH  - Punctures
MH  - Temporomandibular Joint/*surgery
MH  - *Therapy, Computer-Assisted/instrumentation
MH  - Tomography, X-Ray Computed
MH  - User-Computer Interface
MH  - Video Recording
EDAT- 2001/07/18 10:00
MHDA- 2001/10/26 10:01
CRDT- 2001/07/18 10:00
AID - S1079-2104(01)40187-9 [pii]
AID - 10.1067/moe.2001.114384 [doi]
PST - ppublish
SO  - Oral Surg Oral Med Oral Pathol Oral Radiol Endod. 2001 Jul;92(1):30-7.

PMID- 11253080
OWN - NLM
STAT- MEDLINE
DA  - 20010316
DCOM- 20010329
LR  - 20061115
IS  - 1438-9029 (Print)
IS  - 1438-9010 (Linking)
VI  - 173
IP  - 2
DP  - 2001 Feb
TI  - [Use of VR (virtual reality) software for preoperative implantation fitting with 
      an implantable hearing aid as an example].
PG  - 103-8
AB  - PURPOSE: To prove the feasibility of a preoperative fitting test for an
      implantable hearing aid using a VR environment. METHODS: A high-resolution spiral
      CT was performed after mastoidectomy in 10 temporal bone specimens. The bony
      structures were segmented and merged with the Computer-Aided Design (CAD) data of
      the hearing aid in a VR environment. For each specimen a three-dimensional
      fitting test was carried out by three examiners determining the implantability of
      the hearing aid. The implantation simulation was compared with the real
      implantation procedure performed by an experienced ENT surgeon. RESULTS: The used
      VR system enabled real-time 3D-visualisation and manipulation of CT- and
      CAD-data. All objects could be independently moved in all three dimensions. The
      VR fitting test corresponded closely with the real implantation. The
      implantability of the hearing aid was properly predicted by all three examiners. 
      CONCLUSION: Merging CT and CAD data in a virtual reality environment bears high
      potential for the pre-surgical determination of the fit and mountability of
      medical implants in complex anatomical regions.
FAU - Dammann, F
AU  - Dammann F
AD  - Radiologische Klinik, Abt. fur Radiologische Diagnostik,
      Eberhard-Karls-Universitat Tubingen. florian.dammann@med.uni-tuebingen.de
FAU - Bode, A
AU  - Bode A
FAU - Heuschmid, M
AU  - Heuschmid M
FAU - Schwaderer, E
AU  - Schwaderer E
FAU - Maassen, M
AU  - Maassen M
FAU - Schaich, M
AU  - Schaich M
FAU - Seemann, M
AU  - Seemann M
FAU - Zenner, H P
AU  - Zenner HP
FAU - Claussen, C D
AU  - Claussen CD
LA  - ger
PT  - Comparative Study
PT  - English Abstract
PT  - Journal Article
TT  - Einsatz einer VR (Virtuelle Realitat)-Software zur praoperativen
      Implantationsprufung am Beispiel eines implantierbaren Horgerates.
PL  - Germany
TA  - Rofo
JT  - RoFo : Fortschritte auf dem Gebiete der Rontgenstrahlen und der Nuklearmedizin
JID - 7507497
SB  - IM
MH  - *Cochlear Implantation
MH  - *Cochlear Implants
MH  - Computer Simulation
MH  - Computer-Aided Design
MH  - Humans
MH  - Image Processing, Computer-Assisted
MH  - Mastoid/radiography/surgery
MH  - Predictive Value of Tests
MH  - Preoperative Care
MH  - *Software
MH  - Tomography, X-Ray Computed
MH  - *User-Computer Interface
EDAT- 2001/03/17 10:00
MHDA- 2001/04/03 10:01
CRDT- 2001/03/17 10:00
AID - 10.1055/s-2001-10892 [doi]
PST - ppublish
SO  - Rofo. 2001 Feb;173(2):103-8.

PMID- 11158653
OWN - NLM
STAT- MEDLINE
DA  - 20010222
DCOM- 20010531
LR  - 20041117
IS  - 0271-5333 (Print)
IS  - 0271-5333 (Linking)
VI  - 21
IP  - 1
DP  - 2001 Jan-Feb
TI  - Computer-aided surgical planning for implantation of hearing aids based on CT
      data in a VR environment.
PG  - 183-91
AB  - A study was undertaken to assess the feasibility of a preoperative fitting test
      for an implantable hearing aid in a virtual reality (VR) environment.
      High-resolution spiral computed tomography (CT) of the mastoid bone was
      performed, and the results of a mastoidectomy were simulated with manual
      segmentation on a standard medical workstation. CT was also performed on a
      temporal bone specimen obtained at real mastoidectomy, and the bone margins were 
      segmented automatically with threshold-based techniques. A triangulated surface
      representation of the bone structures including the mastoid cavity was generated.
      These data as well as the computer-aided design (CAD) files of the medical
      devices were transferred into a VR environment. The CAD components of the hearing
      aid were manipulated to simulate the surgical implantation procedure. Merging CAD
      data of an implantable hearing aid with CT data of the temporal bone in a VR
      environment was shown to be a feasible method of providing three-dimensional
      information for the presurgical determination of fit and mountability. Advances
      in hardware and software are expected to improve the usability of this method.
      Although clinical studies are needed, these results may serve as an impetus for
      exploring the use of low-cost, widely available VR computer equipment in a
      potentially broad field of clinical applications.
FAU - Dammann, F
AU  - Dammann F
AD  - Departments of Diagnostic Radiology, University Hospital Tubingen,
      Hoppe-Seyler-Strasse 3, D-72076 Tubingen, Germany.
      florian.dammann@med.uni-tuebingen.de
FAU - Bode, A
AU  - Bode A
FAU - Schwaderer, E
AU  - Schwaderer E
FAU - Schaich, M
AU  - Schaich M
FAU - Heuschmid, M
AU  - Heuschmid M
FAU - Maassen, M M
AU  - Maassen MM
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Radiographics
JT  - Radiographics : a review publication of the Radiological Society of North
      America, Inc
JID - 8302501
SB  - IM
MH  - *Cochlear Implants
MH  - Computer Simulation
MH  - *Computer-Aided Design
MH  - Deafness/rehabilitation
MH  - Feasibility Studies
MH  - Humans
MH  - Imaging, Three-Dimensional
MH  - Mastoid/*radiography
MH  - Preoperative Care
MH  - *Prosthesis Implantation
MH  - Temporal Bone/*radiography
MH  - *Tomography, X-Ray Computed
MH  - User-Computer Interface
EDAT- 2001/02/07 11:00
MHDA- 2001/06/02 10:01
CRDT- 2001/02/07 11:00
AID - 10.1148/radiographics.21.1.g01ja21183 [doi]
PST - ppublish
SO  - Radiographics. 2001 Jan-Feb;21(1):183-91.

PMID- 11144789
OWN - NLM
STAT- MEDLINE
DA  - 20001228
DCOM- 20010201
LR  - 20061115
IS  - 0007-1285 (Print)
IS  - 0007-1285 (Linking)
VI  - 73
IP  - 875
DP  - 2000 Nov
TI  - Advances in ultrasound: from microscanning to telerobotics.
PG  - 1138-47
AB  - This paper is in memory of W V Mayneord (1902-1988). Experiments conducted in
      Mayneord's laboratory were amongst the first to show that ultrasound had
      diagnostic potential. Now, one in every four imaging studies uses ultrasound.
      Amongst numerous contemporary advances, microscanning is concerned with imaging
      subcentimetre size volumes of tissue in three dimensions with 10-100 microns
      resolution. The traditional approach is by pulse echo imaging, with a focused
      ultrasonic beam in the frequency range 20-100 MHz. This approach may be
      complemented by ultrasonic CT (to correct for attenuation and speed variations), 
      reflex transmission imaging (to provide attenuation data) and synthetic aperture 
      scanning (to decrease imaging time). Harmonic microscanning may reduce artefacts,
      and elasticity imaging may also be possible. Microscanning is likely to have
      applications in pathology and in the operating room, for trackless
      microintervention, in molecular biology and drug studies, and in experimental
      imaging of small mammals including, in particular, the mouse. Robotics is the
      engineering science concerned with devices that are able to execute tasks usually
      performed by humans. Two procedures, ultrasonically guided biopsy and ultrasonic 
      laparoscopy, are being used to demonstrate the feasibility of telerobotics. The
      approach is that of telepresence, as distinct from supervisory control or virtual
      reality. Problems associated with image compression and communications latency
      are identified. Although incremental developments in medical ultrasound have
      resulted from clinical pull, major advances have, in general, been due to
      technical push.
FAU - Wells, P N
AU  - Wells PN
AD  - Department of Medical Physics & Bioengineering, Centre for Physics and
      Engineering Research in Medicine, Bristol General Hospital, Bristol BS1 6SY, UK.
LA  - eng
PT  - Biography
PT  - Historical Article
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PT  - Review
PL  - England
TA  - Br J Radiol
JT  - The British journal of radiology
JID - 0373125
SB  - AIM
SB  - IM
MH  - England
MH  - History, 20th Century
MH  - Humans
MH  - Microscopy/methods/trends
MH  - Robotics/*trends
MH  - Ultrasonography/history/methods/*trends
MH  - Ultrasonography, Interventional/trends
RF  - 26
PS  - Mayneord WV
FPS - Mayneord, W V
EDAT- 2001/01/06 11:00
MHDA- 2001/02/28 10:01
CRDT- 2001/01/06 11:00
AID - 10.1259/bjr.73.875.11144789 [doi]
PST - ppublish
SO  - Br J Radiol. 2000 Nov;73(875):1138-47.

PMID- 11115263
OWN - NLM
STAT- MEDLINE
DA  - 20001215
DCOM- 20001222
LR  - 20150417
IS  - 0003-9950 (Print)
IS  - 0003-9950 (Linking)
VI  - 118
IP  - 12
DP  - 2000 Dec
TI  - Vitreous surgery simulator.
PG  - 1679-81
AB  - OBJECTIVE: To reduce the surgical risks to patients and expose surgeons to
      surgical experience and complications, we have developed a practical system of
      vitreous surgery using virtual-reality technology. METHODS: The system is
      composed of high-resolution color stereo binoculars, haptic devices, foot
      switches, and a high-speed graphics computer. To simulate vitreous surgery, we
      created several virtual patient eyes with retinal diseases such as preretinal
      membranes and subretinal neovascular tissue at the fovea. RESULTS: The simulator 
      provided the trainees with an operating environment similar to an actual one, and
      allowed them to learn to maneuver surgical instruments and remove proliferative
      tissue on the retina, under the retina, or both. This system allowed surgeons to 
      avoid iatrogenic complications through visual signs such as retinal hemorrhage
      when the instrument contacted the retinal surface. CONCLUSIONS: This simulator
      may not only be suitable for residents to learn ocular surgical techniques but
      may also allow veteran surgeons to develop new surgical methods and skills.
FAU - Hikichi, T
AU  - Hikichi T
AD  - Department of Ophthalmology, Asahikawa Medical College, 2-1 Midorigaoka-higashi, 
      Asahikawa 078-8307, Japan. hikichi@asahikawa-med.ac.jp
FAU - Yoshida, A
AU  - Yoshida A
FAU - Igarashi, S
AU  - Igarashi S
FAU - Mukai, N
AU  - Mukai N
FAU - Harada, M
AU  - Harada M
FAU - Muroi, K
AU  - Muroi K
FAU - Terada, T
AU  - Terada T
LA  - eng
PT  - Journal Article
PL  - UNITED STATES
TA  - Arch Ophthalmol
JT  - Archives of ophthalmology (Chicago, Ill. : 1960)
JID - 7706534
SB  - AIM
SB  - IM
MH  - *Computer Simulation
MH  - Computer-Assisted Instruction/*methods/trends
MH  - Humans
MH  - Internship and Residency
MH  - Ophthalmology/*education
MH  - *User-Computer Interface
MH  - *Vitrectomy
EDAT- 2000/12/15 11:00
MHDA- 2001/02/28 10:01
CRDT- 2000/12/15 11:00
AID - eni00003 [pii]
PST - ppublish
SO  - Arch Ophthalmol. 2000 Dec;118(12):1679-81.

PMID- 11003058
OWN - NLM
STAT- MEDLINE
DA  - 20000927
DCOM- 20000927
LR  - 20080909
IS  - 0013-4694 (Print)
IS  - 0013-4694 (Linking)
VI  - 109
IP  - 1
DP  - 1998 Feb
TI  - Virtual reality: a tutorial.
PG  - 1-9
AB  - Virtual reality (VR) technology is complex and relies on multidisciplinary
      knowledge. VR applications are attracting an increasing interest among
      neuroscientists, in particular in the study of the human brain. Here we present a
      brief tutorial in which we address aspects of VR methodology that are most
      relevant to neurophysiology applications. After a brief survey of possible
      applications to neurophysiology, we discuss the following issues in VR: display
      technology, visual stimulus presentation techniques, visual spatial resolution
      and accuracy, devices for real-time interaction with the virtual environment and 
      force-feedback.
FAU - Carrozzo, M
AU  - Carrozzo M
AD  - Sez. Fisiologia Umana e Chinesiologia. C.N.R.-I.N.B., Istituto Scientifico S.
      Lucia, Rome, Italy. carrozzo@caspur.it
FAU - Lacquaniti, F
AU  - Lacquaniti F
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - IRELAND
TA  - Electroencephalogr Clin Neurophysiol
JT  - Electroencephalography and clinical neurophysiology
JID - 0375035
SB  - IM
MH  - Humans
MH  - *Neurophysiology
MH  - *User-Computer Interface
EDAT- 2000/09/26 11:00
MHDA- 2000/09/30 11:01
CRDT- 2000/09/26 11:00
PST - ppublish
SO  - Electroencephalogr Clin Neurophysiol. 1998 Feb;109(1):1-9.

PMID- 10986734
OWN - NLM
STAT- MEDLINE
DA  - 20001227
DCOM- 20001227
LR  - 20051116
IS  - 0193-953X (Print)
IS  - 0193-953X (Linking)
VI  - 23
IP  - 3
DP  - 2000 Sep
TI  - Behavioral, cognitive, and family therapy for obsessive-compulsive and related
      disorders.
PG  - 657-70
AB  - Behavioral therapy and cognitive therapy, individually and combined, are a solid 
      base in any therapy, the goal of which is to decrease the maladaptive behaviors
      associated with obsessive-compulsive spectrum disorders. Future research into
      this area involves two branches: (1) better resolution in what components of
      current treatments are effective and (2) a better understanding of the cause of
      OCD. The therapies of choice are behavioral therapy and cognitive therapy, but
      often what is described as behavioral therapy and cognitive therapy varies.
      Further refinement of the specific components of behavioral therapy and cognitive
      therapy that directly apply to OCD is needed. The specific components likely
      include the use of ERP and rational emotive behavioral therapy but often even
      these therapies can be parceled into smaller discrete parts. Many facets still
      have not been explored thoroughly (e.g., the extent of exposure to adverse
      situations needed, ideal length of therapy, time needed for exposure, and the use
      of virtual reality versus traditional exposures). A better understanding of the
      biological basis for OCD also would further the field. A better understanding of 
      the basis of this disorder also would help clinicians to treat it with medication
      and behavioral therapy. Research into how behavioral therapy and cognitive
      therapy makes neurophysiologic changes would show the effectiveness of the
      treatment and a biological basis. Such studies could include the use of MR
      imaging during different stages in behavioral therapy and the use of functional
      during therapy to observe changes in the brain. Although OCD still is not fully
      understood, researchers are now beginning to understand how to treat it, and a
      solid base of empiric data now exists. The authors hope that investigators will
      continue research toward a better understanding of this disorder so that
      clinicians can better help their patients.
FAU - Neziroglu, F
AU  - Neziroglu F
AD  - Department of Biopsychosocial Research, Bio-Behavioral Institute, Great Neck, New
      York, USA.
FAU - Hsia, C
AU  - Hsia C
FAU - Yaryura-Tobias, J A
AU  - Yaryura-Tobias JA
LA  - eng
PT  - Journal Article
PT  - Review
PL  - UNITED STATES
TA  - Psychiatr Clin North Am
JT  - The Psychiatric clinics of North America
JID - 7708110
SB  - IM
MH  - *Behavior Therapy
MH  - *Cognitive Therapy
MH  - Comorbidity
MH  - Eating Disorders/epidemiology
MH  - *Family Therapy
MH  - Humans
MH  - Hypochondriasis/epidemiology
MH  - Motivation
MH  - Obsessive-Compulsive Disorder/epidemiology/psychology/*therapy
MH  - Prognosis
MH  - Somatoform Disorders/epidemiology
MH  - Trichotillomania/epidemiology
RF  - 72
EDAT- 2000/09/15 11:00
MHDA- 2001/02/28 10:01
CRDT- 2000/09/15 11:00
PST - ppublish
SO  - Psychiatr Clin North Am. 2000 Sep;23(3):657-70.

PMID- 10977581
OWN - NLM
STAT- MEDLINE
DA  - 20000815
DCOM- 20000815
LR  - 20061115
IS  - 0926-9630 (Print)
IS  - 0926-9630 (Linking)
VI  - 70
DP  - 2000
TI  - Radiological tele-immersion for next generation networks.
PG  - 4-9
AB  - Since the acquisition of high-resolution three-dimensional patient images has
      become widespread, medical volumetric datasets (CT or MR) larger than 100 MB and 
      encompassing more than 250 slices are common. It is important to make this
      patient-specific data quickly available and usable to many specialists at
      different geographical sites. Web-based systems have been developed to provide
      volume or surface rendering of medical data over networks with low fidelity, but 
      these cannot adequately handle stereoscopic visualization or huge datasets.
      State-of-the-art virtual reality techniques and high speed networks have made it 
      possible to create an environment for clinicians geographically distributed to
      immersively share these massive datasets in real-time. An object-oriented method 
      for instantaneously importing medical volumetric data into Tele-Immersive
      environments has been developed at the Virtual Reality in Medicine Laboratory
      (VRMedLab) at the University of Illinois at Chicago (UIC). This networked-VR
      setup is based on LIMBO, an application framework or template that provides the
      basic capabilities of Tele-Immersion. We have developed a modular general purpose
      Tele-Immersion program that automatically combines 3D medical data with the
      methods for handling the data. For this purpose a DICOM loader for IRIS Performer
      has been developed. The loader was designed for SGI machines as a shared object, 
      which is executed at LIMBO's runtime. The loader loads not only the selected
      DICOM dataset, but also methods for rendering, handling, and interacting with the
      data, bringing networked, real-time, stereoscopic interaction with radiological
      data to reality. Collaborative, interactive methods currently implemented in the 
      loader include cutting planes and windowing. The Tele-Immersive environment has
      been tested on the UIC campus over an ATM network. We tested the environment with
      3 nodes; one ImmersaDesk at the VRMedLab, one CAVE at the Electronic
      Visualization Laboratory (EVL) on east campus, and a CT scan machine in UIC
      Hospital. CT data was pulled directly from the scan machine to the Tele-Immersion
      server in our Laboratory, and then the data was synchronously distributed by our 
      Onyx2 Rack server to all the VR setups. Instead of permitting medical volume
      visualization at one VR device, by combining teleconferencing, tele-presence, and
      virtual reality, the Tele-Immersive environment will enable geographically
      distributed clinicians to intuitively interact with the same medical volumetric
      models, point, gesture, converse, and see each other. This environment will bring
      together clinicians at different geographic locations to participate in
      Tele-Immersive consultation and collaboration.
FAU - Ai, Z
AU  - Ai Z
AD  - University of Illinois at Chicago, VRMedLab 60612, USA. zai@uic.edu,
      jsilver@uic.edu
FAU - Dech, F
AU  - Dech F
FAU - Rasmussen, M
AU  - Rasmussen M
FAU - Silverstein, J C
AU  - Silverstein JC
LA  - eng
PT  - Journal Article
PT  - Research Support, U.S. Gov't, P.H.S.
PL  - NETHERLANDS
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - T
MH  - Humans
MH  - Image Processing, Computer-Assisted/*instrumentation
MH  - Internet/*instrumentation
MH  - Magnetic Resonance Imaging/*instrumentation
MH  - Medical Records Systems, Computerized/instrumentation
MH  - Radiology Information Systems/instrumentation
MH  - Software
MH  - Telecommunications/instrumentation
MH  - Teleradiology/*instrumentation
MH  - Tomography, X-Ray Computed/*instrumentation
MH  - *User-Computer Interface
EDAT- 2000/09/08 11:00
MHDA- 2000/09/08 11:01
CRDT- 2000/09/08 11:00
PST - ppublish
SO  - Stud Health Technol Inform. 2000;70:4-9.

PMID- 10789131
OWN - NLM
STAT- MEDLINE
DA  - 20000621
DCOM- 20000621
LR  - 20061115
IS  - 0033-832X (Print)
IS  - 0033-832X (Linking)
VI  - 40
IP  - 3
DP  - 2000 Mar
TI  - [Basic principles of data acquisition and data processing for construction of
      high quality virtual models].
PG  - 304-12
AB  - Creating models for virtual reality subdivides into several steps. The aim of the
      data acquisition is the extraction of nearly isotropic (same solution in all
      three axes) data sets with low noise content. An approximate isotropy can be
      achieved by suitable choice of scan parameters. For raw data reconstruction, the 
      application of high-resolution reconstruction algorithms is prohibited due to
      increased noise. A missing isotropy can computationally be approximated by
      interpolation. Further noise suppression is achieved by applying filters.
      Additionally, the contrast of the object for segmentation can be increased by
      image processing operators. The correct choice of the segmentation method and the
      editing tools is essential for a precise segmentation with minimal user
      interaction. Prior to visualization, smoothing the shape of the segmented model
      (shape-based or morphological interpolation, polygon reduction of wire frame
      model) further improves the visual appearance of the 3D model.
FAU - Shin, H
AU  - Shin H
AD  - Diagnostische Radiologie I, Medizinische Hochschule Hannover.
      shin.hoen-oh@mh-hannover.de
FAU - Stamm, G
AU  - Stamm G
FAU - Hogemann, D
AU  - Hogemann D
FAU - Galanski, M
AU  - Galanski M
LA  - ger
PT  - English Abstract
PT  - Journal Article
TT  - Grundregeln der Datenakquisition und Datennachverarbeitung fur die Erstellung
      hochwertiger virtueller Modelle.
PL  - GERMANY
TA  - Radiologe
JT  - Der Radiologe
JID - 0401257
SB  - IM
MH  - Algorithms
MH  - Computer Graphics/instrumentation
MH  - *Computer Simulation
MH  - Diagnostic Imaging/*instrumentation
MH  - Humans
MH  - Image Enhancement/instrumentation
MH  - Image Processing, Computer-Assisted/*instrumentation
MH  - Quality Assurance, Health Care
MH  - *User-Computer Interface
EDAT- 2000/05/02 09:00
MHDA- 2000/06/24 11:00
CRDT- 2000/05/02 09:00
PST - ppublish
SO  - Radiologe. 2000 Mar;40(3):304-12.

PMID- 10789125
OWN - NLM
STAT- MEDLINE
DA  - 20000621
DCOM- 20000621
LR  - 20061115
IS  - 0033-832X (Print)
IS  - 0033-832X (Linking)
VI  - 40
IP  - 3
DP  - 2000 Mar
TI  - [Dynamic MR mammography. Multidimensional visualization of contrast medium
      enhancement in virtual reality].
PG  - 262-6
AB  - BACKGROUND: The purpose of this study was the development of a method for fast
      and efficient analysis of dynamic MR images of the female breast. The image data 
      sets were acquired with a saturation-recovery turbo-FLASH sequence which enables 
      the detection of the kinetics of the contrast agent concentration in the whole
      breast with a high temporal and spatial resolution. In addition, a morphologic
      3D-FLASH data set was acquired. METHODS: The dynamic image datasets were analyzed
      by a pharmacokinetic model which enables the representation of the relevant
      functional tissue information by two parameters. In order to display
      simultaneously morphologic and functional tissue information, we developed a
      multidimensional visualization system, which enables a practical and intuitive
      human-computer interface in virtual reality. DISCUSSIONS: The developed system
      allows the fast and efficient analysis of dynamic MR data sets. An important
      clinical application is the localization and definition of multiple lesions of
      the female breast.
FAU - Englmeier, K H
AU  - Englmeier KH
AD  - GSF-Forschungszentrum fur Umwelt und Gesundheit, Institut fur Medizinische
      Informatik und Systemforschung, Neuherberg. englmeier@gsf.de
FAU - Griebel, J
AU  - Griebel J
FAU - Lucht, R
AU  - Lucht R
FAU - Knopp, M
AU  - Knopp M
FAU - Siebert, M
AU  - Siebert M
FAU - Brix, G
AU  - Brix G
LA  - ger
PT  - English Abstract
PT  - Journal Article
TT  - Dynamische MR-Mammographie. Multidimensionale Visualisierung der
      Kontrastmittelanreicherung in virtueller Realitat.
PL  - GERMANY
TA  - Radiologe
JT  - Der Radiologe
JID - 0401257
RN  - 0 (Contrast Media)
SB  - IM
MH  - Adult
MH  - Aged
MH  - Breast Neoplasms/*diagnosis
MH  - Carcinoma, Ductal, Breast/diagnosis
MH  - Contrast Media/*pharmacokinetics
MH  - Female
MH  - Fibroadenoma/diagnosis
MH  - Humans
MH  - Image Processing, Computer-Assisted/*instrumentation
MH  - Infusion Pumps
MH  - Magnetic Resonance Imaging/*instrumentation
MH  - Mammography/*instrumentation
MH  - Middle Aged
MH  - Neoplasms, Multiple Primary/diagnosis
MH  - *User-Computer Interface
EDAT- 2000/05/02 09:00
MHDA- 2000/06/24 11:00
CRDT- 2000/05/02 09:00
PST - ppublish
SO  - Radiologe. 2000 Mar;40(3):262-6.

PMID- 10719514
OWN - NLM
STAT- MEDLINE
DA  - 20000331
DCOM- 20000331
LR  - 20061115
IS  - 1089-7771 (Print)
IS  - 1089-7771 (Linking)
VI  - 2
IP  - 2
DP  - 1998 Jun
TI  - A VRML-based anatomical visualization tool for medical education.
PG  - 55-61
AB  - The advent of the Virtual Reality Modeling Language (VRML) as a portable file
      format for describing three-dimensional (3-D) scenes has enabled researchers,
      educators, and students to share anatomical models on the World Wide Web (WWW).
      The implication for medical teaching is that students can interactively examine
      anatomical structures and their 3-D spatial relationships by using current
      personal computer (PC) technology. This paper describes the creation of 3-D
      anatomical models that are accessible on the WWW, using high-resolution
      middle-ear data as an example. The 3-D models are created by interactive
      segmentation of the source images (histological and MRI sections) and 3-D surface
      reconstruction. The resulting models are translated into VRML format. Section
      images can be superimposed on the model, allowing students to view a section in
      its 3-D context. To enhance the viewing of these scenes, a VRML browser was
      modified to support transparent rendering of surfaces. Finally, a WWW interface
      was designed to allow users to choose the model structures, section images, and
      associated viewing parameters to build their own 3-D scenes.
FAU - Warrick, P A
AU  - Warrick PA
AD  - Department of BioMedical Engineering, McGill University, Montreal, P.Q., Canada.
FAU - Funnell, W R
AU  - Funnell WR
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - UNITED STATES
TA  - IEEE Trans Inf Technol Biomed
JT  - IEEE transactions on information technology in biomedicine : a publication of the
      IEEE Engineering in Medicine and Biology Society
JID - 9712259
SB  - IM
MH  - Education, Medical/*methods
MH  - Internet
MH  - *Models, Anatomic
EDAT- 2000/03/17
MHDA- 2000/03/17 00:01
CRDT- 2000/03/17 00:00
PST - ppublish
SO  - IEEE Trans Inf Technol Biomed. 1998 Jun;2(2):55-61.

PMID- 10557190
OWN - NLM
STAT- MEDLINE
DA  - 19991117
DCOM- 19991117
LR  - 20061115
IS  - 1462-6446 (Print)
IS  - 1462-6446 (Linking)
VI  - 1
IP  - 2
DP  - 1998 Sep
TI  - Reconstruction of three-dimensional digital teeth.
PG  - 22-5
AB  - OBJECTIVE: Dental anatomy is one of the most important basic courses in the
      education of dentistry. The deep understanding of both the external and internal 
      morphologic characteristics is very important to the teaching, research and
      clinical practice of dentistry. METHODS: In the present study, 32 permanent teeth
      from the skull specimen of a young man were individually embedded in black fluid 
      resin, each in special containers. They were ground by a numerically-controlled
      grinding machine at intervals of 0.2 mm per layer. A distinct outline of the
      tooth could be seen on every section. Black and white photographs were taken and 
      scanned into a computer by a film-scanner to obtain sequences of two-dimensional 
      images of the tooth sections. After pattern recognition, all of the images of
      each tooth were piled up at intervals of 0.2 mm by the technique of computerized 
      reconstruction. RESULTS: The three-dimensional stereo tooth models were built up 
      from two-dimensional data. On the basis of those models, computer graphic
      techniques were used to highlight, smooth, and shade the teeth. These digital
      teeth and dentitions could function as a series of computerized teaching models. 
      Their high resolution and accuracy could meet the basic demands of dentistry.
      CONCLUSIONS: The present study developed new techniques of model preparation,
      image input, and 3-D reconstruction. These digital teeth and dentitions provide
      an important foundation for the application of computer imaging, CAD/CAM,
      computer-assisted instruction, and virtual reality in dentistry.
FAU - Han, K
AU  - Han K
AD  - Department of Prosthodontics, School of Stomatology, Beijing Medical University, 
      P. R. China.
FAU - Lu, R Q
AU  - Lu RQ
FAU - Ma, Y H
AU  - Ma YH
FAU - Lu, P J
AU  - Lu PJ
FAU - Zhang, H
AU  - Zhang H
FAU - Wang, W B
AU  - Wang WB
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - ENGLAND
TA  - Chin J Dent Res
JT  - The Chinese journal of dental research : the official journal of the Scientific
      Section of the Chinese Stomatological Association (CSA)
JID - 100892845
SB  - D
MH  - Anatomy, Cross-Sectional
MH  - Computer-Aided Design
MH  - Computer-Assisted Instruction
MH  - *Dental Models
MH  - Education, Dental/*methods
MH  - Humans
MH  - *Image Processing, Computer-Assisted
MH  - Male
MH  - Models, Educational
MH  - Photography, Dental
MH  - Tooth/*anatomy & histology
EDAT- 1999/11/11
MHDA- 1999/11/11 00:01
CRDT- 1999/11/11 00:00
PST - ppublish
SO  - Chin J Dent Res. 1998 Sep;1(2):22-5.

PMID- 10538352
OWN - NLM
STAT- MEDLINE
DA  - 19990805
DCOM- 19990805
LR  - 20121115
IS  - 0926-9630 (Print)
IS  - 0926-9630 (Linking)
VI  - 62
DP  - 1999
TI  - Virtual reality on the web: the potentials of different methodologies and
      visualization techniques for scientific research and medical education.
PG  - 181-6
AB  - Academic and medical imaging are increasingly using computer based 3D
      reconstruction and/or visualization. Three-dimensional interactive models play a 
      major role in areas such as preclinical medical education, clinical visualization
      and medical research. While 3D is comparably easy to do on a high end
      workstations, distribution and use of interactive 3D graphics necessitate the use
      of personal computers and the web. Several new techniques have been demonstrated 
      providing interactive 3D via a web browser thereby allowing a limited version of 
      VR to be experienced by a larger majority of students, medical practitioners and 
      researchers. These techniques include QuickTimeVR2 (QTVR), VRML2, QuickDraw3D,
      OpenGL and Java3D. In order to test the usability of the different techniques,
      Mednet have initiated a number of projects designed to evaluate the potentials of
      3D techniques for scientific reporting, clinical visualization and medical
      education. These include datasets created by manual tracing followed by
      triangulation, smoothing and 3D visualization, MRI or high-resolution
      laserscanning. Preliminary results indicate that both VRML and QTVR fulfills most
      of the requirements of web based, interactive 3D visualization, whereas
      QuickDraw3D is too limited. Presently, the JAVA 3D has not yet reached a level
      where in depth testing is possible. The use of high-resolution laserscanning is
      an important addition to 3D digitization.
FAU - Kling-Petersen, T
AU  - Kling-Petersen T
AD  - Mednet, Goteborg, Sweden. kling@mednet.gu.se
FAU - Pascher, R
AU  - Pascher R
FAU - Rydmark, M
AU  - Rydmark M
LA  - eng
PT  - Journal Article
PL  - NETHERLANDS
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - T
MH  - Computer Graphics
MH  - Computer Systems
MH  - Education, Medical/*methods
MH  - Humans
MH  - *Image Processing, Computer-Assisted
MH  - *Internet
MH  - Publishing
MH  - *Research Design
MH  - Software
MH  - User-Computer Interface
EDAT- 1999/10/28
MHDA- 1999/10/28 00:01
CRDT- 1999/10/28 00:00
PST - ppublish
SO  - Stud Health Technol Inform. 1999;62:181-6.

PMID- 10350910
OWN - NLM
STAT- MEDLINE
DA  - 19990428
DCOM- 19990428
LR  - 20051116
IS  - 0926-9630 (Print)
IS  - 0926-9630 (Linking)
VI  - 58
DP  - 1998
TI  - From toy to tool: the development of immersive virtual reality environments for
      psychotherapy of specific phobias.
PG  - 103-11
AB  - Virtual Reality (VR) entered the mental health field some years ago. While the
      technology itself has been available for more than ten years now, there is still 
      a certain amount of uncertainty among researchers and users as to whether VR will
      one day fulfill all it's promises. In this chapter we are giving an overview of
      the implementation of the technology in our mental health research facility in
      Basel, Switzerland. The development of two applications for use with
      claustrophobic and acrophobic patients perspectively serves just as an example
      within this context. Some may say, the chapter is too much based on technical
      considerations. Strictly speaking, VR is pure technology, even knowing that this 
      special form of technology has sensory, psychological and even philosophical
      implications not known from other human computer interfaces so far. As far as we 
      are concerned, the development of the technology for use within the mental health
      sector has merely just begun. As today's mostly used immersive output devices
      (Head-mounted Displays, shutter glasses) do not have a satisfactory resolution,
      do restrict movements and prevent multi-user-capabilities, there will be a soar
      of mental health applications the day some or at least the most important of
      these obstacles have been overcome.
FAU - Bullinger, A H
AU  - Bullinger AH
AD  - Department of Clinical Psychiatry, University of Basel, Switzerland.
FAU - Roessler, A
AU  - Roessler A
FAU - Mueller-Spahn, F
AU  - Mueller-Spahn F
LA  - eng
PT  - Journal Article
PT  - Review
PL  - NETHERLANDS
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - T
MH  - *Computer Simulation
MH  - Desensitization, Psychologic/*instrumentation
MH  - Humans
MH  - Image Processing, Computer-Assisted/*instrumentation
MH  - Phobic Disorders/*rehabilitation
MH  - Research
MH  - *Social Environment
MH  - Switzerland
MH  - Therapy, Computer-Assisted/*instrumentation
MH  - *User-Computer Interface
RF  - 13
EDAT- 1999/06/03
MHDA- 1999/06/03 00:01
CRDT- 1999/06/03 00:00
PST - ppublish
SO  - Stud Health Technol Inform. 1998;58:103-11.

PMID- 10098819
OWN - NLM
STAT- MEDLINE
DA  - 19990504
DCOM- 19990504
LR  - 20061115
IS  - 0003-6870 (Print)
IS  - 0003-6870 (Linking)
VI  - 30
IP  - 1
DP  - 1999 Feb
TI  - Physical ergonomics of virtual environment use.
PG  - 79-90
AB  - This paper describes an investigation of the types of problems that may be
      experienced by Virtual Reality (VR) users. Initial concerns have been voiced
      about various issues concerning the design of VR equipment, particularly the
      physical ergonomics of head-mounted displays (HMDs) and hand-held input devices, 
      and the problems associated with display resolution and lags. This study
      investigated a number of VR users' perceptions of the types of physical
      ergonomics issues that they were aware of when participating in a number of
      different virtual environments (VEs), using different VR systems. Several
      different methods were employed, including questionnaires, body mapping, user
      observation and interviews. Issues highlighted as either causing participants
      discomfort or interfering with their experience of the VE were: discomfort from
      static posture requirements, general discomfort from wearing the HMD, difficulty 
      becoming accustomed to 3D hand held input devices, dissatisfaction with deficits 
      in the visual display and fear of getting 'tangled' in connecting cables. The
      implications of these findings for developers, implementers and users of VR are
      discussed.
FAU - Nichols, S
AU  - Nichols S
AD  - Department of Manufacturing Engineering and Operations Management, University of 
      Nottingham, University Park, UK.
LA  - eng
PT  - Clinical Trial
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - ENGLAND
TA  - Appl Ergon
JT  - Applied ergonomics
JID - 0261412
SB  - IM
MH  - Adult
MH  - Data Display/adverse effects
MH  - Equipment Design
MH  - Female
MH  - *Human Engineering
MH  - Humans
MH  - Male
MH  - Posture
MH  - *User-Computer Interface
MH  - Vision Disorders/etiology
EDAT- 1999/03/31
MHDA- 1999/03/31 00:01
CRDT- 1999/03/31 00:00
AID - S0003687098000453 [pii]
PST - ppublish
SO  - Appl Ergon. 1999 Feb;30(1):79-90.

PMID- 9877291
OWN - NLM
STAT- MEDLINE
DA  - 19990128
DCOM- 19990128
LR  - 20140617
IS  - 0021-8782 (Print)
IS  - 0021-8782 (Linking)
VI  - 193 ( Pt 3)
DP  - 1998 Oct
TI  - Advances in three-dimensional diagnostic radiology.
PG  - 363-71
AB  - The maturity of current 3D rendering software in combination with recent
      developments in computer vision techniques enable an exciting range of
      applications for the visualisation, measurement and interactive manipulation of
      volumetric data, relevant both for diagnostic imaging and for anatomy. This paper
      reviews recent work in this area from the Image Sciences Institute at Utrecht
      University. The processes that yield a useful visual presentation are sequential.
      After acquisition and before any visualisation, an essential step is to prepare
      the data properly: this field is known as 'image processing' or 'computer vision'
      in analogy with the processing in human vision. Examples will be discussed of
      modern image enhancement and denoising techniques, and the complex process of
      automatically finding the objects or regions of interest, i.e. segmentation. One 
      of the newer and promising methodologies for image analysis is based on a
      mathematical analysis of the human (cortical) visual processing: multiscale image
      analysis. After preprocessing the 3D rendering can be acquired by simulating the 
      'ray casting' in the computer. New possibilities are presented, such as the
      integrated visualisation in one image of (accurately registered) datasets of the 
      same patient acquired in different modality scanners. Other examples include
      colour coding of functional data such as SPECT brain perfusion or functional
      magnetic resonance (MR) data and even metric data such as skull thickness on the 
      rendered 3D anatomy from MR or computed tomography (CT). Optimal use and
      perception of 3D visualisation in radiology requires fast display and truly
      interactive manipulation facilities. Modern and increasingly cheaper workstations
      ( < $10000) allow this to be a reality. It is now possible to manipulate 3D
      images of 256 at 15 frames per second interactively, placing virtual reality
      within reach. The possibilities of modern workstations become increasingly more
      sophisticated and versatile. Examples presented include the automatic detection
      of the optimal viewing angle of the neck of aneurysms and the simulation of the
      design and placement procedure of intra-abdominal aortic stents. Such
      developments, together with the availability of high-resolution datasets of
      modern scanners and data such as from the NIH Visible Human project, have a
      dramatic impact on interactive 3D anatomical atlases.
FAU - ter Haar Romeny, B M
AU  - ter Haar Romeny BM
AD  - Image Sciences Institute, Utrecht University, The Netherlands. bart@isi.uu.nl
FAU - Zuiderveld, K J
AU  - Zuiderveld KJ
FAU - Van Waes, P F
AU  - Van Waes PF
FAU - Van Walsum, T
AU  - Van Walsum T
FAU - Van Der Weijden, R
AU  - Van Der Weijden R
FAU - Weickert, J
AU  - Weickert J
FAU - Stokking, R
AU  - Stokking R
FAU - Wink, O
AU  - Wink O
FAU - Kalitzin, S
AU  - Kalitzin S
FAU - Maintz, T
AU  - Maintz T
FAU - Zonneveld, F
AU  - Zonneveld F
FAU - Viergever, M A
AU  - Viergever MA
LA  - eng
PT  - Journal Article
PT  - Review
PL  - ENGLAND
TA  - J Anat
JT  - Journal of anatomy
JID - 0137162
SB  - IM
MH  - Humans
MH  - Radiographic Image Enhancement/*trends
RF  - 20
PMC - PMC1467872
OID - NLM: PMC1467872
EDAT- 1999/01/07
MHDA- 1999/01/07 00:01
CRDT- 1999/01/07 00:00
PST - ppublish
SO  - J Anat. 1998 Oct;193 ( Pt 3):363-71.

PMID- 10180549
OWN - NLM
STAT- MEDLINE
DA  - 19980723
DCOM- 19980723
LR  - 20130520
IS  - 0926-9630 (Print)
IS  - 0926-9630 (Linking)
VI  - 50
DP  - 1998
TI  - The virtual retinal display: a new technology for virtual reality and augmented
      vision in medicine.
PG  - 252-7
AB  - INTRODUCTION: The Virtual Retinal Display (VRD) is a new technology for creating 
      visual images. It was developed at the Human Interface Technology Laboratory (HIT
      Lab) by Dr. Thomas A. Furness III. The VRD creates images by scanning low power
      laser light directly onto the retina. This special method results in images that 
      are bright, high contrast and high resolution. In this paper, we describe how the
      VRD functions, the special consequences of its mechanism of action and potential 
      medical applications of the VRD, including surgical displays and displays for
      people with low vision. A description of its safety analysis will also be
      included. In one set of tests we had a number of patients with partial loss of
      vision view images with the VRD. There were two groups of subjects: patients with
      macular degeneration, a degenerative disease of the retina and patients with
      keratoconus. Typical VRD images are on the order of 300 nanowatts. VRD images are
      also readily viewed superimposed on ambient room light. In our low vision test
      subjects, 5 out of 8 subjects with macular degeneration felt the VRD images were 
      better and brighter than the CRT or paper images and they were able to reach the 
      same or better level of resolution. All patients with Keratoconus were able to
      resolve lines of test several lines smaller with the VRD than with their own
      correction. Further, they all felt that the VRD images were sharper and easier to
      view. The VRD is a safe new display technology. The power levels recorded from
      the system are several orders below the power levels prescribed by the American
      National Standard. The VRD readily creates images that can be easily seen in
      ambient roomlight and it can create images that can be seen in ambient daylight. 
      The combination of high brightness and contrast and high resolution make the VRD 
      an ideal candidate for use in a surgical display. Further, tests show strong
      potential for the VRD to be a display technology for patients with low vision.
FAU - Viirre, E
AU  - Viirre E
AD  - Human Interface Technology Laboratory, University of Washington, Seattle
      98195-2142, USA.
FAU - Pryor, H
AU  - Pryor H
FAU - Nagata, S
AU  - Nagata S
FAU - Furness, T A 3rd
AU  - Furness TA 3rd
LA  - eng
PT  - Journal Article
PT  - Research Support, U.S. Gov't, Non-P.H.S.
PL  - NETHERLANDS
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - T
MH  - Equipment Design
MH  - Equipment Safety
MH  - Humans
MH  - Keratoconus
MH  - Lasers
MH  - Macular Degeneration
MH  - *Retina
MH  - *Sensory Aids
MH  - Vision, Low/*therapy
EDAT- 1997/12/08
MHDA- 2001/03/28 10:01
CRDT- 1997/12/08 00:00
PST - ppublish
SO  - Stud Health Technol Inform. 1998;50:252-7.

PMID- 9731329
OWN - NLM
STAT- MEDLINE
DA  - 19980924
DCOM- 19980924
LR  - 20091111
IS  - 0067-8856 (Print)
IS  - 0067-8856 (Linking)
VI  - 33
DP  - 1997
TI  - The realization of a haptic (force feedback) interface device for the purpose of 
      angioplasty surgery simulation.
PG  - 19-24
AB  - Simulation is becoming an increasingly accepted method for training personnel for
      complex or high risk tasks. With the advent of modern Virtual Reality (VR)
      technology, such simulations are becoming more and more immersive. One
      significant limitation to the advance of this science is the challenges
      associated with simulating the touch or feel of various tasks in conjunction with
      VR simulations. This work has focused on creating and assessing the feasibility
      of haptic technology for high fidelity surgery simulation. It has culminated in a
      prototypical interface device to provide tactile feedback during the simulation
      of complex interventional radiology procedures such as Angioplasty. This device
      extends state of the art motion control, distributed computing processes, high
      resolution sensors for real-time feedback, and modular design techniques to
      accomplish these goals. The realization of the device, its capabilities,
      interfacing requirements, its limitations, and future extensions will be
      presented here.
FAU - Barnes, S Z
AU  - Barnes SZ
AD  - Ohio State University, Department of Biomedical Engineering, Columbus, USA.
FAU - Morr, D R
AU  - Morr DR
FAU - Oggero, E
AU  - Oggero E
FAU - Pagnacco, G
AU  - Pagnacco G
FAU - Berme, N
AU  - Berme N
LA  - eng
PT  - Journal Article
PL  - UNITED STATES
TA  - Biomed Sci Instrum
JT  - Biomedical sciences instrumentation
JID - 0140524
SB  - IM
MH  - *Angioplasty, Balloon
MH  - *Computer Simulation
MH  - *Education, Medical
MH  - Educational Technology
MH  - General Surgery/*education
MH  - Humans
MH  - *User-Computer Interface
EDAT- 1997/01/01 00:00
MHDA- 1998/09/10 00:01
CRDT- 1997/01/01 00:00
PST - ppublish
SO  - Biomed Sci Instrum. 1997;33:19-24.

PMID- 8988467
OWN - NLM
STAT- MEDLINE
DA  - 19970417
DCOM- 19970417
LR  - 20130918
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 4
IP  - 1
DP  - 1997 Jan-Feb
TI  - Telemedicine expanding the scope of health care information.
PG  - 1-5
AB  - The definition of health information is growing to include multimedia audio,
      video, and high-resolution still images. This article describes the telemedicine 
      program at East Carolina University School of Medicine, including the
      telemedicine applications presently in use and the virtual reality applications
      currently under development' Included are the major design criteria that shape
      the telemedicine network some of the lessons learned in developing the network,
      and a discussion of the future of telemedicine, including efforts to incorporate 
      telemedicine within a fully integrated health information system.
FAU - Balch, D C
AU  - Balch DC
AD  - East Carolina University, Greenville, NC, USA. dave@sparkymed.ecu.edu
FAU - Tichenor, J M
AU  - Tichenor JM
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PT  - Research Support, U.S. Gov't, Non-P.H.S.
PL  - UNITED STATES
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
CIN - J Am Med Inform Assoc. 1997 Jan-Feb;4(1):69-70. PMID: 8988476
MH  - Computer Communication Networks/*organization & administration
MH  - Computer User Training
MH  - Humans
MH  - Information Services
MH  - Medical Records Systems, Computerized
MH  - North Carolina
MH  - Remote Consultation/organization & administration
MH  - Rural Health Services/*organization & administration
MH  - Systems Integration
MH  - Telemedicine/*organization & administration
MH  - User-Computer Interface
PMC - PMC61191
OID - NLM: PMC61191
EDAT- 1997/01/01
MHDA- 1997/01/01 00:01
CRDT- 1997/01/01 00:00
PST - ppublish
SO  - J Am Med Inform Assoc. 1997 Jan-Feb;4(1):1-5.

PMID- 10168945
OWN - NLM
STAT- MEDLINE
DA  - 19970904
DCOM- 19970904
LR  - 20071115
IS  - 0926-9630 (Print)
IS  - 0926-9630 (Linking)
VI  - 39
DP  - 1997
TI  - The BRAIN project: an interactive learning tool using desktop virtual reality on 
      personal computers.
PG  - 529-38
AB  - The BRAIN-project is an endeavor in using computer aided learning to improve the 
      understanding of the human brain anatomy. The project consists of four parts,
      each based on modular packages: BRAINIMAGES: Brain atlas consisting of horizontal
      and frontal brain slices spaced I mm apart enabling the identification of
      structures and areas of the brain. The software also contains views of the
      brain's outer surface with all pertinent structures marked. BRAINRADIOLOGY:
      Visualisation of the brain using CT, MRI and angiography. The different imaging
      techniques enable the user to explore the brain from several angles and also view
      the major blood vessels of the brain. NEUROHISTOLOGY: Cells of the brain using
      histologically stained sections. The program emphasizes the organization of cells
      in layers and the interaction of different cell types. 3D-BRAIN: Three
      dimensional reconstructions based on physical slices of a human brain. The
      reconstructed brain views are made interactive using a simple form of desktop
      virtual reality: QuickTime VR technology. The user can rotate the different views
      in all directions producing a 3D effect. The different views are designed to
      highlight important structures and their organization within the outlined (and
      semi transparent) brain surface. Contrary to similar applications, the actual
      three dimensional objects are not based on MRI or CT scans (with comparatively
      poor resolution), but on tracings made on high resolution images of photographs
      of actual sections of a postmortem brain. N.B., this approach produces 3D
      renderings in a more detailed and reliable way. The BRAIN project is designed as 
      a support package for students in preclinical education by supplying additional
      means for gathering information pertinent to the curriculum. By cross linking,
      the students can switch from a three dimensional object to a corresponding slice,
      and then to the relevant histological sample and son on. The software components 
      are based on a modular design enabling easy modification of the various parts and
      the entire project is designed to run on both Apple Macintosh and MS Windows
      based PCs.
FAU - Kling-Petersen, T
AU  - Kling-Petersen T
AD  - Mednet, Goteborg University, Sweden.
FAU - Rydmark, M
AU  - Rydmark M
LA  - eng
PT  - Journal Article
PL  - NETHERLANDS
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - T
MH  - Anatomy/education
MH  - Atlases as Topic
MH  - Brain/*anatomy & histology/radiography
MH  - Computer-Assisted Instruction/*methods
MH  - Humans
MH  - *Microcomputers
MH  - *User-Computer Interface
EDAT- 1996/12/08
MHDA- 1996/12/08 00:01
CRDT- 1996/12/08 00:00
PST - ppublish
SO  - Stud Health Technol Inform. 1997;39:529-38.

PMID- 10165366
OWN - NLM
STAT- MEDLINE
DA  - 19970408
DCOM- 19970408
LR  - 20061115
IS  - 1078-3024 (Print)
IS  - 1078-3024 (Linking)
VI  - 2
IP  - 4
DP  - 1996 Winter
TI  - Telemedicine and distributed medical intelligence.
PG  - 295-301
AB  - Recent trends in health care informatics and telemedicine indicate that systems
      are being developed with a primary focus on technology and business, not on the
      process of medicine itself. The authors present a new model of health care
      information, distributed medical intelligence, which promotes the development of 
      an integrative medical communication system addressing the process of providing
      expert medical knowledge to the point of need. The model incorporates audio,
      video, high-resolution still images, and virtual reality applications into an
      integrated medical communications network. Three components of the model (care
      portals, Docking Station, and the bridge) are described. The implementation of
      this model at the East Carolina University School of Medicine is also outlined.
FAU - Warner, D
AU  - Warner D
AD  - Northeast Parallel Architecture Center, Syracuse University, NY, USA.
FAU - Tichenor, J M
AU  - Tichenor JM
FAU - Balch, D C
AU  - Balch DC
LA  - eng
PT  - Comparative Study
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PT  - Research Support, U.S. Gov't, Non-P.H.S.
PL  - UNITED STATES
TA  - Telemed J
JT  - Telemedicine journal : the official journal of the American Telemedicine
      Association
JID - 9507612
SB  - T
MH  - *Computer Communication Networks
MH  - *Information Systems
MH  - Models, Theoretical
MH  - North Carolina
MH  - Schools, Medical
MH  - *Telemedicine
EDAT- 1996/01/01 00:00
MHDA- 1999/04/02 00:01
CRDT- 1996/01/01 00:00
PST - ppublish
SO  - Telemed J. 1996 Winter;2(4):295-301.

PMID- 7554830
OWN - NLM
STAT- MEDLINE
DA  - 19951030
DCOM- 19951030
LR  - 20061115
IS  - 0010-4825 (Print)
IS  - 0010-4825 (Linking)
VI  - 25
IP  - 2
DP  - 1995 Mar
TI  - An inventory of computer resources for the medical application of virtual
      reality.
PG  - 115-25
AB  - Within the framework of the scientific community, we could define virtual reality
      (VR) as an effective simulation of complex environmental aspects related to both 
      interaction-dependent and high-risk operations, where mistakes will lead to
      unacceptable consequences. Surgeons performing open surgery, endoscopists working
      on the intestine or neurologists working on the brain-all are impressive examples
      where the VR approach looks potentially quite interesting. In fact the risk of
      unsatisfactory implementations, too poor with respect to the complexity of the
      real world, coming from the unsatisfactory performance of the present-day
      technology, is quite high. Typically, the loss of the real time requirement for
      the operator interactions can remove much of the effectiveness of what has been
      built. Some questions about the real need for high performance computational
      resources and high level graphic resolution need to be answered. This paper
      presents and discusses an inventory of computational resources used in real
      applications.
FAU - Pinciroli, F
AU  - Pinciroli F
AD  - Dipartimento di Bioingegneria, Politecnico di Milano, Italy.
FAU - Valenza, P
AU  - Valenza P
LA  - eng
PT  - Comparative Study
PT  - Journal Article
PL  - UNITED STATES
TA  - Comput Biol Med
JT  - Computers in biology and medicine
JID - 1250250
SB  - IM
MH  - CD-ROM
MH  - Classification
MH  - Computer Graphics
MH  - *Computer Simulation
MH  - Computer Terminals
MH  - *Computers
MH  - Europe
MH  - Questionnaires
MH  - Research
MH  - United States
EDAT- 1995/03/01
MHDA- 1995/03/01 00:01
CRDT- 1995/03/01 00:00
AID - 0010-4825(95)00003-M [pii]
PST - ppublish
SO  - Comput Biol Med. 1995 Mar;25(2):115-25.
